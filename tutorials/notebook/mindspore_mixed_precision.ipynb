{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center/>混合精度训练体验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "神经网络训练的时候，数据和权重等各种参数一般使用单精度浮点数（float32）进行计算和存储。在采用复杂神经网络进行训练时，由于计算量的增加，机器的内存开销变得非常大。经常玩模型训练的人知道，内存资源的不足会导致训练的效率变低，简单说就是训练变慢，有没有什么比较好的方法，在不提升硬件资源的基础上加快训练呢？这次我们介绍其中一种方法--混合精度训练，说白了就是将参数取其一半长度进行计算，即使用半精度浮点数（float16）计算，这样就能节省一半内存开销。当然，为了保证模型的精度，不能把所有的计算参数都换成半精度。为了兼顾模型精度和训练效率，MindSpore在框架中设置了一个自动混合精度训练的功能，本次体验我们将使用ResNet-50网络进行训练，体验MindSpore混合精度训练和单精度训练的不同之处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MindSpore混合精度训练的原理介绍。\n",
    "2. 数据集准备。\n",
    "3. 定义ResNet-50网络。\n",
    "4. 定义`One_Step_Time`回调函数。\n",
    "5. 定义训练网络（此处设置自动混合精度训练参数`amp_level`）。\n",
    "6. 验证模型精度。\n",
    "7. 混合精度训练和单精度训练的对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 你可以在这里找到完整可运行的样例代码：<https://gitee.com/mindspore/mindspore/tree/master/model_zoo/official/cv/resnet>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MindSpore混合精度训练原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://gitee.com/mindspore/docs/raw/master/tutorials/training/source_zh_cn/advanced_use/images/mix_precision.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 参数以FP32存储；\n",
    "2. 正向计算过程中，遇到FP16算子，需要把算子输入和参数从FP32 `cast`成FP16进行计算；\n",
    "3. 将Loss层设置为FP32进行计算；\n",
    "4. 反向计算过程中，首先乘以Loss Scale值，避免反向梯度过小而产生下溢；\n",
    "5. FP16参数参与梯度计算，其结果将被cast回FP32；\n",
    "6. 除以`Loss scale`值，还原被放大的梯度；\n",
    "7. 判断梯度是否存在溢出，如果溢出则跳过更新，否则优化器以FP32对原始参数进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上可以理解(float16为半精度浮点数，float32为单精度浮点数)，MindSpore是将网络中的前向计算部分`cast`成半精度浮点数进行计算，以节省内存空间，提升性能，同时将`loss`值保持单精度浮点数进行计算和存储，`weight`使用半精度浮点数进行计算，单精度浮点数进行保存，通过这样操作即提升了训练效率，又保证了一定的模型精度，达到提升训练性能的目的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载并解压数据集cifar10到指定位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-03 16:21:55--  https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/cifar10.zip\n",
      "Resolving proxy-notebook.modelarts-dev-proxy.com (proxy-notebook.modelarts-dev-proxy.com)... 192.168.0.172\n",
      "Connecting to proxy-notebook.modelarts-dev-proxy.com (proxy-notebook.modelarts-dev-proxy.com)|192.168.0.172|:8083... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 166235630 (159M) [application/zip]\n",
      "Saving to: ‘cifar10.zip’\n",
      "\n",
      "cifar10.zip         100%[===================>] 158.53M  56.9MB/s    in 2.8s    \n",
      "\n",
      "2020-12-03 16:21:59 (56.9 MB/s) - ‘cifar10.zip’ saved [166235630/166235630]\n",
      "\n",
      "Archive:  cifar10.zip\n",
      "   creating: ./datasets/cifar10/\n",
      "   creating: ./datasets/cifar10/test/\n",
      "  inflating: ./datasets/cifar10/test/test_batch.bin  \n",
      "   creating: ./datasets/cifar10/train/\n",
      "  inflating: ./datasets/cifar10/train/batches.meta.txt  \n",
      "  inflating: ./datasets/cifar10/train/data_batch_1.bin  \n",
      "  inflating: ./datasets/cifar10/train/data_batch_2.bin  \n",
      "  inflating: ./datasets/cifar10/train/data_batch_3.bin  \n",
      "  inflating: ./datasets/cifar10/train/data_batch_4.bin  \n",
      "  inflating: ./datasets/cifar10/train/data_batch_5.bin  \n",
      "./datasets/cifar10\n",
      "├── test\n",
      "│   └── test_batch.bin\n",
      "└── train\n",
      "    ├── batches.meta.txt\n",
      "    ├── data_batch_1.bin\n",
      "    ├── data_batch_2.bin\n",
      "    ├── data_batch_3.bin\n",
      "    ├── data_batch_4.bin\n",
      "    └── data_batch_5.bin\n",
      "\n",
      "2 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/cifar10.zip\n",
    "!unzip -o cifar10.zip -d ./datasets\n",
    "!tree ./datasets/cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先将CIFAR-10的原始数据集可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cifar dataset size is : 50000\n",
      "the tensor of image is: (32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mindspore.dataset.engine as de\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_path = \"./datasets/cifar10/train\"\n",
    "ds = de.Cifar10Dataset(train_path, num_parallel_workers=8, shuffle=True)\n",
    "print(\"the cifar dataset size is :\", ds.get_dataset_size())\n",
    "dict1 = ds.create_dict_iterator()\n",
    "datas = dict1.get_next()\n",
    "image = datas[\"image\"].asnumpy()\n",
    "print(\"the tensor of image is:\", image.shape)\n",
    "plt.imshow(np.array(image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到CIFAR-10总共包含了50000张32×32的彩色图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义数据增强函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据集增强函数并将原始数据集进行增强，查看数据集增强后张量数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cifar dataset size is: 1562\n",
      "the tensor of image is: (32, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.dataset.engine as de\n",
    "import mindspore.dataset.vision.c_transforms as C\n",
    "import mindspore.dataset.transforms.c_transforms as C2\n",
    "\n",
    "def create_dataset(dataset_path, do_train, repeat_num=1, batch_size=32):\n",
    "    \n",
    "    ds = de.Cifar10Dataset(dataset_path, num_parallel_workers=8, shuffle=True)\n",
    "    \n",
    "    # define map operations\n",
    "    trans = []\n",
    "    if do_train:\n",
    "        trans += [\n",
    "            C.RandomCrop((32, 32), (4, 4, 4, 4)),\n",
    "            C.RandomHorizontalFlip(prob=0.5)\n",
    "        ]\n",
    "\n",
    "    trans += [\n",
    "        C.Resize((224, 224)),\n",
    "        C.Rescale(1.0 / 255.0, 0.0),\n",
    "        C.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]),\n",
    "        C.HWC2CHW()\n",
    "    ]\n",
    "\n",
    "    type_cast_op = C2.TypeCast(mstype.int32)\n",
    "\n",
    "    ds = ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=8)\n",
    "    ds = ds.map(operations=trans, input_columns=\"image\", num_parallel_workers=8)\n",
    "\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    ds = ds.repeat(repeat_num)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds = create_dataset(train_path, do_train=True, repeat_num=1, batch_size=32)\n",
    "print(\"the cifar dataset size is:\", ds.get_dataset_size())\n",
    "dict1 = ds.create_dict_iterator()\n",
    "datas = dict1.get_next()\n",
    "image = datas[\"image\"].asnumpy()\n",
    "print(\"the tensor of image is:\", image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cifar10通过数据增强后的，变成了一共有1562个batch，张量为(32,3,224,224)的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义深度神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本篇使用的MindSpore中的ResNet-50网络模型，下载相关的代码文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-03 16:22:03--  https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/source-codes/resnet.py\n",
      "Resolving proxy-notebook.modelarts-dev-proxy.com (proxy-notebook.modelarts-dev-proxy.com)... 192.168.0.172\n",
      "Connecting to proxy-notebook.modelarts-dev-proxy.com (proxy-notebook.modelarts-dev-proxy.com)|192.168.0.172|:8083... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 9533 (9.3K) [binary/octet-stream]\n",
      "Saving to: ‘resnet.py’\n",
      "\n",
      "resnet.py           100%[===================>]   9.31K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-12-03 16:22:03 (102 MB/s) - ‘resnet.py’ saved [9533/9533]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/source-codes/resnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载后的文件在notebook的工作目录上，可以导出resnet50网络作为本案例的训练网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import resnet50\n",
    "\n",
    "network = resnet50(batch_size=32, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义回调函数Time_per_Step来计算单步训练耗时"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Time_per_Step`用于计算每步训练的时间消耗情况，方便对比混合精度训练和单精度训练的性能区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.callback import Callback\n",
    "import time\n",
    "\n",
    "class Time_per_Step(Callback):\n",
    "    def step_begin(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        cb_params.init_time = time.time()\n",
    "        \n",
    "    def step_end(selfself, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        one_step_time = (time.time() - cb_params.init_time) * 1000\n",
    "        print(one_step_time, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置混合精度训练并执行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于MindSpore已经添加了自动混合精度训练功能，我们这里操作起来非常方便，只需要在Model中添加参数`amp_level=O2`就完成了设置GPU模式下的混合精度训练设置。运行时，将会自动混合精度训练模型。\n",
    "\n",
    "`amp_level`的参数详情：\n",
    "\n",
    "`O0`：表示不做任何变化，即单精度训练，系统默认`O0`。\n",
    "\n",
    "`O2`：表示将网络中的参数计算变为float16。适用于GPU环境。\n",
    "\n",
    "`O3`：表示将网络中的参数计算变为float16，同时需要在Model中添加参数`keep_batchnorm_fp32=False`。适用于Ascend环境。\n",
    "\n",
    "在`Model`中设置`amp_level=O2`后即可执行混合精度训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 2.3160617\n",
      "24444.591760635376 ms\n",
      "epoch: 1 step: 2, loss is 2.298256\n",
      "61.20491027832031 ms\n",
      "epoch: 1 step: 3, loss is 2.311338\n",
      "59.53788757324219 ms\n",
      "epoch: 1 step: 4, loss is 2.2904897\n",
      "58.71152877807617 ms\n",
      "epoch: 1 step: 5, loss is 2.2978528\n",
      "60.266733169555664 ms\n",
      "epoch: 1 step: 6, loss is 2.2929726\n",
      "56.272268295288086 ms\n",
      "... ...\n",
      "epoch: 5 step: 1554, loss is 0.48822948\n",
      "58.71415138244629 ms\n",
      "epoch: 5 step: 1555, loss is 0.46233642\n",
      "57.90591239929199 ms\n",
      "epoch: 5 step: 1556, loss is 0.7254324\n",
      "58.26139450073242 ms\n",
      "epoch: 5 step: 1557, loss is 0.6298543\n",
      "58.3195686340332 ms\n",
      "epoch: 5 step: 1558, loss is 0.6005585\n",
      "59.252262115478516 ms\n",
      "epoch: 5 step: 1559, loss is 0.49638084\n",
      "58.45355987548828 ms\n",
      "epoch: 5 step: 1560, loss is 0.6874767\n",
      "57.88683891296387 ms\n",
      "epoch: 5 step: 1561, loss is 0.8344187\n",
      "57.00039863586426 ms\n",
      "epoch: 5 step: 1562, loss is 0.32391208\n",
      "56.182861328125 ms\n",
      "Epoch time: 96696.206, per step time: 61.905\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train ResNet-50\"\"\"\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from mindspore import context\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Image classification')\n",
    "parser.add_argument('--dataset', type=str, default=\"cifar10\", help='Dataset, either cifar10 or imagenet2012')\n",
    "parser.add_argument('--run_distribute', type=bool, default=False, help='Run distribute')\n",
    "parser.add_argument('--device_target', type=str, default='GPU', help='Device target')\n",
    "parser.add_argument('--pre_trained', type=str, default=None, help='Pretrained checkpoint path')\n",
    "args_opt = parser.parse_known_args()[0]\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "de.config.set_seed(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "    \n",
    "    model_path= \"./models/ckpt/mindspore_mixed_precision\"\n",
    "    batch_size = 32\n",
    "    epoch_size = 3\n",
    "    ds_train_path = \"./datasets/cifar10/train\"\n",
    "    \n",
    "    # clean up old run files before in Linux\n",
    "    os.system('rm -f {0}*.ckpt {0}*.meta {0}*.pb'.format(model_path))\n",
    "    # create dataset\n",
    "    dataset = create_dataset(dataset_path=ds_train_path, do_train=True, repeat_num=1,\n",
    "                                 batch_size=batch_size)\n",
    "    \n",
    "    # define net\n",
    "    net = network\n",
    "\n",
    "    # define opt\n",
    "    step_size = dataset.get_dataset_size()\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    \n",
    "    # define loss, model\n",
    "    loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(network.trainable_params(), lr, momentum)\n",
    "    model = Model(net, loss_fn=loss, optimizer=opt, metrics={'acc'},amp_level=\"O2\")\n",
    "    \n",
    "    # define callbacks function\n",
    "    steptime_cb = Time_per_Step()\n",
    "    time_cb = TimeMonitor(data_size=step_size)\n",
    "    loss_cb = LossMonitor()\n",
    "\n",
    "    cb = [time_cb, loss_cb, steptime_cb]\n",
    "\n",
    "    # train model\n",
    "    model.train(epoch_size, dataset, callbacks=cb, dataset_sink_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证模型精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用模型进行精度验证可以得出以下代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {'acc': 0.7817508012820513}\n"
     ]
    }
   ],
   "source": [
    "# Eval model\n",
    "eval_dataset_path = \"./datasets/cifar10/test\"\n",
    "eval_data = create_dataset(eval_dataset_path,do_train=False)\n",
    "acc = model.eval(eval_data,dataset_sink_mode=True)\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比不同网络下的混合精度训练和单精度训练的差别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于篇幅原因，我们这里只展示了ResNet-50网络的混合精度训练情况。可以在主程序入口的Model中设置参数`amp_level = O0`进行单精度训练，训练完毕后，将结果进行对比，看看两者的情况，下面将我测试的情况做成表格如下。（训练时，笔者使用的GPU为Nvidia Tesla V100，不同的硬件对训练的效率影响较大，下述表格中的数据仅供参考）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  网络 | 是否混合训练 | 单步训练时间 | epoch | Accuracy\n",
    "|:------  |:-----| :------- |:--- |:------  \n",
    "|ResNet-50 |  否  | 100ms   |  5 |  0.8128245 \n",
    "|ResNet-50 |  是  | 58ms   |  5 |  0.7817508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过多次测试，使用ResNet-50网络，CIFAR-10数据集，进行混合精度训练对整体的训练效率提升了60%左右，而最终模型的精度有少量降低，对于使用者来说，混合精度训练在提升训练效率上，是一个很好的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，如果你想参考单步训练或者手动设置混合精度训练，可以参考官网教程<https://www.mindspore.cn/tutorial/training/zh-CN/master/advanced_use/enable_mixed_precision.html>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次体验我们尝试了在ResNet-50网络中使用混合精度来进行模型训练，并对比了单精度下的训练过程，了解到了混合精度训练的原理和对模型训练的提升效果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore-1.0.1",
   "language": "python",
   "name": "mindspore-1.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
