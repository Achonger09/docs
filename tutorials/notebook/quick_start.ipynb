{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>手写数字分类识别入门体验教程</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现一个图片分类应用\n",
    "## 概述\n",
    "下面我们通过一个实际样例，带领大家体验MindSpore基础的功能，对于一般的用户而言，完成整个样例实践会持续20~30分钟。\n",
    "\n",
    "本例子会实现一个简单的图片分类的功能，整体流程如下：\n",
    "\n",
    "1. 处理需要的数据集，这里使用了MNIST数据集。\n",
    "\n",
    "2. 定义一个网络，这里我们使用LeNet网络。\n",
    "\n",
    "3. 定义损失函数和优化器。\n",
    "\n",
    "4. 加载数据集并进行训练，训练完成后，查看结果及保存模型文件。\n",
    "\n",
    "5. 加载保存的模型，进行推理。\n",
    "\n",
    "6. 验证模型，加载测试数据集和训练后的模型，验证结果精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：<br/>你可以在这里找到完整可运行的样例代码：https://gitee.com/mindspore/docs/blob/master/tutorials/tutorial_code/lenet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练的数据集下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法一：\n",
    "从以下网址下载，并将数据包解压缩后放至Jupyter的工作目录下：<br/>训练数据集：{\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\"}\n",
    "<br/>测试数据集：{\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"}<br/>我们用下面代码查询jupyter的工作目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据集放在----`Jupyter工作目录+\\MNIST_Data\\train\\`，此时train文件夹内应该包含两个文件，`train-images-idx3-ubyte`和`train-labels-idx1-ubyte` <br/>测试数据集放在----`Jupyter工作目录+\\MNIST_Data\\test\\`，此时test文件夹内应该包含两个文件，`t10k-images-idx3-ubyte`和`t10k-labels-idx1-ubyte`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法二：\n",
    "直接执行下面代码，会自动进行训练集的下载与解压，但是整个过程根据网络好坏情况会需要花费几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Downloading the MNIST dataset******\n"
     ]
    }
   ],
   "source": [
    "import urllib.request   \n",
    "from urllib.parse import urlparse\n",
    "import gzip \n",
    "\n",
    "def unzipfile(gzip_path):\n",
    "    \"\"\"unzip dataset file\n",
    "    Args:\n",
    "        gzip_path: dataset file path\n",
    "    \"\"\"\n",
    "    open_file = open(gzip_path.replace('.gz',''), 'wb')\n",
    "    gz_file = gzip.GzipFile(gzip_path)\n",
    "    open_file.write(gz_file.read())\n",
    "    gz_file.close()\n",
    "    \n",
    "def download_dataset():\n",
    "    \"\"\"Download the dataset from http://yann.lecun.com/exdb/mnist/.\"\"\"\n",
    "    print(\"******Downloading the MNIST dataset******\")\n",
    "    train_path = \"./MNIST_Data/train/\" \n",
    "    test_path = \"./MNIST_Data/test/\"\n",
    "    train_path_check = os.path.exists(train_path)\n",
    "    test_path_check = os.path.exists(test_path)\n",
    "    if train_path_check == False and test_path_check == False:\n",
    "        os.makedirs(train_path)\n",
    "        os.makedirs(test_path)\n",
    "    train_url = {\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\"}\n",
    "    test_url = {\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"}\n",
    "    \n",
    "    for url in train_url:\n",
    "        url_parse = urlparse(url)\n",
    "        # split the file name from url\n",
    "        file_name = os.path.join(train_path,url_parse.path.split('/')[-1])\n",
    "        if not os.path.exists(file_name.replace('.gz', '')):\n",
    "            file = urllib.request.urlretrieve(url, file_name)\n",
    "            unzipfile(file_name)\n",
    "            os.remove(file_name)\n",
    "            \n",
    "    for url in test_url:\n",
    "        url_parse = urlparse(url)\n",
    "        # split the file name from url\n",
    "        file_name = os.path.join(test_path,url_parse.path.split('/')[-1])\n",
    "        if not os.path.exists(file_name.replace('.gz', '')):\n",
    "            file = urllib.request.urlretrieve(url, file_name)\n",
    "            unzipfile(file_name)\n",
    "            os.remove(file_name)\n",
    "\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样就完成了数据集的下载解压缩工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理MNIST数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们后面会采用LeNet这样的卷积神经网络对数据集进行训练，而采用LeNet在训练数据时，对数据格式是有所要求的，所以接下来的工作需要我们先查看数据集内的数据是什么样的，这样才能构造一个针对性的数据转换函数，将数据集数据转换成符合训练要求的数据形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多的LeNet网络的介绍不在此赘述，希望详细了解LeNet网络，可以查询http://yann.lecun.com/exdb/lenet/ 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看原始数据集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of mnist_ds: <class 'mindspore.dataset.engine.datasets.MnistDataset'>\n",
      "Number of pictures contained in the mnist_ds： 60000\n",
      "The item of mnist_ds: dict_keys(['image', 'label'])\n",
      "Tensor of image in item: (28, 28, 1)\n",
      "The label of item: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mindspore import context\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import mindspore.dataset as ds\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\") \n",
    "train_data_path = \"./MNIST_Data/train\"\n",
    "test_data_path = \"./MNIST_Data/test\"\n",
    "mnist_ds = ds.MnistDataset(train_data_path)\n",
    "print('The type of mnist_ds:', type(mnist_ds))\n",
    "print(\"Number of pictures contained in the mnist_ds：\",mnist_ds.get_dataset_size())\n",
    "\n",
    "dic_ds = mnist_ds.create_dict_iterator()\n",
    "item = dic_ds.get_next()\n",
    "img = item[\"image\"]\n",
    "label = item[\"label\"]\n",
    "\n",
    "print(\"The item of mnist_ds:\", item.keys())\n",
    "print(\"Tensor of image in item:\", img.shape) \n",
    "print(\"The label of item:\", label)\n",
    "\n",
    "plt.imshow(np.squeeze(img))\n",
    "plt.title(\"number:%s\"% item[\"label\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的运行情况我们可以看到,训练数据集`train-images-idx3-ubyte`和`train-labels-idx1-ubyte`对应的是6万张图片和6万个数字下标，载入数据后经过`create_dict_iterator`转换字典型的数据集，取其中的一个数据查看，这是一个key为`image`和`label`的字典，其中的`image`的张量(高度28，宽度28，通道1)和`label`为对应图片的数字。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集对于训练非常重要，好的数据集可以有效提高训练精度和效率，在加载数据集前，我们通常会对数据集进行一些处理。\n",
    "#### 定义数据集及数据操作\n",
    "我们定义一个函数`create_dataset`来创建数据集。在这个函数中，我们定义好需要进行的数据增强和处理操作：\n",
    "1. 定义数据集。\n",
    "2. 定义进行数据增强和处理所需要的一些参数。\n",
    "3. 根据参数，生成对应的数据增强操作。\n",
    "4. 使用`map`映射函数，将数据操作应用到数据集。\n",
    "5. 对生成的数据集进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset.transforms.vision.c_transforms as CV\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "from mindspore.dataset.transforms.vision import Inter\n",
    "from mindspore.common import dtype as mstype\n",
    "\n",
    "\n",
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    \"\"\" create dataset for train or test\n",
    "    Args:\n",
    "        data_path (str): Data path\n",
    "        batch_size (int): The number of data records in each group\n",
    "        repeat_size (int): The number of replicated data records\n",
    "        num_parallel_workers (int): The number of parallel workers\n",
    "    \"\"\"\n",
    "    # define dataset\n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "\n",
    "    # define some parameters needed for data enhancement and rough justification\n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "\n",
    "    # according to the parameters, generate the corresponding data enhancement method\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)\n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = C.TypeCast(mstype.int32)\n",
    "\n",
    "    # using map to apply operations to a dataset\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"label\", operations=type_cast_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=resize_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=rescale_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=rescale_nml_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=hwc2chw_op, num_parallel_workers=num_parallel_workers)\n",
    "    \n",
    "    # process the generated dataset\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    mnist_ds = mnist_ds.repeat(repeat_size)\n",
    "\n",
    "    return mnist_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中\n",
    "<br/>`batch_size`：每组包含的数据个数，现设置每组包含32个数据。\n",
    "<br/>`repeat_size`：数据集复制的数量。\n",
    "<br/>先进行`shuffle`、`batch`操作，再进行`repeat`操作，这样能保证1个`epoch`内数据不重复。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们查看将要进行训练的数据集内容是什么样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，查看数据集内包含多少组数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups in the dataset: 1875\n"
     ]
    }
   ],
   "source": [
    "datas = create_dataset(train_data_path)\n",
    "print('Number of groups in the dataset:', datas.get_dataset_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其次，取出其中一组数据，查看包含的`key`，图片数据的张量，以及下标`labels`的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['label', 'image'])\n",
      "Tensor of image: (32, 1, 32, 32)\n",
      "labels: [6 3 5 8 9 0 1 8 1 6 8 9 1 3 0 9 0 4 0 2 2 6 7 9 4 9 1 4 1 4 3 3]\n"
     ]
    }
   ],
   "source": [
    "data = datas.create_dict_iterator().get_next()\n",
    "print(data.keys())\n",
    "images = data[\"image\"] \n",
    "labels = data[\"label\"] \n",
    "print('Tensor of image:', images.shape)\n",
    "print('labels:', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，查看`image`的图像和下标对应的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 1\n",
    "for i in images:\n",
    "    plt.subplot(4, 8, count) \n",
    "    plt.imshow(np.squeeze(i))\n",
    "    plt.title('num:%s'%labels[count-1])\n",
    "    plt.xticks([])\n",
    "    count += 1\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上述三个查询操作，看到经过变换后的图片，数据集内分成了1875组数据，每组数据中含有32张图片，每张图片像数值为32×32，数据全部准备好后，就可以进行下一步的数据训练了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在对手写字体识别上，通常采用卷积神经网络架构（CNN）进行学习预测，最经典的属1998年由Yann LeCun创建的LeNet5架构，<br/>其中分为：<br/>1、输入层；<br/>2、卷积层C1；<br/>3、池化层S2；<br/>4、卷积层C3；<br/>5、池化层S4；<br/>6、全连接F6；<br/>7、全连接；<br/>8、全连接OUTPUT。<br/>结构示意如下图:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet5结构图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mindspore.cn/tutorial/zh-CN/master/_images/LeNet_5.jpg\" alt=\"LeNet5\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在构建LeNet5前，我们需要对全连接层以及卷积层进行初始化。\n",
    "\n",
    "`TruncatedNormal`：参数初始化方法，MindSpore支持`TruncatedNormal`、`Normal`、`Uniform`等多种参数初始化方法，具体可以参考MindSpore API的`mindspore.common.initializer`模块说明。\n",
    "\n",
    "初始化示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "\n",
    "# initialize 2D convolution function\n",
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    \"\"\"Conv layer weight initial.\"\"\"\n",
    "    weight = weight_variable()\n",
    "    return nn.Conv2d(in_channels, out_channels,\n",
    "                     kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                     weight_init=weight, has_bias=False, pad_mode=\"valid\")\n",
    "\n",
    "# initialize full connection layer\n",
    "def fc_with_initialize(input_channels, out_channels):\n",
    "    \"\"\"Fc layer weight initial.\"\"\"\n",
    "    weight = weight_variable()\n",
    "    bias = weight_variable()\n",
    "    return nn.Dense(input_channels, out_channels, weight, bias)\n",
    "\n",
    "# set truncated normal distribution\n",
    "def weight_variable():\n",
    "    \"\"\"Weight initial.\"\"\"\n",
    "    return TruncatedNormal(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用MindSpore定义神经网络需要继承`mindspore.nn.cell.Cell`，`Cell`是所有神经网络（`Conv2d`等）的基类。\n",
    "\n",
    "神经网络的各层需要预先在`__init__`方法中定义，然后通过定义`construct`方法来完成神经网络的前向构造，按照LeNet5的网络结构，定义网络各层如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Cell):\n",
    "    \"\"\"Lenet network structure.\"\"\"\n",
    "    # define the operator required\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.batch_size = 32\n",
    "        self.conv1 = conv(1, 6, 5)\n",
    "        self.conv2 = conv(6, 16, 5)\n",
    "        self.fc1 = fc_with_initialize(16 * 5 * 5, 120)\n",
    "        self.fc2 = fc_with_initialize(120, 84)\n",
    "        self.fc3 = fc_with_initialize(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    # use the preceding operators to construct networks\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建完成后，我们将LeNet5的整体参数打印出来查看一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5<\n",
       "  (conv1): Conv2d<input_channels=1, output_channels=6, kernel_size=(5, 5),stride=(1, 1),  pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False,weight_init=Parameter (name=conv1.weight), bias_init=None>\n",
       "  (conv2): Conv2d<input_channels=6, output_channels=16, kernel_size=(5, 5),stride=(1, 1),  pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False,weight_init=Parameter (name=conv2.weight), bias_init=None>\n",
       "  (fc1): Dense<in_channels=400, out_channels=120, weight=Parameter (name=fc1.weight), has_bias=True, bias=Parameter (name=fc1.bias)>\n",
       "  (fc2): Dense<in_channels=120, out_channels=84, weight=Parameter (name=fc2.weight), has_bias=True, bias=Parameter (name=fc2.bias)>\n",
       "  (fc3): Dense<in_channels=84, out_channels=10, weight=Parameter (name=fc3.weight), has_bias=True, bias=Parameter (name=fc3.bias)>\n",
       "  (relu): ReLU<>\n",
       "  (max_pool2d): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "  (flatten): Flatten<>\n",
       "  >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = LeNet5()\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter (name=conv1.weight),\n",
       " Parameter (name=conv2.weight),\n",
       " Parameter (name=fc1.weight),\n",
       " Parameter (name=fc1.bias),\n",
       " Parameter (name=fc2.weight),\n",
       " Parameter (name=fc2.bias),\n",
       " Parameter (name=fc3.weight),\n",
       " Parameter (name=fc3.bias)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = network.trainable_params()\n",
    "param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建训练网络并进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建完成神经网络后，就可以着手进行训练网络的构建，模型训练函数为`Model.train`，参数主要包含：\n",
    "1. 圈数`epoch size`（每圈需要遍历完成1875组图片）；\n",
    "2. 数据集`ds_train`；\n",
    "3. 回调函数`callbacks`包含`ModelCheckpoint`、`LossMonitor`和`Callback`模型检测参数；\n",
    "4. 数据下沉模式`dataset_sink_mode`，此参数默认`True`需设置成`False`，因为此功能不支持CPU模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training related modules\n",
    "from mindspore import Tensor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor,Callback\n",
    "from mindspore.train import Model\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "\n",
    "def train_net(model, epoch_size, mnist_path, repeat_size, ckpoint_cb, step_loss_info):\n",
    "    \"\"\"Define the training method.\"\"\"\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    # load training dataset\n",
    "    ds_train = create_dataset(os.path.join(mnist_path, \"train\"), 32, repeat_size)\n",
    "    model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, LossMonitor(), step_loss_info], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义一个存储每一步训练的`step`和对应loss值的类`Step_loss_info`，并继承了`Callback`类，可以自定义训练过程中的处理措施，非常方便，等训练完成后，可将数据绘图查看loss的变化情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom callback function\n",
    "class StepLossInfo(Callback):\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        # step_loss dictionary for saving loss value and step number information\n",
    "        step_loss[\"loss_value\"].append(str(cb_params.net_outputs))\n",
    "        step_loss[\"step\"].append(str(cb_params.cur_step_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数及优化器\n",
    "\n",
    "在进行定义之前，先简单介绍损失函数及优化器的概念。\n",
    "\n",
    "损失函数：又叫目标函数，用于衡量预测值与实际值差异的程度。深度学习通过不停地迭代来缩小损失函数的值。定义一个好的损失函数，可以有效提高模型的性能。\n",
    "\n",
    "优化器：用于最小化损失函数，从而在训练过程中改进模型。\n",
    "\n",
    "定义了损失函数后，可以得到损失函数关于权重的梯度。梯度用于指示优化器优化权重的方向，以提高模型性能。\n",
    "\n",
    "定义损失函数。\n",
    "\n",
    "MindSpore支持的损失函数有`SoftmaxCrossEntropyWithLogits`、`L1Loss`、`MSELoss`等。这里使用`SoftmaxCrossEntropyWithLogits`损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step 1, loss is 2.3036417961120605\n",
      "epoch: 1 step 2, loss is 2.298630714416504\n",
      "epoch: 1 step 3, loss is 2.302391529083252\n",
      "epoch: 1 step 4, loss is 2.304328441619873\n",
      "epoch: 1 step 5, loss is 2.3027987480163574\n",
      "epoch: 1 step 6, loss is 2.2987725734710693\n",
      "epoch: 1 step 7, loss is 2.298673629760742\n",
      "epoch: 1 step 8, loss is 2.30534029006958\n",
      "epoch: 1 step 9, loss is 2.303036689758301\n",
      "epoch: 1 step 10, loss is 2.2993321418762207\n",
      "epoch: 1 step 11, loss is 2.305026054382324\n",
      "epoch: 1 step 12, loss is 2.302748918533325\n",
      "epoch: 1 step 13, loss is 2.3028924465179443\n",
      "epoch: 1 step 14, loss is 2.2981364727020264\n",
      "epoch: 1 step 15, loss is 2.3044252395629883\n",
      "epoch: 1 step 16, loss is 2.2937963008880615\n",
      "epoch: 1 step 17, loss is 2.302947759628296\n",
      "epoch: 1 step 18, loss is 2.301767587661743\n",
      "epoch: 1 step 19, loss is 2.302520275115967\n",
      "epoch: 1 step 20, loss is 2.2997517585754395\n",
      "epoch: 1 step 21, loss is 2.300358533859253\n",
      "epoch: 1 step 22, loss is 2.296435832977295\n",
      "epoch: 1 step 23, loss is 2.3037216663360596\n",
      "epoch: 1 step 24, loss is 2.3002805709838867\n",
      "epoch: 1 step 25, loss is 2.3053646087646484\n",
      "epoch: 1 step 26, loss is 2.296821355819702\n",
      "epoch: 1 step 27, loss is 2.2995078563690186\n",
      "epoch: 1 step 28, loss is 2.305546760559082\n",
      "epoch: 1 step 29, loss is 2.305027484893799\n",
      "epoch: 1 step 30, loss is 2.3053534030914307\n",
      "epoch: 1 step 31, loss is 2.3146908283233643\n",
      "epoch: 1 step 32, loss is 2.2932584285736084\n",
      "epoch: 1 step 33, loss is 2.303548574447632\n",
      "epoch: 1 step 34, loss is 2.3062822818756104\n",
      "epoch: 1 step 35, loss is 2.307175397872925\n",
      "epoch: 1 step 36, loss is 2.3170557022094727\n",
      "epoch: 1 step 37, loss is 2.29900860786438\n",
      "epoch: 1 step 38, loss is 2.301845073699951\n",
      "epoch: 1 step 39, loss is 2.2978885173797607\n",
      "epoch: 1 step 40, loss is 2.3042001724243164\n",
      "epoch: 1 step 41, loss is 2.303277015686035\n",
      "epoch: 1 step 42, loss is 2.2995805740356445\n",
      "epoch: 1 step 43, loss is 2.307396411895752\n",
      "epoch: 1 step 44, loss is 2.3049159049987793\n",
      "epoch: 1 step 45, loss is 2.304211378097534\n",
      "epoch: 1 step 46, loss is 2.300304651260376\n",
      "epoch: 1 step 47, loss is 2.30509614944458\n",
      "epoch: 1 step 48, loss is 2.2977967262268066\n",
      "epoch: 1 step 49, loss is 2.2965590953826904\n",
      "epoch: 1 step 50, loss is 2.300846815109253\n",
      "epoch: 1 step 51, loss is 2.3011419773101807\n",
      "epoch: 1 step 52, loss is 2.291372537612915\n",
      "epoch: 1 step 53, loss is 2.3017473220825195\n",
      "epoch: 1 step 54, loss is 2.302234649658203\n",
      "epoch: 1 step 55, loss is 2.3049476146698\n",
      "epoch: 1 step 56, loss is 2.296499252319336\n",
      "epoch: 1 step 57, loss is 2.3119330406188965\n",
      "epoch: 1 step 58, loss is 2.29875111579895\n",
      "epoch: 1 step 59, loss is 2.299650192260742\n",
      "epoch: 1 step 60, loss is 2.295192241668701\n",
      "epoch: 1 step 61, loss is 2.2914061546325684\n",
      "epoch: 1 step 62, loss is 2.312401294708252\n",
      "epoch: 1 step 63, loss is 2.3097002506256104\n",
      "epoch: 1 step 64, loss is 2.299806594848633\n",
      "epoch: 1 step 65, loss is 2.302612543106079\n",
      "epoch: 1 step 66, loss is 2.2979307174682617\n",
      "epoch: 1 step 67, loss is 2.31546950340271\n",
      "epoch: 1 step 68, loss is 2.3103079795837402\n",
      "epoch: 1 step 69, loss is 2.309143304824829\n",
      "epoch: 1 step 70, loss is 2.305349349975586\n",
      "epoch: 1 step 71, loss is 2.3021116256713867\n",
      "epoch: 1 step 72, loss is 2.302931547164917\n",
      "epoch: 1 step 73, loss is 2.299171209335327\n",
      "epoch: 1 step 74, loss is 2.3023552894592285\n",
      "epoch: 1 step 75, loss is 2.297666311264038\n",
      "epoch: 1 step 76, loss is 2.2955446243286133\n",
      "epoch: 1 step 77, loss is 2.303368091583252\n",
      "epoch: 1 step 78, loss is 2.2970433235168457\n",
      "epoch: 1 step 79, loss is 2.3118627071380615\n",
      "epoch: 1 step 80, loss is 2.2917704582214355\n",
      "epoch: 1 step 81, loss is 2.3150627613067627\n",
      "epoch: 1 step 82, loss is 2.3017776012420654\n",
      "epoch: 1 step 83, loss is 2.3065297603607178\n",
      "epoch: 1 step 84, loss is 2.318979024887085\n",
      "epoch: 1 step 85, loss is 2.3001444339752197\n",
      "epoch: 1 step 86, loss is 2.3014917373657227\n",
      "epoch: 1 step 87, loss is 2.309880018234253\n",
      "epoch: 1 step 88, loss is 2.294804096221924\n",
      "epoch: 1 step 89, loss is 2.3006980419158936\n",
      "epoch: 1 step 90, loss is 2.308440685272217\n",
      "epoch: 1 step 91, loss is 2.3000504970550537\n",
      "epoch: 1 step 92, loss is 2.3011293411254883\n",
      "epoch: 1 step 93, loss is 2.3041226863861084\n",
      "epoch: 1 step 94, loss is 2.289018392562866\n",
      "epoch: 1 step 95, loss is 2.3014912605285645\n",
      "epoch: 1 step 96, loss is 2.302461862564087\n",
      "epoch: 1 step 97, loss is 2.3085408210754395\n",
      "epoch: 1 step 98, loss is 2.296156167984009\n",
      "epoch: 1 step 99, loss is 2.29742169380188\n",
      "epoch: 1 step 100, loss is 2.304044246673584\n",
      "epoch: 1 step 101, loss is 2.3033947944641113\n",
      "epoch: 1 step 102, loss is 2.304230213165283\n",
      "epoch: 1 step 103, loss is 2.306795358657837\n",
      "epoch: 1 step 104, loss is 2.3009331226348877\n",
      "epoch: 1 step 105, loss is 2.2976226806640625\n",
      "epoch: 1 step 106, loss is 2.294156551361084\n",
      "epoch: 1 step 107, loss is 2.299952507019043\n",
      "epoch: 1 step 108, loss is 2.309349298477173\n",
      "epoch: 1 step 109, loss is 2.300881862640381\n",
      "epoch: 1 step 110, loss is 2.311763048171997\n",
      "epoch: 1 step 111, loss is 2.3041746616363525\n",
      "epoch: 1 step 112, loss is 2.296386241912842\n",
      "epoch: 1 step 113, loss is 2.3057456016540527\n",
      "epoch: 1 step 114, loss is 2.2932939529418945\n",
      "epoch: 1 step 115, loss is 2.3116936683654785\n",
      "epoch: 1 step 116, loss is 2.2911524772644043\n",
      "epoch: 1 step 117, loss is 2.3195571899414062\n",
      "epoch: 1 step 118, loss is 2.3009743690490723\n",
      "epoch: 1 step 119, loss is 2.2873072624206543\n",
      "epoch: 1 step 120, loss is 2.3133697509765625\n",
      "epoch: 1 step 121, loss is 2.30419659614563\n",
      "epoch: 1 step 122, loss is 2.2948532104492188\n",
      "epoch: 1 step 123, loss is 2.3005154132843018\n",
      "epoch: 1 step 124, loss is 2.302123785018921\n",
      "epoch: 1 step 125, loss is 2.3159165382385254\n",
      "epoch: 1 step 126, loss is 2.299440383911133\n",
      "epoch: 1 step 127, loss is 2.294107437133789\n",
      "epoch: 1 step 128, loss is 2.3011081218719482\n",
      "epoch: 1 step 129, loss is 2.2969794273376465\n",
      "epoch: 1 step 130, loss is 2.3207995891571045\n",
      "epoch: 1 step 131, loss is 2.312513589859009\n",
      "epoch: 1 step 132, loss is 2.3004298210144043\n",
      "epoch: 1 step 133, loss is 2.3079676628112793\n",
      "epoch: 1 step 134, loss is 2.291200637817383\n",
      "epoch: 1 step 135, loss is 2.3006200790405273\n",
      "epoch: 1 step 136, loss is 2.310053586959839\n",
      "epoch: 1 step 137, loss is 2.305415630340576\n",
      "epoch: 1 step 138, loss is 2.2974250316619873\n",
      "epoch: 1 step 139, loss is 2.3018136024475098\n",
      "epoch: 1 step 140, loss is 2.2954070568084717\n",
      "epoch: 1 step 141, loss is 2.3027243614196777\n",
      "epoch: 1 step 142, loss is 2.3045427799224854\n",
      "epoch: 1 step 143, loss is 2.2927889823913574\n",
      "epoch: 1 step 144, loss is 2.3079490661621094\n",
      "epoch: 1 step 145, loss is 2.308187484741211\n",
      "epoch: 1 step 146, loss is 2.2903213500976562\n",
      "epoch: 1 step 147, loss is 2.3045201301574707\n",
      "epoch: 1 step 148, loss is 2.2987563610076904\n",
      "epoch: 1 step 149, loss is 2.3156399726867676\n",
      "epoch: 1 step 150, loss is 2.298570394515991\n",
      "epoch: 1 step 151, loss is 2.328263521194458\n",
      "epoch: 1 step 152, loss is 2.3073980808258057\n",
      "epoch: 1 step 153, loss is 2.29105281829834\n",
      "epoch: 1 step 154, loss is 2.3087775707244873\n",
      "epoch: 1 step 155, loss is 2.308013439178467\n",
      "epoch: 1 step 156, loss is 2.3050355911254883\n",
      "epoch: 1 step 157, loss is 2.292358636856079\n",
      "epoch: 1 step 158, loss is 2.3048012256622314\n",
      "epoch: 1 step 159, loss is 2.3068573474884033\n",
      "epoch: 1 step 160, loss is 2.3111112117767334\n",
      "epoch: 1 step 161, loss is 2.2875633239746094\n",
      "epoch: 1 step 162, loss is 2.2821505069732666\n",
      "epoch: 1 step 163, loss is 2.2968549728393555\n",
      "epoch: 1 step 164, loss is 2.283661127090454\n",
      "epoch: 1 step 165, loss is 2.305659532546997\n",
      "epoch: 1 step 166, loss is 2.302140712738037\n",
      "epoch: 1 step 167, loss is 2.295464038848877\n",
      "epoch: 1 step 168, loss is 2.279547691345215\n",
      "epoch: 1 step 169, loss is 2.2998762130737305\n",
      "epoch: 1 step 170, loss is 2.2972824573516846\n",
      "epoch: 1 step 171, loss is 2.306971549987793\n",
      "epoch: 1 step 172, loss is 2.3028149604797363\n",
      "epoch: 1 step 173, loss is 2.2961080074310303\n",
      "epoch: 1 step 174, loss is 2.306591033935547\n",
      "epoch: 1 step 175, loss is 2.294856309890747\n",
      "epoch: 1 step 176, loss is 2.3139917850494385\n",
      "epoch: 1 step 177, loss is 2.3160483837127686\n",
      "epoch: 1 step 178, loss is 2.288738250732422\n",
      "epoch: 1 step 179, loss is 2.3248589038848877\n",
      "epoch: 1 step 180, loss is 2.2906830310821533\n",
      "epoch: 1 step 181, loss is 2.295781373977661\n",
      "epoch: 1 step 182, loss is 2.2896437644958496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 183, loss is 2.309624433517456\n",
      "epoch: 1 step 184, loss is 2.323194742202759\n",
      "epoch: 1 step 185, loss is 2.311706781387329\n",
      "epoch: 1 step 186, loss is 2.3111326694488525\n",
      "epoch: 1 step 187, loss is 2.3091180324554443\n",
      "epoch: 1 step 188, loss is 2.2965402603149414\n",
      "epoch: 1 step 189, loss is 2.295259475708008\n",
      "epoch: 1 step 190, loss is 2.296231269836426\n",
      "epoch: 1 step 191, loss is 2.303983211517334\n",
      "epoch: 1 step 192, loss is 2.306814432144165\n",
      "epoch: 1 step 193, loss is 2.2905185222625732\n",
      "epoch: 1 step 194, loss is 2.308838367462158\n",
      "epoch: 1 step 195, loss is 2.2948405742645264\n",
      "epoch: 1 step 196, loss is 2.298696994781494\n",
      "epoch: 1 step 197, loss is 2.2964284420013428\n",
      "epoch: 1 step 198, loss is 2.3125040531158447\n",
      "epoch: 1 step 199, loss is 2.2885444164276123\n",
      "epoch: 1 step 200, loss is 2.306826114654541\n",
      "epoch: 1 step 201, loss is 2.309328079223633\n",
      "epoch: 1 step 202, loss is 2.2883524894714355\n",
      "epoch: 1 step 203, loss is 2.304533004760742\n",
      "epoch: 1 step 204, loss is 2.301948308944702\n",
      "epoch: 1 step 205, loss is 2.3106493949890137\n",
      "epoch: 1 step 206, loss is 2.305791139602661\n",
      "epoch: 1 step 207, loss is 2.3050265312194824\n",
      "epoch: 1 step 208, loss is 2.2933125495910645\n",
      "epoch: 1 step 209, loss is 2.30745792388916\n",
      "epoch: 1 step 210, loss is 2.312147855758667\n",
      "epoch: 1 step 211, loss is 2.3021814823150635\n",
      "epoch: 1 step 212, loss is 2.282095432281494\n",
      "epoch: 1 step 213, loss is 2.2988312244415283\n",
      "epoch: 1 step 214, loss is 2.299859046936035\n",
      "epoch: 1 step 215, loss is 2.2955031394958496\n",
      "epoch: 1 step 216, loss is 2.288876533508301\n",
      "epoch: 1 step 217, loss is 2.2997374534606934\n",
      "epoch: 1 step 218, loss is 2.2835824489593506\n",
      "epoch: 1 step 219, loss is 2.3038642406463623\n",
      "epoch: 1 step 220, loss is 2.298015594482422\n",
      "epoch: 1 step 221, loss is 2.2944860458374023\n",
      "epoch: 1 step 222, loss is 2.2981929779052734\n",
      "epoch: 1 step 223, loss is 2.3046724796295166\n",
      "epoch: 1 step 224, loss is 2.3166990280151367\n",
      "epoch: 1 step 225, loss is 2.2997946739196777\n",
      "epoch: 1 step 226, loss is 2.2982776165008545\n",
      "epoch: 1 step 227, loss is 2.304516553878784\n",
      "epoch: 1 step 228, loss is 2.294159173965454\n",
      "epoch: 1 step 229, loss is 2.2979888916015625\n",
      "epoch: 1 step 230, loss is 2.3228976726531982\n",
      "epoch: 1 step 231, loss is 2.300828695297241\n",
      "epoch: 1 step 232, loss is 2.3062961101531982\n",
      "epoch: 1 step 233, loss is 2.3068461418151855\n",
      "epoch: 1 step 234, loss is 2.2954905033111572\n",
      "epoch: 1 step 235, loss is 2.315176486968994\n",
      "epoch: 1 step 236, loss is 2.2987992763519287\n",
      "epoch: 1 step 237, loss is 2.3124282360076904\n",
      "epoch: 1 step 238, loss is 2.298109292984009\n",
      "epoch: 1 step 239, loss is 2.305518865585327\n",
      "epoch: 1 step 240, loss is 2.302560329437256\n",
      "epoch: 1 step 241, loss is 2.303983211517334\n",
      "epoch: 1 step 242, loss is 2.320657253265381\n",
      "epoch: 1 step 243, loss is 2.3005549907684326\n",
      "epoch: 1 step 244, loss is 2.2985103130340576\n",
      "epoch: 1 step 245, loss is 2.304802894592285\n",
      "epoch: 1 step 246, loss is 2.300941228866577\n",
      "epoch: 1 step 247, loss is 2.323657989501953\n",
      "epoch: 1 step 248, loss is 2.286917209625244\n",
      "epoch: 1 step 249, loss is 2.3042843341827393\n",
      "epoch: 1 step 250, loss is 2.3197810649871826\n",
      "epoch: 1 step 251, loss is 2.2893900871276855\n",
      "epoch: 1 step 252, loss is 2.301969289779663\n",
      "epoch: 1 step 253, loss is 2.311122417449951\n",
      "epoch: 1 step 254, loss is 2.2994332313537598\n",
      "epoch: 1 step 255, loss is 2.306812047958374\n",
      "epoch: 1 step 256, loss is 2.303797721862793\n",
      "epoch: 1 step 257, loss is 2.3182919025421143\n",
      "epoch: 1 step 258, loss is 2.2994771003723145\n",
      "epoch: 1 step 259, loss is 2.2922940254211426\n",
      "epoch: 1 step 260, loss is 2.2942943572998047\n",
      "epoch: 1 step 261, loss is 2.311457395553589\n",
      "epoch: 1 step 262, loss is 2.3056118488311768\n",
      "epoch: 1 step 263, loss is 2.2893776893615723\n",
      "epoch: 1 step 264, loss is 2.3056020736694336\n",
      "epoch: 1 step 265, loss is 2.300929307937622\n",
      "epoch: 1 step 266, loss is 2.2821691036224365\n",
      "epoch: 1 step 267, loss is 2.3025898933410645\n",
      "epoch: 1 step 268, loss is 2.3109312057495117\n",
      "epoch: 1 step 269, loss is 2.3037710189819336\n",
      "epoch: 1 step 270, loss is 2.300994873046875\n",
      "epoch: 1 step 271, loss is 2.3064684867858887\n",
      "epoch: 1 step 272, loss is 2.306129217147827\n",
      "epoch: 1 step 273, loss is 2.302043914794922\n",
      "epoch: 1 step 274, loss is 2.2923431396484375\n",
      "epoch: 1 step 275, loss is 2.301884889602661\n",
      "epoch: 1 step 276, loss is 2.291098117828369\n",
      "epoch: 1 step 277, loss is 2.3073880672454834\n",
      "epoch: 1 step 278, loss is 2.3108322620391846\n",
      "epoch: 1 step 279, loss is 2.3005025386810303\n",
      "epoch: 1 step 280, loss is 2.309103012084961\n",
      "epoch: 1 step 281, loss is 2.31179141998291\n",
      "epoch: 1 step 282, loss is 2.277594566345215\n",
      "epoch: 1 step 283, loss is 2.31227707862854\n",
      "epoch: 1 step 284, loss is 2.290104627609253\n",
      "epoch: 1 step 285, loss is 2.3200223445892334\n",
      "epoch: 1 step 286, loss is 2.297940254211426\n",
      "epoch: 1 step 287, loss is 2.2998781204223633\n",
      "epoch: 1 step 288, loss is 2.3022446632385254\n",
      "epoch: 1 step 289, loss is 2.32137131690979\n",
      "epoch: 1 step 290, loss is 2.303280830383301\n",
      "epoch: 1 step 291, loss is 2.298297166824341\n",
      "epoch: 1 step 292, loss is 2.306844472885132\n",
      "epoch: 1 step 293, loss is 2.3117358684539795\n",
      "epoch: 1 step 294, loss is 2.299665927886963\n",
      "epoch: 1 step 295, loss is 2.305180788040161\n",
      "epoch: 1 step 296, loss is 2.3082194328308105\n",
      "epoch: 1 step 297, loss is 2.3148446083068848\n",
      "epoch: 1 step 298, loss is 2.304473400115967\n",
      "epoch: 1 step 299, loss is 2.2927048206329346\n",
      "epoch: 1 step 300, loss is 2.297117233276367\n",
      "epoch: 1 step 301, loss is 2.301973581314087\n",
      "epoch: 1 step 302, loss is 2.299013614654541\n",
      "epoch: 1 step 303, loss is 2.3000245094299316\n",
      "epoch: 1 step 304, loss is 2.311347484588623\n",
      "epoch: 1 step 305, loss is 2.3053359985351562\n",
      "epoch: 1 step 306, loss is 2.3081910610198975\n",
      "epoch: 1 step 307, loss is 2.3169445991516113\n",
      "epoch: 1 step 308, loss is 2.297750949859619\n",
      "epoch: 1 step 309, loss is 2.30489444732666\n",
      "epoch: 1 step 310, loss is 2.29947829246521\n",
      "epoch: 1 step 311, loss is 2.301111936569214\n",
      "epoch: 1 step 312, loss is 2.322146415710449\n",
      "epoch: 1 step 313, loss is 2.3110451698303223\n",
      "epoch: 1 step 314, loss is 2.3123786449432373\n",
      "epoch: 1 step 315, loss is 2.3374645709991455\n",
      "epoch: 1 step 316, loss is 2.3028552532196045\n",
      "epoch: 1 step 317, loss is 2.2909250259399414\n",
      "epoch: 1 step 318, loss is 2.3044238090515137\n",
      "epoch: 1 step 319, loss is 2.295652389526367\n",
      "epoch: 1 step 320, loss is 2.3132457733154297\n",
      "epoch: 1 step 321, loss is 2.299982786178589\n",
      "epoch: 1 step 322, loss is 2.2876060009002686\n",
      "epoch: 1 step 323, loss is 2.305941343307495\n",
      "epoch: 1 step 324, loss is 2.287879705429077\n",
      "epoch: 1 step 325, loss is 2.2931158542633057\n",
      "epoch: 1 step 326, loss is 2.3060152530670166\n",
      "epoch: 1 step 327, loss is 2.3094165325164795\n",
      "epoch: 1 step 328, loss is 2.2952308654785156\n",
      "epoch: 1 step 329, loss is 2.301609516143799\n",
      "epoch: 1 step 330, loss is 2.3078248500823975\n",
      "epoch: 1 step 331, loss is 2.307288408279419\n",
      "epoch: 1 step 332, loss is 2.3012943267822266\n",
      "epoch: 1 step 333, loss is 2.2988827228546143\n",
      "epoch: 1 step 334, loss is 2.293768882751465\n",
      "epoch: 1 step 335, loss is 2.3158555030822754\n",
      "epoch: 1 step 336, loss is 2.323178768157959\n",
      "epoch: 1 step 337, loss is 2.309025526046753\n",
      "epoch: 1 step 338, loss is 2.3028969764709473\n",
      "epoch: 1 step 339, loss is 2.2952795028686523\n",
      "epoch: 1 step 340, loss is 2.307999610900879\n",
      "epoch: 1 step 341, loss is 2.297755479812622\n",
      "epoch: 1 step 342, loss is 2.3044004440307617\n",
      "epoch: 1 step 343, loss is 2.288539409637451\n",
      "epoch: 1 step 344, loss is 2.2831764221191406\n",
      "epoch: 1 step 345, loss is 2.2872886657714844\n",
      "epoch: 1 step 346, loss is 2.306870460510254\n",
      "epoch: 1 step 347, loss is 2.312478542327881\n",
      "epoch: 1 step 348, loss is 2.2926058769226074\n",
      "epoch: 1 step 349, loss is 2.309343099594116\n",
      "epoch: 1 step 350, loss is 2.291848659515381\n",
      "epoch: 1 step 351, loss is 2.3049778938293457\n",
      "epoch: 1 step 352, loss is 2.305189371109009\n",
      "epoch: 1 step 353, loss is 2.294496774673462\n",
      "epoch: 1 step 354, loss is 2.308093309402466\n",
      "epoch: 1 step 355, loss is 2.3015782833099365\n",
      "epoch: 1 step 356, loss is 2.2906839847564697\n",
      "epoch: 1 step 357, loss is 2.305084705352783\n",
      "epoch: 1 step 358, loss is 2.310594081878662\n",
      "epoch: 1 step 359, loss is 2.291069507598877\n",
      "epoch: 1 step 360, loss is 2.299825668334961\n",
      "epoch: 1 step 361, loss is 2.3010685443878174\n",
      "epoch: 1 step 362, loss is 2.299398183822632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 363, loss is 2.316545009613037\n",
      "epoch: 1 step 364, loss is 2.2973861694335938\n",
      "epoch: 1 step 365, loss is 2.298579454421997\n",
      "epoch: 1 step 366, loss is 2.299386978149414\n",
      "epoch: 1 step 367, loss is 2.28235125541687\n",
      "epoch: 1 step 368, loss is 2.312197208404541\n",
      "epoch: 1 step 369, loss is 2.3015496730804443\n",
      "epoch: 1 step 370, loss is 2.306972026824951\n",
      "epoch: 1 step 371, loss is 2.300973892211914\n",
      "epoch: 1 step 372, loss is 2.2951574325561523\n",
      "epoch: 1 step 373, loss is 2.297781467437744\n",
      "epoch: 1 step 374, loss is 2.2964324951171875\n",
      "epoch: 1 step 375, loss is 2.3094630241394043\n",
      "epoch: 1 step 376, loss is 2.3110594749450684\n",
      "epoch: 1 step 377, loss is 2.316398859024048\n",
      "epoch: 1 step 378, loss is 2.2969913482666016\n",
      "epoch: 1 step 379, loss is 2.2993545532226562\n",
      "epoch: 1 step 380, loss is 2.2793471813201904\n",
      "epoch: 1 step 381, loss is 2.321284294128418\n",
      "epoch: 1 step 382, loss is 2.308730363845825\n",
      "epoch: 1 step 383, loss is 2.311279773712158\n",
      "epoch: 1 step 384, loss is 2.2807345390319824\n",
      "epoch: 1 step 385, loss is 2.298273801803589\n",
      "epoch: 1 step 386, loss is 2.2840373516082764\n",
      "epoch: 1 step 387, loss is 2.302661657333374\n",
      "epoch: 1 step 388, loss is 2.2877776622772217\n",
      "epoch: 1 step 389, loss is 2.2820465564727783\n",
      "epoch: 1 step 390, loss is 2.3102872371673584\n",
      "epoch: 1 step 391, loss is 2.3036928176879883\n",
      "epoch: 1 step 392, loss is 2.3042521476745605\n",
      "epoch: 1 step 393, loss is 2.3074333667755127\n",
      "epoch: 1 step 394, loss is 2.3111190795898438\n",
      "epoch: 1 step 395, loss is 2.294706106185913\n",
      "epoch: 1 step 396, loss is 2.2674827575683594\n",
      "epoch: 1 step 397, loss is 2.317141056060791\n",
      "epoch: 1 step 398, loss is 2.307194471359253\n",
      "epoch: 1 step 399, loss is 2.3064684867858887\n",
      "epoch: 1 step 400, loss is 2.29667067527771\n",
      "epoch: 1 step 401, loss is 2.316262722015381\n",
      "epoch: 1 step 402, loss is 2.2922985553741455\n",
      "epoch: 1 step 403, loss is 2.30635666847229\n",
      "epoch: 1 step 404, loss is 2.293581008911133\n",
      "epoch: 1 step 405, loss is 2.3163130283355713\n",
      "epoch: 1 step 406, loss is 2.2864110469818115\n",
      "epoch: 1 step 407, loss is 2.292649269104004\n",
      "epoch: 1 step 408, loss is 2.3108510971069336\n",
      "epoch: 1 step 409, loss is 2.3138904571533203\n",
      "epoch: 1 step 410, loss is 2.3124492168426514\n",
      "epoch: 1 step 411, loss is 2.286383867263794\n",
      "epoch: 1 step 412, loss is 2.305741310119629\n",
      "epoch: 1 step 413, loss is 2.328089952468872\n",
      "epoch: 1 step 414, loss is 2.2838659286499023\n",
      "epoch: 1 step 415, loss is 2.297269582748413\n",
      "epoch: 1 step 416, loss is 2.3035154342651367\n",
      "epoch: 1 step 417, loss is 2.327326536178589\n",
      "epoch: 1 step 418, loss is 2.310253381729126\n",
      "epoch: 1 step 419, loss is 2.3029470443725586\n",
      "epoch: 1 step 420, loss is 2.319157123565674\n",
      "epoch: 1 step 421, loss is 2.280348777770996\n",
      "epoch: 1 step 422, loss is 2.3144636154174805\n",
      "epoch: 1 step 423, loss is 2.309483766555786\n",
      "epoch: 1 step 424, loss is 2.305119752883911\n",
      "epoch: 1 step 425, loss is 2.293011426925659\n",
      "epoch: 1 step 426, loss is 2.3073065280914307\n",
      "epoch: 1 step 427, loss is 2.2898974418640137\n",
      "epoch: 1 step 428, loss is 2.2863576412200928\n",
      "epoch: 1 step 429, loss is 2.3259050846099854\n",
      "epoch: 1 step 430, loss is 2.293931245803833\n",
      "epoch: 1 step 431, loss is 2.3190293312072754\n",
      "epoch: 1 step 432, loss is 2.3019421100616455\n",
      "epoch: 1 step 433, loss is 2.29414963722229\n",
      "epoch: 1 step 434, loss is 2.3056304454803467\n",
      "epoch: 1 step 435, loss is 2.297004461288452\n",
      "epoch: 1 step 436, loss is 2.3015122413635254\n",
      "epoch: 1 step 437, loss is 2.3112151622772217\n",
      "epoch: 1 step 438, loss is 2.3200738430023193\n",
      "epoch: 1 step 439, loss is 2.2920126914978027\n",
      "epoch: 1 step 440, loss is 2.3166749477386475\n",
      "epoch: 1 step 441, loss is 2.3098225593566895\n",
      "epoch: 1 step 442, loss is 2.3176872730255127\n",
      "epoch: 1 step 443, loss is 2.2913010120391846\n",
      "epoch: 1 step 444, loss is 2.304748296737671\n",
      "epoch: 1 step 445, loss is 2.30777645111084\n",
      "epoch: 1 step 446, loss is 2.301826238632202\n",
      "epoch: 1 step 447, loss is 2.3115742206573486\n",
      "epoch: 1 step 448, loss is 2.2836520671844482\n",
      "epoch: 1 step 449, loss is 2.3101956844329834\n",
      "epoch: 1 step 450, loss is 2.3099701404571533\n",
      "epoch: 1 step 451, loss is 2.2856247425079346\n",
      "epoch: 1 step 452, loss is 2.301503896713257\n",
      "epoch: 1 step 453, loss is 2.30840802192688\n",
      "epoch: 1 step 454, loss is 2.294261932373047\n",
      "epoch: 1 step 455, loss is 2.306784152984619\n",
      "epoch: 1 step 456, loss is 2.312567949295044\n",
      "epoch: 1 step 457, loss is 2.301384687423706\n",
      "epoch: 1 step 458, loss is 2.3095791339874268\n",
      "epoch: 1 step 459, loss is 2.30721378326416\n",
      "epoch: 1 step 460, loss is 2.2918553352355957\n",
      "epoch: 1 step 461, loss is 2.297912836074829\n",
      "epoch: 1 step 462, loss is 2.293703317642212\n",
      "epoch: 1 step 463, loss is 2.3068270683288574\n",
      "epoch: 1 step 464, loss is 2.308913469314575\n",
      "epoch: 1 step 465, loss is 2.2927842140197754\n",
      "epoch: 1 step 466, loss is 2.298229217529297\n",
      "epoch: 1 step 467, loss is 2.3053324222564697\n",
      "epoch: 1 step 468, loss is 2.311330795288086\n",
      "epoch: 1 step 469, loss is 2.3048853874206543\n",
      "epoch: 1 step 470, loss is 2.3125648498535156\n",
      "epoch: 1 step 471, loss is 2.291192054748535\n",
      "epoch: 1 step 472, loss is 2.304387092590332\n",
      "epoch: 1 step 473, loss is 2.2949419021606445\n",
      "epoch: 1 step 474, loss is 2.292856454849243\n",
      "epoch: 1 step 475, loss is 2.3045504093170166\n",
      "epoch: 1 step 476, loss is 2.3035783767700195\n",
      "epoch: 1 step 477, loss is 2.3078746795654297\n",
      "epoch: 1 step 478, loss is 2.2975947856903076\n",
      "epoch: 1 step 479, loss is 2.2870256900787354\n",
      "epoch: 1 step 480, loss is 2.3047573566436768\n",
      "epoch: 1 step 481, loss is 2.288184881210327\n",
      "epoch: 1 step 482, loss is 2.29794979095459\n",
      "epoch: 1 step 483, loss is 2.3161563873291016\n",
      "epoch: 1 step 484, loss is 2.3217427730560303\n",
      "epoch: 1 step 485, loss is 2.31135892868042\n",
      "epoch: 1 step 486, loss is 2.2933225631713867\n",
      "epoch: 1 step 487, loss is 2.2972028255462646\n",
      "epoch: 1 step 488, loss is 2.3297030925750732\n",
      "epoch: 1 step 489, loss is 2.3047773838043213\n",
      "epoch: 1 step 490, loss is 2.2950005531311035\n",
      "epoch: 1 step 491, loss is 2.301220655441284\n",
      "epoch: 1 step 492, loss is 2.294806480407715\n",
      "epoch: 1 step 493, loss is 2.3060131072998047\n",
      "epoch: 1 step 494, loss is 2.2895150184631348\n",
      "epoch: 1 step 495, loss is 2.3064186573028564\n",
      "epoch: 1 step 496, loss is 2.2900142669677734\n",
      "epoch: 1 step 497, loss is 2.3137834072113037\n",
      "epoch: 1 step 498, loss is 2.2951085567474365\n",
      "epoch: 1 step 499, loss is 2.2993836402893066\n",
      "epoch: 1 step 500, loss is 2.292905330657959\n",
      "epoch: 1 step 501, loss is 2.3023834228515625\n",
      "epoch: 1 step 502, loss is 2.3147432804107666\n",
      "epoch: 1 step 503, loss is 2.299447536468506\n",
      "epoch: 1 step 504, loss is 2.306694984436035\n",
      "epoch: 1 step 505, loss is 2.3031160831451416\n",
      "epoch: 1 step 506, loss is 2.2977864742279053\n",
      "epoch: 1 step 507, loss is 2.308394432067871\n",
      "epoch: 1 step 508, loss is 2.3073339462280273\n",
      "epoch: 1 step 509, loss is 2.3020577430725098\n",
      "epoch: 1 step 510, loss is 2.3010921478271484\n",
      "epoch: 1 step 511, loss is 2.300612688064575\n",
      "epoch: 1 step 512, loss is 2.299712657928467\n",
      "epoch: 1 step 513, loss is 2.302595853805542\n",
      "epoch: 1 step 514, loss is 2.2898383140563965\n",
      "epoch: 1 step 515, loss is 2.3039684295654297\n",
      "epoch: 1 step 516, loss is 2.292846202850342\n",
      "epoch: 1 step 517, loss is 2.291675329208374\n",
      "epoch: 1 step 518, loss is 2.309509038925171\n",
      "epoch: 1 step 519, loss is 2.31687068939209\n",
      "epoch: 1 step 520, loss is 2.3104724884033203\n",
      "epoch: 1 step 521, loss is 2.307936191558838\n",
      "epoch: 1 step 522, loss is 2.3007776737213135\n",
      "epoch: 1 step 523, loss is 2.293004035949707\n",
      "epoch: 1 step 524, loss is 2.2929527759552\n",
      "epoch: 1 step 525, loss is 2.302025079727173\n",
      "epoch: 1 step 526, loss is 2.305783271789551\n",
      "epoch: 1 step 527, loss is 2.31724214553833\n",
      "epoch: 1 step 528, loss is 2.284543514251709\n",
      "epoch: 1 step 529, loss is 2.3059749603271484\n",
      "epoch: 1 step 530, loss is 2.294578790664673\n",
      "epoch: 1 step 531, loss is 2.2919039726257324\n",
      "epoch: 1 step 532, loss is 2.308917760848999\n",
      "epoch: 1 step 533, loss is 2.293203115463257\n",
      "epoch: 1 step 534, loss is 2.2920308113098145\n",
      "epoch: 1 step 535, loss is 2.2818307876586914\n",
      "epoch: 1 step 536, loss is 2.311978816986084\n",
      "epoch: 1 step 537, loss is 2.3023197650909424\n",
      "epoch: 1 step 538, loss is 2.3081576824188232\n",
      "epoch: 1 step 539, loss is 2.291484832763672\n",
      "epoch: 1 step 540, loss is 2.316416025161743\n",
      "epoch: 1 step 541, loss is 2.30479097366333\n",
      "epoch: 1 step 542, loss is 2.3058624267578125\n",
      "epoch: 1 step 543, loss is 2.3109488487243652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 544, loss is 2.2846484184265137\n",
      "epoch: 1 step 545, loss is 2.303199052810669\n",
      "epoch: 1 step 546, loss is 2.2937982082366943\n",
      "epoch: 1 step 547, loss is 2.290144443511963\n",
      "epoch: 1 step 548, loss is 2.292776346206665\n",
      "epoch: 1 step 549, loss is 2.3142309188842773\n",
      "epoch: 1 step 550, loss is 2.302577257156372\n",
      "epoch: 1 step 551, loss is 2.2937214374542236\n",
      "epoch: 1 step 552, loss is 2.298457145690918\n",
      "epoch: 1 step 553, loss is 2.3043863773345947\n",
      "epoch: 1 step 554, loss is 2.3041136264801025\n",
      "epoch: 1 step 555, loss is 2.304441213607788\n",
      "epoch: 1 step 556, loss is 2.2959136962890625\n",
      "epoch: 1 step 557, loss is 2.287644624710083\n",
      "epoch: 1 step 558, loss is 2.2996888160705566\n",
      "epoch: 1 step 559, loss is 2.303114652633667\n",
      "epoch: 1 step 560, loss is 2.3127856254577637\n",
      "epoch: 1 step 561, loss is 2.2931501865386963\n",
      "epoch: 1 step 562, loss is 2.3102290630340576\n",
      "epoch: 1 step 563, loss is 2.3031444549560547\n",
      "epoch: 1 step 564, loss is 2.3256449699401855\n",
      "epoch: 1 step 565, loss is 2.3089632987976074\n",
      "epoch: 1 step 566, loss is 2.296027898788452\n",
      "epoch: 1 step 567, loss is 2.3051443099975586\n",
      "epoch: 1 step 568, loss is 2.314303159713745\n",
      "epoch: 1 step 569, loss is 2.298060178756714\n",
      "epoch: 1 step 570, loss is 2.3200125694274902\n",
      "epoch: 1 step 571, loss is 2.3035120964050293\n",
      "epoch: 1 step 572, loss is 2.301438093185425\n",
      "epoch: 1 step 573, loss is 2.309084177017212\n",
      "epoch: 1 step 574, loss is 2.2914998531341553\n",
      "epoch: 1 step 575, loss is 2.3038980960845947\n",
      "epoch: 1 step 576, loss is 2.2964913845062256\n",
      "epoch: 1 step 577, loss is 2.3185367584228516\n",
      "epoch: 1 step 578, loss is 2.294168472290039\n",
      "epoch: 1 step 579, loss is 2.2987618446350098\n",
      "epoch: 1 step 580, loss is 2.307744026184082\n",
      "epoch: 1 step 581, loss is 2.3152453899383545\n",
      "epoch: 1 step 582, loss is 2.2944529056549072\n",
      "epoch: 1 step 583, loss is 2.2912003993988037\n",
      "epoch: 1 step 584, loss is 2.3099448680877686\n",
      "epoch: 1 step 585, loss is 2.2975735664367676\n",
      "epoch: 1 step 586, loss is 2.303675889968872\n",
      "epoch: 1 step 587, loss is 2.304849624633789\n",
      "epoch: 1 step 588, loss is 2.2880008220672607\n",
      "epoch: 1 step 589, loss is 2.2954723834991455\n",
      "epoch: 1 step 590, loss is 2.3061351776123047\n",
      "epoch: 1 step 591, loss is 2.2987239360809326\n",
      "epoch: 1 step 592, loss is 2.2963337898254395\n",
      "epoch: 1 step 593, loss is 2.302501678466797\n",
      "epoch: 1 step 594, loss is 2.306896686553955\n",
      "epoch: 1 step 595, loss is 2.2986130714416504\n",
      "epoch: 1 step 596, loss is 2.296274423599243\n",
      "epoch: 1 step 597, loss is 2.285633087158203\n",
      "epoch: 1 step 598, loss is 2.31473970413208\n",
      "epoch: 1 step 599, loss is 2.3005778789520264\n",
      "epoch: 1 step 600, loss is 2.302191734313965\n",
      "epoch: 1 step 601, loss is 2.304725408554077\n",
      "epoch: 1 step 602, loss is 2.3023934364318848\n",
      "epoch: 1 step 603, loss is 2.318779468536377\n",
      "epoch: 1 step 604, loss is 2.278282880783081\n",
      "epoch: 1 step 605, loss is 2.296987533569336\n",
      "epoch: 1 step 606, loss is 2.287036657333374\n",
      "epoch: 1 step 607, loss is 2.296092987060547\n",
      "epoch: 1 step 608, loss is 2.285728931427002\n",
      "epoch: 1 step 609, loss is 2.277315139770508\n",
      "epoch: 1 step 610, loss is 2.310730218887329\n",
      "epoch: 1 step 611, loss is 2.2932069301605225\n",
      "epoch: 1 step 612, loss is 2.2998502254486084\n",
      "epoch: 1 step 613, loss is 2.33337140083313\n",
      "epoch: 1 step 614, loss is 2.2876906394958496\n",
      "epoch: 1 step 615, loss is 2.3134958744049072\n",
      "epoch: 1 step 616, loss is 2.298297882080078\n",
      "epoch: 1 step 617, loss is 2.2938692569732666\n",
      "epoch: 1 step 618, loss is 2.2808151245117188\n",
      "epoch: 1 step 619, loss is 2.3081531524658203\n",
      "epoch: 1 step 620, loss is 2.2881011962890625\n",
      "epoch: 1 step 621, loss is 2.288402795791626\n",
      "epoch: 1 step 622, loss is 2.2903871536254883\n",
      "epoch: 1 step 623, loss is 2.310781478881836\n",
      "epoch: 1 step 624, loss is 2.3198704719543457\n",
      "epoch: 1 step 625, loss is 2.291807174682617\n",
      "epoch: 1 step 626, loss is 2.2885937690734863\n",
      "epoch: 1 step 627, loss is 2.3097026348114014\n",
      "epoch: 1 step 628, loss is 2.2967135906219482\n",
      "epoch: 1 step 629, loss is 2.291393995285034\n",
      "epoch: 1 step 630, loss is 2.300400733947754\n",
      "epoch: 1 step 631, loss is 2.3118598461151123\n",
      "epoch: 1 step 632, loss is 2.3007006645202637\n",
      "epoch: 1 step 633, loss is 2.300248622894287\n",
      "epoch: 1 step 634, loss is 2.320274829864502\n",
      "epoch: 1 step 635, loss is 2.2868380546569824\n",
      "epoch: 1 step 636, loss is 2.3002429008483887\n",
      "epoch: 1 step 637, loss is 2.2873823642730713\n",
      "epoch: 1 step 638, loss is 2.307615041732788\n",
      "epoch: 1 step 639, loss is 2.3079922199249268\n",
      "epoch: 1 step 640, loss is 2.2916922569274902\n",
      "epoch: 1 step 641, loss is 2.279951572418213\n",
      "epoch: 1 step 642, loss is 2.321791172027588\n",
      "epoch: 1 step 643, loss is 2.2927591800689697\n",
      "epoch: 1 step 644, loss is 2.3093457221984863\n",
      "epoch: 1 step 645, loss is 2.305617570877075\n",
      "epoch: 1 step 646, loss is 2.3011748790740967\n",
      "epoch: 1 step 647, loss is 2.2950925827026367\n",
      "epoch: 1 step 648, loss is 2.2976534366607666\n",
      "epoch: 1 step 649, loss is 2.305446147918701\n",
      "epoch: 1 step 650, loss is 2.3264527320861816\n",
      "epoch: 1 step 651, loss is 2.2816526889801025\n",
      "epoch: 1 step 652, loss is 2.2895913124084473\n",
      "epoch: 1 step 653, loss is 2.2928690910339355\n",
      "epoch: 1 step 654, loss is 2.2872660160064697\n",
      "epoch: 1 step 655, loss is 2.2978932857513428\n",
      "epoch: 1 step 656, loss is 2.298518657684326\n",
      "epoch: 1 step 657, loss is 2.2940309047698975\n",
      "epoch: 1 step 658, loss is 2.3062477111816406\n",
      "epoch: 1 step 659, loss is 2.2833542823791504\n",
      "epoch: 1 step 660, loss is 2.297724723815918\n",
      "epoch: 1 step 661, loss is 2.290584087371826\n",
      "epoch: 1 step 662, loss is 2.3093016147613525\n",
      "epoch: 1 step 663, loss is 2.2913601398468018\n",
      "epoch: 1 step 664, loss is 2.2878904342651367\n",
      "epoch: 1 step 665, loss is 2.2982962131500244\n",
      "epoch: 1 step 666, loss is 2.30412220954895\n",
      "epoch: 1 step 667, loss is 2.2898168563842773\n",
      "epoch: 1 step 668, loss is 2.3147521018981934\n",
      "epoch: 1 step 669, loss is 2.308183193206787\n",
      "epoch: 1 step 670, loss is 2.2994282245635986\n",
      "epoch: 1 step 671, loss is 2.312607765197754\n",
      "epoch: 1 step 672, loss is 2.3106467723846436\n",
      "epoch: 1 step 673, loss is 2.292339563369751\n",
      "epoch: 1 step 674, loss is 2.2949345111846924\n",
      "epoch: 1 step 675, loss is 2.300790309906006\n",
      "epoch: 1 step 676, loss is 2.304965019226074\n",
      "epoch: 1 step 677, loss is 2.2852847576141357\n",
      "epoch: 1 step 678, loss is 2.3012306690216064\n",
      "epoch: 1 step 679, loss is 2.312943458557129\n",
      "epoch: 1 step 680, loss is 2.2971394062042236\n",
      "epoch: 1 step 681, loss is 2.2854537963867188\n",
      "epoch: 1 step 682, loss is 2.2959823608398438\n",
      "epoch: 1 step 683, loss is 2.3153486251831055\n",
      "epoch: 1 step 684, loss is 2.2996137142181396\n",
      "epoch: 1 step 685, loss is 2.2879552841186523\n",
      "epoch: 1 step 686, loss is 2.292052745819092\n",
      "epoch: 1 step 687, loss is 2.28926157951355\n",
      "epoch: 1 step 688, loss is 2.302530527114868\n",
      "epoch: 1 step 689, loss is 2.2990405559539795\n",
      "epoch: 1 step 690, loss is 2.3113174438476562\n",
      "epoch: 1 step 691, loss is 2.311800003051758\n",
      "epoch: 1 step 692, loss is 2.2938122749328613\n",
      "epoch: 1 step 693, loss is 2.281641721725464\n",
      "epoch: 1 step 694, loss is 2.315920114517212\n",
      "epoch: 1 step 695, loss is 2.3154196739196777\n",
      "epoch: 1 step 696, loss is 2.29622220993042\n",
      "epoch: 1 step 697, loss is 2.3036105632781982\n",
      "epoch: 1 step 698, loss is 2.291242837905884\n",
      "epoch: 1 step 699, loss is 2.2951271533966064\n",
      "epoch: 1 step 700, loss is 2.299222230911255\n",
      "epoch: 1 step 701, loss is 2.290109157562256\n",
      "epoch: 1 step 702, loss is 2.2930047512054443\n",
      "epoch: 1 step 703, loss is 2.280167579650879\n",
      "epoch: 1 step 704, loss is 2.315762996673584\n",
      "epoch: 1 step 705, loss is 2.3222908973693848\n",
      "epoch: 1 step 706, loss is 2.2864747047424316\n",
      "epoch: 1 step 707, loss is 2.267042636871338\n",
      "epoch: 1 step 708, loss is 2.3018813133239746\n",
      "epoch: 1 step 709, loss is 2.281364917755127\n",
      "epoch: 1 step 710, loss is 2.307040214538574\n",
      "epoch: 1 step 711, loss is 2.308441162109375\n",
      "epoch: 1 step 712, loss is 2.322699785232544\n",
      "epoch: 1 step 713, loss is 2.2905800342559814\n",
      "epoch: 1 step 714, loss is 2.284076690673828\n",
      "epoch: 1 step 715, loss is 2.3076560497283936\n",
      "epoch: 1 step 716, loss is 2.29257869720459\n",
      "epoch: 1 step 717, loss is 2.282029628753662\n",
      "epoch: 1 step 718, loss is 2.312410831451416\n",
      "epoch: 1 step 719, loss is 2.298229932785034\n",
      "epoch: 1 step 720, loss is 2.259955883026123\n",
      "epoch: 1 step 721, loss is 2.310192584991455\n",
      "epoch: 1 step 722, loss is 2.317457675933838\n",
      "epoch: 1 step 723, loss is 2.2887001037597656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 724, loss is 2.311528205871582\n",
      "epoch: 1 step 725, loss is 2.2796037197113037\n",
      "epoch: 1 step 726, loss is 2.2791337966918945\n",
      "epoch: 1 step 727, loss is 2.2870848178863525\n",
      "epoch: 1 step 728, loss is 2.2893407344818115\n",
      "epoch: 1 step 729, loss is 2.3080923557281494\n",
      "epoch: 1 step 730, loss is 2.281989574432373\n",
      "epoch: 1 step 731, loss is 2.287876844406128\n",
      "epoch: 1 step 732, loss is 2.2949070930480957\n",
      "epoch: 1 step 733, loss is 2.3051536083221436\n",
      "epoch: 1 step 734, loss is 2.2933919429779053\n",
      "epoch: 1 step 735, loss is 2.2848522663116455\n",
      "epoch: 1 step 736, loss is 2.296999216079712\n",
      "epoch: 1 step 737, loss is 2.283834934234619\n",
      "epoch: 1 step 738, loss is 2.313833475112915\n",
      "epoch: 1 step 739, loss is 2.289297580718994\n",
      "epoch: 1 step 740, loss is 2.3047103881835938\n",
      "epoch: 1 step 741, loss is 2.310509443283081\n",
      "epoch: 1 step 742, loss is 2.300405502319336\n",
      "epoch: 1 step 743, loss is 2.2882189750671387\n",
      "epoch: 1 step 744, loss is 2.2621119022369385\n",
      "epoch: 1 step 745, loss is 2.298179864883423\n",
      "epoch: 1 step 746, loss is 2.293515920639038\n",
      "epoch: 1 step 747, loss is 2.3081891536712646\n",
      "epoch: 1 step 748, loss is 2.289299726486206\n",
      "epoch: 1 step 749, loss is 2.294929027557373\n",
      "epoch: 1 step 750, loss is 2.2733545303344727\n",
      "epoch: 1 step 751, loss is 2.27662992477417\n",
      "epoch: 1 step 752, loss is 2.291785955429077\n",
      "epoch: 1 step 753, loss is 2.2820146083831787\n",
      "epoch: 1 step 754, loss is 2.2796335220336914\n",
      "epoch: 1 step 755, loss is 2.300360918045044\n",
      "epoch: 1 step 756, loss is 2.285766839981079\n",
      "epoch: 1 step 757, loss is 2.275282382965088\n",
      "epoch: 1 step 758, loss is 2.289869785308838\n",
      "epoch: 1 step 759, loss is 2.288311243057251\n",
      "epoch: 1 step 760, loss is 2.2835910320281982\n",
      "epoch: 1 step 761, loss is 2.2774996757507324\n",
      "epoch: 1 step 762, loss is 2.2717692852020264\n",
      "epoch: 1 step 763, loss is 2.2631680965423584\n",
      "epoch: 1 step 764, loss is 2.2731502056121826\n",
      "epoch: 1 step 765, loss is 2.281693458557129\n",
      "epoch: 1 step 766, loss is 2.2641055583953857\n",
      "epoch: 1 step 767, loss is 2.271340847015381\n",
      "epoch: 1 step 768, loss is 2.275526285171509\n",
      "epoch: 1 step 769, loss is 2.2647759914398193\n",
      "epoch: 1 step 770, loss is 2.2564775943756104\n",
      "epoch: 1 step 771, loss is 2.2807374000549316\n",
      "epoch: 1 step 772, loss is 2.2322680950164795\n",
      "epoch: 1 step 773, loss is 2.2390637397766113\n",
      "epoch: 1 step 774, loss is 2.254652261734009\n",
      "epoch: 1 step 775, loss is 2.2351579666137695\n",
      "epoch: 1 step 776, loss is 2.2300965785980225\n",
      "epoch: 1 step 777, loss is 2.263421058654785\n",
      "epoch: 1 step 778, loss is 2.2214722633361816\n",
      "epoch: 1 step 779, loss is 2.220160484313965\n",
      "epoch: 1 step 780, loss is 2.224086284637451\n",
      "epoch: 1 step 781, loss is 2.1890642642974854\n",
      "epoch: 1 step 782, loss is 2.212411880493164\n",
      "epoch: 1 step 783, loss is 2.2310309410095215\n",
      "epoch: 1 step 784, loss is 2.215427875518799\n",
      "epoch: 1 step 785, loss is 2.181779623031616\n",
      "epoch: 1 step 786, loss is 2.1368837356567383\n",
      "epoch: 1 step 787, loss is 2.200275421142578\n",
      "epoch: 1 step 788, loss is 2.0769481658935547\n",
      "epoch: 1 step 789, loss is 2.0798652172088623\n",
      "epoch: 1 step 790, loss is 1.9962787628173828\n",
      "epoch: 1 step 791, loss is 2.085353374481201\n",
      "epoch: 1 step 792, loss is 2.023948907852173\n",
      "epoch: 1 step 793, loss is 1.9775162935256958\n",
      "epoch: 1 step 794, loss is 2.0264859199523926\n",
      "epoch: 1 step 795, loss is 1.8990428447723389\n",
      "epoch: 1 step 796, loss is 1.8507258892059326\n",
      "epoch: 1 step 797, loss is 1.8836371898651123\n",
      "epoch: 1 step 798, loss is 1.8537689447402954\n",
      "epoch: 1 step 799, loss is 1.5868067741394043\n",
      "epoch: 1 step 800, loss is 1.6315590143203735\n",
      "epoch: 1 step 801, loss is 1.4959402084350586\n",
      "epoch: 1 step 802, loss is 1.581732988357544\n",
      "epoch: 1 step 803, loss is 1.3930209875106812\n",
      "epoch: 1 step 804, loss is 1.8094263076782227\n",
      "epoch: 1 step 805, loss is 1.2004598379135132\n",
      "epoch: 1 step 806, loss is 1.5204395055770874\n",
      "epoch: 1 step 807, loss is 1.0562299489974976\n",
      "epoch: 1 step 808, loss is 1.1175340414047241\n",
      "epoch: 1 step 809, loss is 1.110710620880127\n",
      "epoch: 1 step 810, loss is 1.22267746925354\n",
      "epoch: 1 step 811, loss is 0.9916217923164368\n",
      "epoch: 1 step 812, loss is 1.3536423444747925\n",
      "epoch: 1 step 813, loss is 1.3294962644577026\n",
      "epoch: 1 step 814, loss is 1.222076416015625\n",
      "epoch: 1 step 815, loss is 1.1926804780960083\n",
      "epoch: 1 step 816, loss is 1.2677249908447266\n",
      "epoch: 1 step 817, loss is 0.7866724729537964\n",
      "epoch: 1 step 818, loss is 1.2224595546722412\n",
      "epoch: 1 step 819, loss is 1.3521312475204468\n",
      "epoch: 1 step 820, loss is 1.3983004093170166\n",
      "epoch: 1 step 821, loss is 1.2548807859420776\n",
      "epoch: 1 step 822, loss is 1.1634089946746826\n",
      "epoch: 1 step 823, loss is 1.2329490184783936\n",
      "epoch: 1 step 824, loss is 0.927302896976471\n",
      "epoch: 1 step 825, loss is 1.3058924674987793\n",
      "epoch: 1 step 826, loss is 0.88958340883255\n",
      "epoch: 1 step 827, loss is 1.2157689332962036\n",
      "epoch: 1 step 828, loss is 0.7676456570625305\n",
      "epoch: 1 step 829, loss is 1.3338539600372314\n",
      "epoch: 1 step 830, loss is 1.210726022720337\n",
      "epoch: 1 step 831, loss is 1.4619954824447632\n",
      "epoch: 1 step 832, loss is 1.070967674255371\n",
      "epoch: 1 step 833, loss is 1.2459098100662231\n",
      "epoch: 1 step 834, loss is 1.0285723209381104\n",
      "epoch: 1 step 835, loss is 1.5987755060195923\n",
      "epoch: 1 step 836, loss is 1.3421015739440918\n",
      "epoch: 1 step 837, loss is 1.0287829637527466\n",
      "epoch: 1 step 838, loss is 0.8404675722122192\n",
      "epoch: 1 step 839, loss is 0.8053593635559082\n",
      "epoch: 1 step 840, loss is 1.134331226348877\n",
      "epoch: 1 step 841, loss is 0.8719921708106995\n",
      "epoch: 1 step 842, loss is 0.981346607208252\n",
      "epoch: 1 step 843, loss is 0.8902426958084106\n",
      "epoch: 1 step 844, loss is 1.1104727983474731\n",
      "epoch: 1 step 845, loss is 0.9911269545555115\n",
      "epoch: 1 step 846, loss is 1.0488018989562988\n",
      "epoch: 1 step 847, loss is 0.7992566227912903\n",
      "epoch: 1 step 848, loss is 0.7287769317626953\n",
      "epoch: 1 step 849, loss is 0.577411413192749\n",
      "epoch: 1 step 850, loss is 0.8648281097412109\n",
      "epoch: 1 step 851, loss is 1.8254376649856567\n",
      "epoch: 1 step 852, loss is 0.9343538880348206\n",
      "epoch: 1 step 853, loss is 1.118343472480774\n",
      "epoch: 1 step 854, loss is 0.7372920513153076\n",
      "epoch: 1 step 855, loss is 0.7415173053741455\n",
      "epoch: 1 step 856, loss is 0.733338475227356\n",
      "epoch: 1 step 857, loss is 0.7452120780944824\n",
      "epoch: 1 step 858, loss is 0.7284213304519653\n",
      "epoch: 1 step 859, loss is 0.7050371170043945\n",
      "epoch: 1 step 860, loss is 0.6951356530189514\n",
      "epoch: 1 step 861, loss is 0.9011646509170532\n",
      "epoch: 1 step 862, loss is 0.5518014430999756\n",
      "epoch: 1 step 863, loss is 0.5539737343788147\n",
      "epoch: 1 step 864, loss is 0.8515357971191406\n",
      "epoch: 1 step 865, loss is 0.8021255731582642\n",
      "epoch: 1 step 866, loss is 0.8317680358886719\n",
      "epoch: 1 step 867, loss is 0.7628864049911499\n",
      "epoch: 1 step 868, loss is 1.076028823852539\n",
      "epoch: 1 step 869, loss is 0.8407242298126221\n",
      "epoch: 1 step 870, loss is 0.9949799180030823\n",
      "epoch: 1 step 871, loss is 0.740688681602478\n",
      "epoch: 1 step 872, loss is 0.8933119773864746\n",
      "epoch: 1 step 873, loss is 0.606465220451355\n",
      "epoch: 1 step 874, loss is 0.7506833672523499\n",
      "epoch: 1 step 875, loss is 0.683668315410614\n",
      "epoch: 1 step 876, loss is 0.40669941902160645\n",
      "epoch: 1 step 877, loss is 0.8291460275650024\n",
      "epoch: 1 step 878, loss is 0.3711823523044586\n",
      "epoch: 1 step 879, loss is 0.7083078622817993\n",
      "epoch: 1 step 880, loss is 0.6440669894218445\n",
      "epoch: 1 step 881, loss is 1.1711574792861938\n",
      "epoch: 1 step 882, loss is 0.8168731331825256\n",
      "epoch: 1 step 883, loss is 0.7596681714057922\n",
      "epoch: 1 step 884, loss is 0.6600638628005981\n",
      "epoch: 1 step 885, loss is 0.711455225944519\n",
      "epoch: 1 step 886, loss is 0.4803568124771118\n",
      "epoch: 1 step 887, loss is 0.5074321627616882\n",
      "epoch: 1 step 888, loss is 0.5216010212898254\n",
      "epoch: 1 step 889, loss is 0.5154662132263184\n",
      "epoch: 1 step 890, loss is 0.8748500943183899\n",
      "epoch: 1 step 891, loss is 0.6415078043937683\n",
      "epoch: 1 step 892, loss is 0.331193208694458\n",
      "epoch: 1 step 893, loss is 0.48383283615112305\n",
      "epoch: 1 step 894, loss is 0.3206727206707001\n",
      "epoch: 1 step 895, loss is 0.33423829078674316\n",
      "epoch: 1 step 896, loss is 0.5230504274368286\n",
      "epoch: 1 step 897, loss is 0.5705544352531433\n",
      "epoch: 1 step 898, loss is 0.6121129393577576\n",
      "epoch: 1 step 899, loss is 0.3681733310222626\n",
      "epoch: 1 step 900, loss is 0.32715505361557007\n",
      "epoch: 1 step 901, loss is 0.7740625739097595\n",
      "epoch: 1 step 902, loss is 0.37605494260787964\n",
      "epoch: 1 step 903, loss is 0.2818998396396637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 904, loss is 0.8959805369377136\n",
      "epoch: 1 step 905, loss is 0.35969066619873047\n",
      "epoch: 1 step 906, loss is 0.5569093823432922\n",
      "epoch: 1 step 907, loss is 0.6490380167961121\n",
      "epoch: 1 step 908, loss is 0.4854198098182678\n",
      "epoch: 1 step 909, loss is 0.681684136390686\n",
      "epoch: 1 step 910, loss is 0.5594454407691956\n",
      "epoch: 1 step 911, loss is 0.28246811032295227\n",
      "epoch: 1 step 912, loss is 0.564134955406189\n",
      "epoch: 1 step 913, loss is 0.3480125367641449\n",
      "epoch: 1 step 914, loss is 0.30245739221572876\n",
      "epoch: 1 step 915, loss is 0.3057793080806732\n",
      "epoch: 1 step 916, loss is 0.40296462178230286\n",
      "epoch: 1 step 917, loss is 0.5620078444480896\n",
      "epoch: 1 step 918, loss is 0.3885918855667114\n",
      "epoch: 1 step 919, loss is 0.3405517637729645\n",
      "epoch: 1 step 920, loss is 0.5268466472625732\n",
      "epoch: 1 step 921, loss is 0.11871110647916794\n",
      "epoch: 1 step 922, loss is 0.4030132293701172\n",
      "epoch: 1 step 923, loss is 0.44585901498794556\n",
      "epoch: 1 step 924, loss is 0.42256829142570496\n",
      "epoch: 1 step 925, loss is 0.05742168426513672\n",
      "epoch: 1 step 926, loss is 0.43707379698753357\n",
      "epoch: 1 step 927, loss is 0.31248682737350464\n",
      "epoch: 1 step 928, loss is 0.48477858304977417\n",
      "epoch: 1 step 929, loss is 0.22904114425182343\n",
      "epoch: 1 step 930, loss is 0.6515914797782898\n",
      "epoch: 1 step 931, loss is 0.38605231046676636\n",
      "epoch: 1 step 932, loss is 0.5625531673431396\n",
      "epoch: 1 step 933, loss is 0.39168664813041687\n",
      "epoch: 1 step 934, loss is 0.20879001915454865\n",
      "epoch: 1 step 935, loss is 0.2718164324760437\n",
      "epoch: 1 step 936, loss is 0.5753874778747559\n",
      "epoch: 1 step 937, loss is 0.4230019152164459\n",
      "epoch: 1 step 938, loss is 0.4174725115299225\n",
      "epoch: 1 step 939, loss is 0.8505776524543762\n",
      "epoch: 1 step 940, loss is 0.25025784969329834\n",
      "epoch: 1 step 941, loss is 0.711872398853302\n",
      "epoch: 1 step 942, loss is 0.1983395218849182\n",
      "epoch: 1 step 943, loss is 0.3040161728858948\n",
      "epoch: 1 step 944, loss is 0.4821297824382782\n",
      "epoch: 1 step 945, loss is 0.5496278405189514\n",
      "epoch: 1 step 946, loss is 0.3190930187702179\n",
      "epoch: 1 step 947, loss is 0.3668420910835266\n",
      "epoch: 1 step 948, loss is 0.3687497675418854\n",
      "epoch: 1 step 949, loss is 0.15128424763679504\n",
      "epoch: 1 step 950, loss is 0.474439412355423\n",
      "epoch: 1 step 951, loss is 0.4503163993358612\n",
      "epoch: 1 step 952, loss is 0.3093399405479431\n",
      "epoch: 1 step 953, loss is 0.2081325352191925\n",
      "epoch: 1 step 954, loss is 0.564822256565094\n",
      "epoch: 1 step 955, loss is 0.6963821053504944\n",
      "epoch: 1 step 956, loss is 0.516822874546051\n",
      "epoch: 1 step 957, loss is 0.08782825618982315\n",
      "epoch: 1 step 958, loss is 0.7355473041534424\n",
      "epoch: 1 step 959, loss is 0.3020493984222412\n",
      "epoch: 1 step 960, loss is 0.17054177820682526\n",
      "epoch: 1 step 961, loss is 0.29689866304397583\n",
      "epoch: 1 step 962, loss is 0.2564084529876709\n",
      "epoch: 1 step 963, loss is 0.32002487778663635\n",
      "epoch: 1 step 964, loss is 0.6085982322692871\n",
      "epoch: 1 step 965, loss is 0.2022058367729187\n",
      "epoch: 1 step 966, loss is 0.28568506240844727\n",
      "epoch: 1 step 967, loss is 0.40296539664268494\n",
      "epoch: 1 step 968, loss is 0.7496739029884338\n",
      "epoch: 1 step 969, loss is 0.20458398759365082\n",
      "epoch: 1 step 970, loss is 0.2953733801841736\n",
      "epoch: 1 step 971, loss is 0.5422435998916626\n",
      "epoch: 1 step 972, loss is 0.29642194509506226\n",
      "epoch: 1 step 973, loss is 0.3858273923397064\n",
      "epoch: 1 step 974, loss is 0.3633837401866913\n",
      "epoch: 1 step 975, loss is 0.25124484300613403\n",
      "epoch: 1 step 976, loss is 0.20992040634155273\n",
      "epoch: 1 step 977, loss is 0.13602547347545624\n",
      "epoch: 1 step 978, loss is 0.1998327523469925\n",
      "epoch: 1 step 979, loss is 0.30320289731025696\n",
      "epoch: 1 step 980, loss is 0.33806726336479187\n",
      "epoch: 1 step 981, loss is 0.6388981938362122\n",
      "epoch: 1 step 982, loss is 0.36718547344207764\n",
      "epoch: 1 step 983, loss is 0.2681766450405121\n",
      "epoch: 1 step 984, loss is 0.26537206768989563\n",
      "epoch: 1 step 985, loss is 0.3361125588417053\n",
      "epoch: 1 step 986, loss is 0.6573469638824463\n",
      "epoch: 1 step 987, loss is 0.24379801750183105\n",
      "epoch: 1 step 988, loss is 0.31784507632255554\n",
      "epoch: 1 step 989, loss is 0.27742987871170044\n",
      "epoch: 1 step 990, loss is 0.5038543343544006\n",
      "epoch: 1 step 991, loss is 0.09328068047761917\n",
      "epoch: 1 step 992, loss is 0.40782731771469116\n",
      "epoch: 1 step 993, loss is 0.08224949240684509\n",
      "epoch: 1 step 994, loss is 0.2283739447593689\n",
      "epoch: 1 step 995, loss is 0.2058914601802826\n",
      "epoch: 1 step 996, loss is 0.5321757793426514\n",
      "epoch: 1 step 997, loss is 0.15863986313343048\n",
      "epoch: 1 step 998, loss is 0.2732018828392029\n",
      "epoch: 1 step 999, loss is 0.21776258945465088\n",
      "epoch: 1 step 1000, loss is 0.3760163187980652\n",
      "epoch: 1 step 1001, loss is 0.2683853507041931\n",
      "epoch: 1 step 1002, loss is 0.2589399218559265\n",
      "epoch: 1 step 1003, loss is 0.04534674063324928\n",
      "epoch: 1 step 1004, loss is 0.5600655674934387\n",
      "epoch: 1 step 1005, loss is 0.2572353780269623\n",
      "epoch: 1 step 1006, loss is 0.7334855198860168\n",
      "epoch: 1 step 1007, loss is 0.2793818712234497\n",
      "epoch: 1 step 1008, loss is 0.11112275719642639\n",
      "epoch: 1 step 1009, loss is 0.4475588798522949\n",
      "epoch: 1 step 1010, loss is 0.27338021993637085\n",
      "epoch: 1 step 1011, loss is 0.20580638945102692\n",
      "epoch: 1 step 1012, loss is 0.40580126643180847\n",
      "epoch: 1 step 1013, loss is 0.07276472449302673\n",
      "epoch: 1 step 1014, loss is 0.3398958146572113\n",
      "epoch: 1 step 1015, loss is 0.6265392303466797\n",
      "epoch: 1 step 1016, loss is 0.08471273630857468\n",
      "epoch: 1 step 1017, loss is 0.31604471802711487\n",
      "epoch: 1 step 1018, loss is 0.338906854391098\n",
      "epoch: 1 step 1019, loss is 0.49559280276298523\n",
      "epoch: 1 step 1020, loss is 0.27650532126426697\n",
      "epoch: 1 step 1021, loss is 0.6406198740005493\n",
      "epoch: 1 step 1022, loss is 0.3085279166698456\n",
      "epoch: 1 step 1023, loss is 0.4372611939907074\n",
      "epoch: 1 step 1024, loss is 0.5810808539390564\n",
      "epoch: 1 step 1025, loss is 0.4246627688407898\n",
      "epoch: 1 step 1026, loss is 0.3712407648563385\n",
      "epoch: 1 step 1027, loss is 0.3081851303577423\n",
      "epoch: 1 step 1028, loss is 0.21821783483028412\n",
      "epoch: 1 step 1029, loss is 0.5841119885444641\n",
      "epoch: 1 step 1030, loss is 0.3688592314720154\n",
      "epoch: 1 step 1031, loss is 0.31897640228271484\n",
      "epoch: 1 step 1032, loss is 0.2769280970096588\n",
      "epoch: 1 step 1033, loss is 0.5379514098167419\n",
      "epoch: 1 step 1034, loss is 0.25380346179008484\n",
      "epoch: 1 step 1035, loss is 0.34640347957611084\n",
      "epoch: 1 step 1036, loss is 0.16768336296081543\n",
      "epoch: 1 step 1037, loss is 0.3480660319328308\n",
      "epoch: 1 step 1038, loss is 0.38453879952430725\n",
      "epoch: 1 step 1039, loss is 0.3001658022403717\n",
      "epoch: 1 step 1040, loss is 0.7822790145874023\n",
      "epoch: 1 step 1041, loss is 0.2834794819355011\n",
      "epoch: 1 step 1042, loss is 0.3137734830379486\n",
      "epoch: 1 step 1043, loss is 0.5421685576438904\n",
      "epoch: 1 step 1044, loss is 0.18315750360488892\n",
      "epoch: 1 step 1045, loss is 0.05776865780353546\n",
      "epoch: 1 step 1046, loss is 0.27788466215133667\n",
      "epoch: 1 step 1047, loss is 0.3679546117782593\n",
      "epoch: 1 step 1048, loss is 0.4025610387325287\n",
      "epoch: 1 step 1049, loss is 0.4029242694377899\n",
      "epoch: 1 step 1050, loss is 0.16425970196723938\n",
      "epoch: 1 step 1051, loss is 0.14769382774829865\n",
      "epoch: 1 step 1052, loss is 0.1314668357372284\n",
      "epoch: 1 step 1053, loss is 0.2774055004119873\n",
      "epoch: 1 step 1054, loss is 0.6040791869163513\n",
      "epoch: 1 step 1055, loss is 0.15977488458156586\n",
      "epoch: 1 step 1056, loss is 0.3691514730453491\n",
      "epoch: 1 step 1057, loss is 0.28412625193595886\n",
      "epoch: 1 step 1058, loss is 0.5344435572624207\n",
      "epoch: 1 step 1059, loss is 0.4580501317977905\n",
      "epoch: 1 step 1060, loss is 0.12012836337089539\n",
      "epoch: 1 step 1061, loss is 0.18099641799926758\n",
      "epoch: 1 step 1062, loss is 0.08387185633182526\n",
      "epoch: 1 step 1063, loss is 0.4229600131511688\n",
      "epoch: 1 step 1064, loss is 0.23241564631462097\n",
      "epoch: 1 step 1065, loss is 0.6064302921295166\n",
      "epoch: 1 step 1066, loss is 0.617723286151886\n",
      "epoch: 1 step 1067, loss is 0.08103369176387787\n",
      "epoch: 1 step 1068, loss is 0.2632162868976593\n",
      "epoch: 1 step 1069, loss is 0.09751598536968231\n",
      "epoch: 1 step 1070, loss is 0.09698432683944702\n",
      "epoch: 1 step 1071, loss is 0.2307710200548172\n",
      "epoch: 1 step 1072, loss is 0.24673278629779816\n",
      "epoch: 1 step 1073, loss is 0.47342631220817566\n",
      "epoch: 1 step 1074, loss is 0.26532411575317383\n",
      "epoch: 1 step 1075, loss is 0.17981591820716858\n",
      "epoch: 1 step 1076, loss is 0.21233554184436798\n",
      "epoch: 1 step 1077, loss is 0.1286160945892334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 1078, loss is 0.22428953647613525\n",
      "epoch: 1 step 1079, loss is 0.19300851225852966\n",
      "epoch: 1 step 1080, loss is 0.13316313922405243\n",
      "epoch: 1 step 1081, loss is 0.33551234006881714\n",
      "epoch: 1 step 1082, loss is 0.6692869067192078\n",
      "epoch: 1 step 1083, loss is 0.18172471225261688\n",
      "epoch: 1 step 1084, loss is 0.44903361797332764\n",
      "epoch: 1 step 1085, loss is 0.22222338616847992\n",
      "epoch: 1 step 1086, loss is 0.23797328770160675\n",
      "epoch: 1 step 1087, loss is 0.540205717086792\n",
      "epoch: 1 step 1088, loss is 0.3685106635093689\n",
      "epoch: 1 step 1089, loss is 0.34796908497810364\n",
      "epoch: 1 step 1090, loss is 0.06477059423923492\n",
      "epoch: 1 step 1091, loss is 0.2196572870016098\n",
      "epoch: 1 step 1092, loss is 0.31783750653266907\n",
      "epoch: 1 step 1093, loss is 0.4156820774078369\n",
      "epoch: 1 step 1094, loss is 0.5367379784584045\n",
      "epoch: 1 step 1095, loss is 0.2490120530128479\n",
      "epoch: 1 step 1096, loss is 0.2063281387090683\n",
      "epoch: 1 step 1097, loss is 0.3062203824520111\n",
      "epoch: 1 step 1098, loss is 0.5498185753822327\n",
      "epoch: 1 step 1099, loss is 0.24774104356765747\n",
      "epoch: 1 step 1100, loss is 0.17051738500595093\n",
      "epoch: 1 step 1101, loss is 0.23986303806304932\n",
      "epoch: 1 step 1102, loss is 0.4491817057132721\n",
      "epoch: 1 step 1103, loss is 0.3186136484146118\n",
      "epoch: 1 step 1104, loss is 0.3498857617378235\n",
      "epoch: 1 step 1105, loss is 0.28111812472343445\n",
      "epoch: 1 step 1106, loss is 0.32438984513282776\n",
      "epoch: 1 step 1107, loss is 0.073697529733181\n",
      "epoch: 1 step 1108, loss is 0.6178018450737\n",
      "epoch: 1 step 1109, loss is 0.3223627805709839\n",
      "epoch: 1 step 1110, loss is 0.4303666353225708\n",
      "epoch: 1 step 1111, loss is 0.35319793224334717\n",
      "epoch: 1 step 1112, loss is 0.15253594517707825\n",
      "epoch: 1 step 1113, loss is 0.1582525074481964\n",
      "epoch: 1 step 1114, loss is 0.29381710290908813\n",
      "epoch: 1 step 1115, loss is 0.40499237179756165\n",
      "epoch: 1 step 1116, loss is 0.2567298114299774\n",
      "epoch: 1 step 1117, loss is 0.1395392268896103\n",
      "epoch: 1 step 1118, loss is 0.1815434694290161\n",
      "epoch: 1 step 1119, loss is 0.1104380339384079\n",
      "epoch: 1 step 1120, loss is 0.19085386395454407\n",
      "epoch: 1 step 1121, loss is 0.2832586467266083\n",
      "epoch: 1 step 1122, loss is 0.0957142785191536\n",
      "epoch: 1 step 1123, loss is 0.06894905865192413\n",
      "epoch: 1 step 1124, loss is 0.09497775882482529\n",
      "epoch: 1 step 1125, loss is 0.09656362980604172\n",
      "epoch: 1 step 1126, loss is 0.20896317064762115\n",
      "epoch: 1 step 1127, loss is 0.07586798071861267\n",
      "epoch: 1 step 1128, loss is 0.31554341316223145\n",
      "epoch: 1 step 1129, loss is 0.30824175477027893\n",
      "epoch: 1 step 1130, loss is 0.32638534903526306\n",
      "epoch: 1 step 1131, loss is 0.46965035796165466\n",
      "epoch: 1 step 1132, loss is 0.40726661682128906\n",
      "epoch: 1 step 1133, loss is 0.23672117292881012\n",
      "epoch: 1 step 1134, loss is 0.6298201680183411\n",
      "epoch: 1 step 1135, loss is 0.20049166679382324\n",
      "epoch: 1 step 1136, loss is 0.4530198574066162\n",
      "epoch: 1 step 1137, loss is 0.06658273190259933\n",
      "epoch: 1 step 1138, loss is 0.03635825589299202\n",
      "epoch: 1 step 1139, loss is 0.4011572003364563\n",
      "epoch: 1 step 1140, loss is 0.3976319432258606\n",
      "epoch: 1 step 1141, loss is 0.282844603061676\n",
      "epoch: 1 step 1142, loss is 0.45697933435440063\n",
      "epoch: 1 step 1143, loss is 0.15638460218906403\n",
      "epoch: 1 step 1144, loss is 0.28267666697502136\n",
      "epoch: 1 step 1145, loss is 0.12315250933170319\n",
      "epoch: 1 step 1146, loss is 0.27250251173973083\n",
      "epoch: 1 step 1147, loss is 0.2064804881811142\n",
      "epoch: 1 step 1148, loss is 0.29979947209358215\n",
      "epoch: 1 step 1149, loss is 0.4557610750198364\n",
      "epoch: 1 step 1150, loss is 0.3270760774612427\n",
      "epoch: 1 step 1151, loss is 0.41850700974464417\n",
      "epoch: 1 step 1152, loss is 0.1860130876302719\n",
      "epoch: 1 step 1153, loss is 0.27925026416778564\n",
      "epoch: 1 step 1154, loss is 0.4810539484024048\n",
      "epoch: 1 step 1155, loss is 0.12464289367198944\n",
      "epoch: 1 step 1156, loss is 0.16106286644935608\n",
      "epoch: 1 step 1157, loss is 0.16907911002635956\n",
      "epoch: 1 step 1158, loss is 0.06749197095632553\n",
      "epoch: 1 step 1159, loss is 0.29827752709388733\n",
      "epoch: 1 step 1160, loss is 0.24341711401939392\n",
      "epoch: 1 step 1161, loss is 0.08036495745182037\n",
      "epoch: 1 step 1162, loss is 0.24053184688091278\n",
      "epoch: 1 step 1163, loss is 0.11434865742921829\n",
      "epoch: 1 step 1164, loss is 0.13994774222373962\n",
      "epoch: 1 step 1165, loss is 0.045894984155893326\n",
      "epoch: 1 step 1166, loss is 0.18184658885002136\n",
      "epoch: 1 step 1167, loss is 0.1025833785533905\n",
      "epoch: 1 step 1168, loss is 0.29611027240753174\n",
      "epoch: 1 step 1169, loss is 0.14438430964946747\n",
      "epoch: 1 step 1170, loss is 0.29945775866508484\n",
      "epoch: 1 step 1171, loss is 0.2431691586971283\n",
      "epoch: 1 step 1172, loss is 0.2653314769268036\n",
      "epoch: 1 step 1173, loss is 0.23848384618759155\n",
      "epoch: 1 step 1174, loss is 0.42164602875709534\n",
      "epoch: 1 step 1175, loss is 0.11151123046875\n",
      "epoch: 1 step 1176, loss is 0.42921751737594604\n",
      "epoch: 1 step 1177, loss is 0.12506745755672455\n",
      "epoch: 1 step 1178, loss is 0.3728172183036804\n",
      "epoch: 1 step 1179, loss is 0.22415082156658173\n",
      "epoch: 1 step 1180, loss is 0.3576843738555908\n",
      "epoch: 1 step 1181, loss is 0.40304967761039734\n",
      "epoch: 1 step 1182, loss is 0.40224263072013855\n",
      "epoch: 1 step 1183, loss is 0.1798265278339386\n",
      "epoch: 1 step 1184, loss is 0.5039652585983276\n",
      "epoch: 1 step 1185, loss is 0.13534842431545258\n",
      "epoch: 1 step 1186, loss is 0.10237590968608856\n",
      "epoch: 1 step 1187, loss is 0.11380477249622345\n",
      "epoch: 1 step 1188, loss is 0.33532029390335083\n",
      "epoch: 1 step 1189, loss is 0.37075909972190857\n",
      "epoch: 1 step 1190, loss is 0.2595348656177521\n",
      "epoch: 1 step 1191, loss is 0.5487306714057922\n",
      "epoch: 1 step 1192, loss is 0.23060090839862823\n",
      "epoch: 1 step 1193, loss is 0.20298916101455688\n",
      "epoch: 1 step 1194, loss is 0.167954221367836\n",
      "epoch: 1 step 1195, loss is 0.31161487102508545\n",
      "epoch: 1 step 1196, loss is 0.294167160987854\n",
      "epoch: 1 step 1197, loss is 0.19163778424263\n",
      "epoch: 1 step 1198, loss is 0.15200237929821014\n",
      "epoch: 1 step 1199, loss is 0.32278865575790405\n",
      "epoch: 1 step 1200, loss is 0.7320305705070496\n",
      "epoch: 1 step 1201, loss is 0.2634473145008087\n",
      "epoch: 1 step 1202, loss is 0.1496431529521942\n",
      "epoch: 1 step 1203, loss is 0.33701348304748535\n",
      "epoch: 1 step 1204, loss is 0.1080637201666832\n",
      "epoch: 1 step 1205, loss is 0.41639846563339233\n",
      "epoch: 1 step 1206, loss is 0.11405153572559357\n",
      "epoch: 1 step 1207, loss is 0.11913920938968658\n",
      "epoch: 1 step 1208, loss is 0.31337475776672363\n",
      "epoch: 1 step 1209, loss is 0.08249074965715408\n",
      "epoch: 1 step 1210, loss is 0.1016281247138977\n",
      "epoch: 1 step 1211, loss is 0.1404246836900711\n",
      "epoch: 1 step 1212, loss is 0.34405234456062317\n",
      "epoch: 1 step 1213, loss is 0.19854076206684113\n",
      "epoch: 1 step 1214, loss is 0.12035379558801651\n",
      "epoch: 1 step 1215, loss is 0.13874436914920807\n",
      "epoch: 1 step 1216, loss is 0.06980980932712555\n",
      "epoch: 1 step 1217, loss is 0.12272334098815918\n",
      "epoch: 1 step 1218, loss is 0.11663737148046494\n",
      "epoch: 1 step 1219, loss is 0.22052861750125885\n",
      "epoch: 1 step 1220, loss is 0.15443752706050873\n",
      "epoch: 1 step 1221, loss is 0.20201179385185242\n",
      "epoch: 1 step 1222, loss is 0.2150571197271347\n",
      "epoch: 1 step 1223, loss is 0.21844343841075897\n",
      "epoch: 1 step 1224, loss is 0.030694296583533287\n",
      "epoch: 1 step 1225, loss is 0.04256812483072281\n",
      "epoch: 1 step 1226, loss is 0.0408121682703495\n",
      "epoch: 1 step 1227, loss is 0.22226330637931824\n",
      "epoch: 1 step 1228, loss is 0.0520462691783905\n",
      "epoch: 1 step 1229, loss is 0.1642502397298813\n",
      "epoch: 1 step 1230, loss is 0.4938809275627136\n",
      "epoch: 1 step 1231, loss is 0.07367879152297974\n",
      "epoch: 1 step 1232, loss is 0.19636599719524384\n",
      "epoch: 1 step 1233, loss is 0.05613357201218605\n",
      "epoch: 1 step 1234, loss is 0.18221279978752136\n",
      "epoch: 1 step 1235, loss is 0.17399460077285767\n",
      "epoch: 1 step 1236, loss is 0.21953904628753662\n",
      "epoch: 1 step 1237, loss is 0.12992781400680542\n",
      "epoch: 1 step 1238, loss is 0.21823962032794952\n",
      "epoch: 1 step 1239, loss is 0.06261825561523438\n",
      "epoch: 1 step 1240, loss is 0.059050578624010086\n",
      "epoch: 1 step 1241, loss is 0.05838501825928688\n",
      "epoch: 1 step 1242, loss is 0.38619691133499146\n",
      "epoch: 1 step 1243, loss is 0.07106852531433105\n",
      "epoch: 1 step 1244, loss is 0.15589046478271484\n",
      "epoch: 1 step 1245, loss is 0.04772113263607025\n",
      "epoch: 1 step 1246, loss is 0.21523457765579224\n",
      "epoch: 1 step 1247, loss is 0.5234687924385071\n",
      "epoch: 1 step 1248, loss is 0.4725988507270813\n",
      "epoch: 1 step 1249, loss is 0.10416189581155777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 1250, loss is 0.524069607257843\n",
      "epoch: 1 step 1251, loss is 0.2652841806411743\n",
      "epoch: 1 step 1252, loss is 0.2759210765361786\n",
      "epoch: 1 step 1253, loss is 0.18665245175361633\n",
      "epoch: 1 step 1254, loss is 0.30893442034721375\n",
      "epoch: 1 step 1255, loss is 0.23022381961345673\n",
      "epoch: 1 step 1256, loss is 0.12406717985868454\n",
      "epoch: 1 step 1257, loss is 0.35657501220703125\n",
      "epoch: 1 step 1258, loss is 0.1813289225101471\n",
      "epoch: 1 step 1259, loss is 0.19929412007331848\n",
      "epoch: 1 step 1260, loss is 0.3767518401145935\n",
      "epoch: 1 step 1261, loss is 0.045815952122211456\n",
      "epoch: 1 step 1262, loss is 0.3493342995643616\n",
      "epoch: 1 step 1263, loss is 0.2095005214214325\n",
      "epoch: 1 step 1264, loss is 0.038586486130952835\n",
      "epoch: 1 step 1265, loss is 0.21155467629432678\n",
      "epoch: 1 step 1266, loss is 0.1904488503932953\n",
      "epoch: 1 step 1267, loss is 0.30973947048187256\n",
      "epoch: 1 step 1268, loss is 0.0544302798807621\n",
      "epoch: 1 step 1269, loss is 0.06591106206178665\n",
      "epoch: 1 step 1270, loss is 0.48256736993789673\n",
      "epoch: 1 step 1271, loss is 0.13080522418022156\n",
      "epoch: 1 step 1272, loss is 0.19014829397201538\n",
      "epoch: 1 step 1273, loss is 0.22884391248226166\n",
      "epoch: 1 step 1274, loss is 0.08307930827140808\n",
      "epoch: 1 step 1275, loss is 0.3609071373939514\n",
      "epoch: 1 step 1276, loss is 0.03559282049536705\n",
      "epoch: 1 step 1277, loss is 0.1531498283147812\n",
      "epoch: 1 step 1278, loss is 0.18672996759414673\n",
      "epoch: 1 step 1279, loss is 0.2806112468242645\n",
      "epoch: 1 step 1280, loss is 0.27941325306892395\n",
      "epoch: 1 step 1281, loss is 0.3150455355644226\n",
      "epoch: 1 step 1282, loss is 0.42465540766716003\n",
      "epoch: 1 step 1283, loss is 0.06855327636003494\n",
      "epoch: 1 step 1284, loss is 0.07230948656797409\n",
      "epoch: 1 step 1285, loss is 0.2690505385398865\n",
      "epoch: 1 step 1286, loss is 0.24108488857746124\n",
      "epoch: 1 step 1287, loss is 0.15547722578048706\n",
      "epoch: 1 step 1288, loss is 0.13465237617492676\n",
      "epoch: 1 step 1289, loss is 0.6730027794837952\n",
      "epoch: 1 step 1290, loss is 0.13007678091526031\n",
      "epoch: 1 step 1291, loss is 0.02121412381529808\n",
      "epoch: 1 step 1292, loss is 0.049784980714321136\n",
      "epoch: 1 step 1293, loss is 0.11070896685123444\n",
      "epoch: 1 step 1294, loss is 0.2565460205078125\n",
      "epoch: 1 step 1295, loss is 0.05546726658940315\n",
      "epoch: 1 step 1296, loss is 0.11611609905958176\n",
      "epoch: 1 step 1297, loss is 0.09831753373146057\n",
      "epoch: 1 step 1298, loss is 0.05479292571544647\n",
      "epoch: 1 step 1299, loss is 0.21358942985534668\n",
      "epoch: 1 step 1300, loss is 0.325830340385437\n",
      "epoch: 1 step 1301, loss is 0.5012524127960205\n",
      "epoch: 1 step 1302, loss is 0.294604629278183\n",
      "epoch: 1 step 1303, loss is 0.15517286956310272\n",
      "epoch: 1 step 1304, loss is 0.039048220962285995\n",
      "epoch: 1 step 1305, loss is 0.0981094092130661\n",
      "epoch: 1 step 1306, loss is 0.17601901292800903\n",
      "epoch: 1 step 1307, loss is 0.1788097769021988\n",
      "epoch: 1 step 1308, loss is 0.27252811193466187\n",
      "epoch: 1 step 1309, loss is 0.2025330811738968\n",
      "epoch: 1 step 1310, loss is 0.3006960153579712\n",
      "epoch: 1 step 1311, loss is 0.2401321530342102\n",
      "epoch: 1 step 1312, loss is 0.11384464800357819\n",
      "epoch: 1 step 1313, loss is 0.13461089134216309\n",
      "epoch: 1 step 1314, loss is 0.12387176603078842\n",
      "epoch: 1 step 1315, loss is 0.034613706171512604\n",
      "epoch: 1 step 1316, loss is 0.191122904419899\n",
      "epoch: 1 step 1317, loss is 0.03321123495697975\n",
      "epoch: 1 step 1318, loss is 0.13519324362277985\n",
      "epoch: 1 step 1319, loss is 0.23534858226776123\n",
      "epoch: 1 step 1320, loss is 0.036745283752679825\n",
      "epoch: 1 step 1321, loss is 0.37704044580459595\n",
      "epoch: 1 step 1322, loss is 0.4474242031574249\n",
      "epoch: 1 step 1323, loss is 0.26421141624450684\n",
      "epoch: 1 step 1324, loss is 0.4650835692882538\n",
      "epoch: 1 step 1325, loss is 0.1605958789587021\n",
      "epoch: 1 step 1326, loss is 0.09721336513757706\n",
      "epoch: 1 step 1327, loss is 0.23781290650367737\n",
      "epoch: 1 step 1328, loss is 0.2742028534412384\n",
      "epoch: 1 step 1329, loss is 0.2173849642276764\n",
      "epoch: 1 step 1330, loss is 0.13021768629550934\n",
      "epoch: 1 step 1331, loss is 0.13957762718200684\n",
      "epoch: 1 step 1332, loss is 0.05297097936272621\n",
      "epoch: 1 step 1333, loss is 0.2608557343482971\n",
      "epoch: 1 step 1334, loss is 0.34402093291282654\n",
      "epoch: 1 step 1335, loss is 0.11400490254163742\n",
      "epoch: 1 step 1336, loss is 0.25951486825942993\n",
      "epoch: 1 step 1337, loss is 0.31313174962997437\n",
      "epoch: 1 step 1338, loss is 0.19678816199302673\n",
      "epoch: 1 step 1339, loss is 0.14140719175338745\n",
      "epoch: 1 step 1340, loss is 0.06490781158208847\n",
      "epoch: 1 step 1341, loss is 0.2738936245441437\n",
      "epoch: 1 step 1342, loss is 0.14719265699386597\n",
      "epoch: 1 step 1343, loss is 0.13369572162628174\n",
      "epoch: 1 step 1344, loss is 0.18537528812885284\n",
      "epoch: 1 step 1345, loss is 0.1548815816640854\n",
      "epoch: 1 step 1346, loss is 0.20167259871959686\n",
      "epoch: 1 step 1347, loss is 0.04860328882932663\n",
      "epoch: 1 step 1348, loss is 0.26139897108078003\n",
      "epoch: 1 step 1349, loss is 0.27616557478904724\n",
      "epoch: 1 step 1350, loss is 0.09206501394510269\n",
      "epoch: 1 step 1351, loss is 0.1818128377199173\n",
      "epoch: 1 step 1352, loss is 0.12076954543590546\n",
      "epoch: 1 step 1353, loss is 0.21239732205867767\n",
      "epoch: 1 step 1354, loss is 0.3705439865589142\n",
      "epoch: 1 step 1355, loss is 0.35355713963508606\n",
      "epoch: 1 step 1356, loss is 0.231022447347641\n",
      "epoch: 1 step 1357, loss is 0.22299233078956604\n",
      "epoch: 1 step 1358, loss is 0.014381278306245804\n",
      "epoch: 1 step 1359, loss is 0.19613440334796906\n",
      "epoch: 1 step 1360, loss is 0.45969653129577637\n",
      "epoch: 1 step 1361, loss is 0.07987777143716812\n",
      "epoch: 1 step 1362, loss is 0.2917234003543854\n",
      "epoch: 1 step 1363, loss is 0.21176476776599884\n",
      "epoch: 1 step 1364, loss is 0.15656745433807373\n",
      "epoch: 1 step 1365, loss is 0.1705927699804306\n",
      "epoch: 1 step 1366, loss is 0.28086960315704346\n",
      "epoch: 1 step 1367, loss is 0.27005940675735474\n",
      "epoch: 1 step 1368, loss is 0.14511409401893616\n",
      "epoch: 1 step 1369, loss is 0.09363985061645508\n",
      "epoch: 1 step 1370, loss is 0.18109314143657684\n",
      "epoch: 1 step 1371, loss is 0.22667500376701355\n",
      "epoch: 1 step 1372, loss is 0.4181455969810486\n",
      "epoch: 1 step 1373, loss is 0.060120873153209686\n",
      "epoch: 1 step 1374, loss is 0.37927189469337463\n",
      "epoch: 1 step 1375, loss is 0.21917177736759186\n",
      "epoch: 1 step 1376, loss is 0.554511547088623\n",
      "epoch: 1 step 1377, loss is 0.430952787399292\n",
      "epoch: 1 step 1378, loss is 0.5707189440727234\n",
      "epoch: 1 step 1379, loss is 0.304430216550827\n",
      "epoch: 1 step 1380, loss is 0.15270961821079254\n",
      "epoch: 1 step 1381, loss is 0.12651991844177246\n",
      "epoch: 1 step 1382, loss is 0.15000121295452118\n",
      "epoch: 1 step 1383, loss is 0.1347784847021103\n",
      "epoch: 1 step 1384, loss is 0.13474896550178528\n",
      "epoch: 1 step 1385, loss is 0.1895076185464859\n",
      "epoch: 1 step 1386, loss is 0.19797468185424805\n",
      "epoch: 1 step 1387, loss is 0.378776490688324\n",
      "epoch: 1 step 1388, loss is 0.3142922818660736\n",
      "epoch: 1 step 1389, loss is 0.18020403385162354\n",
      "epoch: 1 step 1390, loss is 0.20521847903728485\n",
      "epoch: 1 step 1391, loss is 0.15917985141277313\n",
      "epoch: 1 step 1392, loss is 0.12527571618556976\n",
      "epoch: 1 step 1393, loss is 0.07082045078277588\n",
      "epoch: 1 step 1394, loss is 0.0378243662416935\n",
      "epoch: 1 step 1395, loss is 0.3067173957824707\n",
      "epoch: 1 step 1396, loss is 0.09532315284013748\n",
      "epoch: 1 step 1397, loss is 0.22564195096492767\n",
      "epoch: 1 step 1398, loss is 0.06700921058654785\n",
      "epoch: 1 step 1399, loss is 0.19249945878982544\n",
      "epoch: 1 step 1400, loss is 0.09617947787046432\n",
      "epoch: 1 step 1401, loss is 0.39516302943229675\n",
      "epoch: 1 step 1402, loss is 0.09691809862852097\n",
      "epoch: 1 step 1403, loss is 0.048507556319236755\n",
      "epoch: 1 step 1404, loss is 0.33102044463157654\n",
      "epoch: 1 step 1405, loss is 0.07082463055849075\n",
      "epoch: 1 step 1406, loss is 0.12862513959407806\n",
      "epoch: 1 step 1407, loss is 0.42798691987991333\n",
      "epoch: 1 step 1408, loss is 0.20406198501586914\n",
      "epoch: 1 step 1409, loss is 0.23511460423469543\n",
      "epoch: 1 step 1410, loss is 0.2709139585494995\n",
      "epoch: 1 step 1411, loss is 0.19246803224086761\n",
      "epoch: 1 step 1412, loss is 0.20838122069835663\n",
      "epoch: 1 step 1413, loss is 0.21794021129608154\n",
      "epoch: 1 step 1414, loss is 0.08478481322526932\n",
      "epoch: 1 step 1415, loss is 0.012655519880354404\n",
      "epoch: 1 step 1416, loss is 0.14444799721240997\n",
      "epoch: 1 step 1417, loss is 0.037335995584726334\n",
      "epoch: 1 step 1418, loss is 0.06604143232107162\n",
      "epoch: 1 step 1419, loss is 0.14586074650287628\n",
      "epoch: 1 step 1420, loss is 0.1347969025373459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 1421, loss is 0.2732638716697693\n",
      "epoch: 1 step 1422, loss is 0.28914135694503784\n",
      "epoch: 1 step 1423, loss is 0.18879273533821106\n",
      "epoch: 1 step 1424, loss is 0.13441845774650574\n",
      "epoch: 1 step 1425, loss is 0.09011184424161911\n",
      "epoch: 1 step 1426, loss is 0.1790235936641693\n",
      "epoch: 1 step 1427, loss is 0.18365859985351562\n",
      "epoch: 1 step 1428, loss is 0.030408916994929314\n",
      "epoch: 1 step 1429, loss is 0.24467791616916656\n",
      "epoch: 1 step 1430, loss is 0.29295310378074646\n",
      "epoch: 1 step 1431, loss is 0.07330065965652466\n",
      "epoch: 1 step 1432, loss is 0.11970701068639755\n",
      "epoch: 1 step 1433, loss is 0.19104799628257751\n",
      "epoch: 1 step 1434, loss is 0.22241932153701782\n",
      "epoch: 1 step 1435, loss is 0.2240758091211319\n",
      "epoch: 1 step 1436, loss is 0.10165629535913467\n",
      "epoch: 1 step 1437, loss is 0.20622384548187256\n",
      "epoch: 1 step 1438, loss is 0.22979219257831573\n",
      "epoch: 1 step 1439, loss is 0.4825741946697235\n",
      "epoch: 1 step 1440, loss is 0.34842449426651\n",
      "epoch: 1 step 1441, loss is 0.24044188857078552\n",
      "epoch: 1 step 1442, loss is 0.11065179854631424\n",
      "epoch: 1 step 1443, loss is 0.11732476949691772\n",
      "epoch: 1 step 1444, loss is 0.17063923180103302\n",
      "epoch: 1 step 1445, loss is 0.14149747788906097\n",
      "epoch: 1 step 1446, loss is 0.17800576984882355\n",
      "epoch: 1 step 1447, loss is 0.12914671003818512\n",
      "epoch: 1 step 1448, loss is 0.287578821182251\n",
      "epoch: 1 step 1449, loss is 0.1374102085828781\n",
      "epoch: 1 step 1450, loss is 0.16122445464134216\n",
      "epoch: 1 step 1451, loss is 0.09191429615020752\n",
      "epoch: 1 step 1452, loss is 0.08258654922246933\n",
      "epoch: 1 step 1453, loss is 0.026686370372772217\n",
      "epoch: 1 step 1454, loss is 0.14997930824756622\n",
      "epoch: 1 step 1455, loss is 0.2664296329021454\n",
      "epoch: 1 step 1456, loss is 0.2523840069770813\n",
      "epoch: 1 step 1457, loss is 0.26017773151397705\n",
      "epoch: 1 step 1458, loss is 0.18211503326892853\n",
      "epoch: 1 step 1459, loss is 0.039881281554698944\n",
      "epoch: 1 step 1460, loss is 0.1660570502281189\n",
      "epoch: 1 step 1461, loss is 0.3116016089916229\n",
      "epoch: 1 step 1462, loss is 0.14994260668754578\n",
      "epoch: 1 step 1463, loss is 0.3222777545452118\n",
      "epoch: 1 step 1464, loss is 0.1977226287126541\n",
      "epoch: 1 step 1465, loss is 0.11967132985591888\n",
      "epoch: 1 step 1466, loss is 0.10561515390872955\n",
      "epoch: 1 step 1467, loss is 0.2444068342447281\n",
      "epoch: 1 step 1468, loss is 0.2793606221675873\n",
      "epoch: 1 step 1469, loss is 0.031023547053337097\n",
      "epoch: 1 step 1470, loss is 0.025633910670876503\n",
      "epoch: 1 step 1471, loss is 0.18152564764022827\n",
      "epoch: 1 step 1472, loss is 0.06083272397518158\n",
      "epoch: 1 step 1473, loss is 0.2525058686733246\n",
      "epoch: 1 step 1474, loss is 0.15242691338062286\n",
      "epoch: 1 step 1475, loss is 0.07130670547485352\n",
      "epoch: 1 step 1476, loss is 0.0347457155585289\n",
      "epoch: 1 step 1477, loss is 0.147914320230484\n",
      "epoch: 1 step 1478, loss is 0.060940198600292206\n",
      "epoch: 1 step 1479, loss is 0.4348907768726349\n",
      "epoch: 1 step 1480, loss is 0.2367706149816513\n",
      "epoch: 1 step 1481, loss is 0.3024718463420868\n",
      "epoch: 1 step 1482, loss is 0.11994308233261108\n",
      "epoch: 1 step 1483, loss is 0.05357520282268524\n",
      "epoch: 1 step 1484, loss is 0.31533414125442505\n",
      "epoch: 1 step 1485, loss is 0.3344602882862091\n",
      "epoch: 1 step 1486, loss is 0.08471953123807907\n",
      "epoch: 1 step 1487, loss is 0.0591905303299427\n",
      "epoch: 1 step 1488, loss is 0.12241467088460922\n",
      "epoch: 1 step 1489, loss is 0.1028100997209549\n",
      "epoch: 1 step 1490, loss is 0.0971469059586525\n",
      "epoch: 1 step 1491, loss is 0.17085614800453186\n",
      "epoch: 1 step 1492, loss is 0.20307905972003937\n",
      "epoch: 1 step 1493, loss is 0.15554949641227722\n",
      "epoch: 1 step 1494, loss is 0.152117058634758\n",
      "epoch: 1 step 1495, loss is 0.036166153848171234\n",
      "epoch: 1 step 1496, loss is 0.0663430467247963\n",
      "epoch: 1 step 1497, loss is 0.06434255093336105\n",
      "epoch: 1 step 1498, loss is 0.028085848316550255\n",
      "epoch: 1 step 1499, loss is 0.10241769999265671\n",
      "epoch: 1 step 1500, loss is 0.22307536005973816\n",
      "epoch: 1 step 1501, loss is 0.016080163419246674\n",
      "epoch: 1 step 1502, loss is 0.2076130211353302\n",
      "epoch: 1 step 1503, loss is 0.14079713821411133\n",
      "epoch: 1 step 1504, loss is 0.17134781181812286\n",
      "epoch: 1 step 1505, loss is 0.24002285301685333\n",
      "epoch: 1 step 1506, loss is 0.07507986575365067\n",
      "epoch: 1 step 1507, loss is 0.015371493995189667\n",
      "epoch: 1 step 1508, loss is 0.35458993911743164\n",
      "epoch: 1 step 1509, loss is 0.13178271055221558\n",
      "epoch: 1 step 1510, loss is 0.07642673701047897\n",
      "epoch: 1 step 1511, loss is 0.24822889268398285\n",
      "epoch: 1 step 1512, loss is 0.16871564090251923\n",
      "epoch: 1 step 1513, loss is 0.40745192766189575\n",
      "epoch: 1 step 1514, loss is 0.2804504632949829\n",
      "epoch: 1 step 1515, loss is 0.1647489070892334\n",
      "epoch: 1 step 1516, loss is 0.2085198163986206\n",
      "epoch: 1 step 1517, loss is 0.011187231168150902\n",
      "epoch: 1 step 1518, loss is 0.06131260469555855\n",
      "epoch: 1 step 1519, loss is 0.13793037831783295\n",
      "epoch: 1 step 1520, loss is 0.08268798887729645\n",
      "epoch: 1 step 1521, loss is 0.2918003499507904\n",
      "epoch: 1 step 1522, loss is 0.1475374847650528\n",
      "epoch: 1 step 1523, loss is 0.05017763748764992\n",
      "epoch: 1 step 1524, loss is 0.4219624102115631\n",
      "epoch: 1 step 1525, loss is 0.07047577202320099\n",
      "epoch: 1 step 1526, loss is 0.36795493960380554\n",
      "epoch: 1 step 1527, loss is 0.205402672290802\n",
      "epoch: 1 step 1528, loss is 0.3113693594932556\n",
      "epoch: 1 step 1529, loss is 0.018939964473247528\n",
      "epoch: 1 step 1530, loss is 0.11963711678981781\n",
      "epoch: 1 step 1531, loss is 0.26485997438430786\n",
      "epoch: 1 step 1532, loss is 0.11608637869358063\n",
      "epoch: 1 step 1533, loss is 0.038664810359478\n",
      "epoch: 1 step 1534, loss is 0.16135820746421814\n",
      "epoch: 1 step 1535, loss is 0.027460472658276558\n",
      "epoch: 1 step 1536, loss is 0.10712457448244095\n",
      "epoch: 1 step 1537, loss is 0.2344018816947937\n",
      "epoch: 1 step 1538, loss is 0.535405158996582\n",
      "epoch: 1 step 1539, loss is 0.22821743786334991\n",
      "epoch: 1 step 1540, loss is 0.1968739926815033\n",
      "epoch: 1 step 1541, loss is 0.29195213317871094\n",
      "epoch: 1 step 1542, loss is 0.025655176490545273\n",
      "epoch: 1 step 1543, loss is 0.07978092133998871\n",
      "epoch: 1 step 1544, loss is 0.1264479160308838\n",
      "epoch: 1 step 1545, loss is 0.22964981198310852\n",
      "epoch: 1 step 1546, loss is 0.12184898555278778\n",
      "epoch: 1 step 1547, loss is 0.4731254279613495\n",
      "epoch: 1 step 1548, loss is 0.03339137136936188\n",
      "epoch: 1 step 1549, loss is 0.014725659042596817\n",
      "epoch: 1 step 1550, loss is 0.34388190507888794\n",
      "epoch: 1 step 1551, loss is 0.2549399733543396\n",
      "epoch: 1 step 1552, loss is 0.24979887902736664\n",
      "epoch: 1 step 1553, loss is 0.19499702751636505\n",
      "epoch: 1 step 1554, loss is 0.1645338535308838\n",
      "epoch: 1 step 1555, loss is 0.24743524193763733\n",
      "epoch: 1 step 1556, loss is 0.03985191136598587\n",
      "epoch: 1 step 1557, loss is 0.07091329246759415\n",
      "epoch: 1 step 1558, loss is 0.052609167993068695\n",
      "epoch: 1 step 1559, loss is 0.07124129682779312\n",
      "epoch: 1 step 1560, loss is 0.0961894765496254\n",
      "epoch: 1 step 1561, loss is 0.0910254493355751\n",
      "epoch: 1 step 1562, loss is 0.11323731392621994\n",
      "epoch: 1 step 1563, loss is 0.17447282373905182\n",
      "epoch: 1 step 1564, loss is 0.27797597646713257\n",
      "epoch: 1 step 1565, loss is 0.12834854423999786\n",
      "epoch: 1 step 1566, loss is 0.04837791621685028\n",
      "epoch: 1 step 1567, loss is 0.23610715568065643\n",
      "epoch: 1 step 1568, loss is 0.00686205830425024\n",
      "epoch: 1 step 1569, loss is 0.18006019294261932\n",
      "epoch: 1 step 1570, loss is 0.0256658885627985\n",
      "epoch: 1 step 1571, loss is 0.15297570824623108\n",
      "epoch: 1 step 1572, loss is 0.1414184272289276\n",
      "epoch: 1 step 1573, loss is 0.17526394128799438\n",
      "epoch: 1 step 1574, loss is 0.08118576556444168\n",
      "epoch: 1 step 1575, loss is 0.10771070420742035\n",
      "epoch: 1 step 1576, loss is 0.03570283204317093\n",
      "epoch: 1 step 1577, loss is 0.11714303493499756\n",
      "epoch: 1 step 1578, loss is 0.1816290020942688\n",
      "epoch: 1 step 1579, loss is 0.021464530378580093\n",
      "epoch: 1 step 1580, loss is 0.11372466385364532\n",
      "epoch: 1 step 1581, loss is 0.17419934272766113\n",
      "epoch: 1 step 1582, loss is 0.011160505935549736\n",
      "epoch: 1 step 1583, loss is 0.24291273951530457\n",
      "epoch: 1 step 1584, loss is 0.010671941563487053\n",
      "epoch: 1 step 1585, loss is 0.017322441563010216\n",
      "epoch: 1 step 1586, loss is 0.2335474044084549\n",
      "epoch: 1 step 1587, loss is 0.2556104063987732\n",
      "epoch: 1 step 1588, loss is 0.0648474395275116\n",
      "epoch: 1 step 1589, loss is 0.22502899169921875\n",
      "epoch: 1 step 1590, loss is 0.47354650497436523\n",
      "epoch: 1 step 1591, loss is 0.2790185511112213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 1592, loss is 0.037289269268512726\n",
      "epoch: 1 step 1593, loss is 0.6669546961784363\n",
      "epoch: 1 step 1594, loss is 0.027973078191280365\n",
      "epoch: 1 step 1595, loss is 0.3043333888053894\n",
      "epoch: 1 step 1596, loss is 0.26716819405555725\n",
      "epoch: 1 step 1597, loss is 0.3676808476448059\n",
      "epoch: 1 step 1598, loss is 0.04774334654211998\n",
      "epoch: 1 step 1599, loss is 0.1505802571773529\n",
      "epoch: 1 step 1600, loss is 0.060209549963474274\n",
      "epoch: 1 step 1601, loss is 0.1517183780670166\n",
      "epoch: 1 step 1602, loss is 0.03348312899470329\n",
      "epoch: 1 step 1603, loss is 0.2172851860523224\n",
      "epoch: 1 step 1604, loss is 0.16908381879329681\n",
      "epoch: 1 step 1605, loss is 0.4056672155857086\n",
      "epoch: 1 step 1606, loss is 0.3545580506324768\n",
      "epoch: 1 step 1607, loss is 0.0785195454955101\n",
      "epoch: 1 step 1608, loss is 0.06628265231847763\n",
      "epoch: 1 step 1609, loss is 0.17911334335803986\n",
      "epoch: 1 step 1610, loss is 0.30736130475997925\n",
      "epoch: 1 step 1611, loss is 0.22257380187511444\n",
      "epoch: 1 step 1612, loss is 0.14600497484207153\n",
      "epoch: 1 step 1613, loss is 0.05811571329832077\n",
      "epoch: 1 step 1614, loss is 0.2594680190086365\n",
      "epoch: 1 step 1615, loss is 0.14777813851833344\n",
      "epoch: 1 step 1616, loss is 0.21176908910274506\n",
      "epoch: 1 step 1617, loss is 0.08806657046079636\n",
      "epoch: 1 step 1618, loss is 0.08265901356935501\n",
      "epoch: 1 step 1619, loss is 0.06283356994390488\n",
      "epoch: 1 step 1620, loss is 0.244098961353302\n",
      "epoch: 1 step 1621, loss is 0.16140873730182648\n",
      "epoch: 1 step 1622, loss is 0.4248126149177551\n",
      "epoch: 1 step 1623, loss is 0.5076652765274048\n",
      "epoch: 1 step 1624, loss is 0.12746888399124146\n",
      "epoch: 1 step 1625, loss is 0.1834188550710678\n",
      "epoch: 1 step 1626, loss is 0.14382439851760864\n",
      "epoch: 1 step 1627, loss is 0.19014105200767517\n",
      "epoch: 1 step 1628, loss is 0.30281925201416016\n",
      "epoch: 1 step 1629, loss is 0.09651453047990799\n",
      "epoch: 1 step 1630, loss is 0.2950707972049713\n",
      "epoch: 1 step 1631, loss is 0.033858783543109894\n",
      "epoch: 1 step 1632, loss is 0.08982428908348083\n",
      "epoch: 1 step 1633, loss is 0.18717190623283386\n",
      "epoch: 1 step 1634, loss is 0.22012434899806976\n",
      "epoch: 1 step 1635, loss is 0.23406831920146942\n",
      "epoch: 1 step 1636, loss is 0.19017261266708374\n",
      "epoch: 1 step 1637, loss is 0.10751032829284668\n",
      "epoch: 1 step 1638, loss is 0.020188376307487488\n",
      "epoch: 1 step 1639, loss is 0.027881013229489326\n",
      "epoch: 1 step 1640, loss is 0.07523792237043381\n",
      "epoch: 1 step 1641, loss is 0.29369279742240906\n",
      "epoch: 1 step 1642, loss is 0.21822905540466309\n",
      "epoch: 1 step 1643, loss is 0.29793232679367065\n",
      "epoch: 1 step 1644, loss is 0.043750420212745667\n",
      "epoch: 1 step 1645, loss is 0.09380664676427841\n",
      "epoch: 1 step 1646, loss is 0.28589677810668945\n",
      "epoch: 1 step 1647, loss is 0.026868261396884918\n",
      "epoch: 1 step 1648, loss is 0.18957915902137756\n",
      "epoch: 1 step 1649, loss is 0.17896448075771332\n",
      "epoch: 1 step 1650, loss is 0.10533048212528229\n",
      "epoch: 1 step 1651, loss is 0.19312293827533722\n",
      "epoch: 1 step 1652, loss is 0.047780029475688934\n",
      "epoch: 1 step 1653, loss is 0.043677132576704025\n",
      "epoch: 1 step 1654, loss is 0.12250451743602753\n",
      "epoch: 1 step 1655, loss is 0.24486027657985687\n",
      "epoch: 1 step 1656, loss is 0.047279682010412216\n",
      "epoch: 1 step 1657, loss is 0.06328191608190536\n",
      "epoch: 1 step 1658, loss is 0.08435419946908951\n",
      "epoch: 1 step 1659, loss is 0.043745022267103195\n",
      "epoch: 1 step 1660, loss is 0.2011641561985016\n",
      "epoch: 1 step 1661, loss is 0.36145713925361633\n",
      "epoch: 1 step 1662, loss is 0.10772320628166199\n",
      "epoch: 1 step 1663, loss is 0.08749391883611679\n",
      "epoch: 1 step 1664, loss is 0.30133727192878723\n",
      "epoch: 1 step 1665, loss is 0.10319367796182632\n",
      "epoch: 1 step 1666, loss is 0.09821230173110962\n",
      "epoch: 1 step 1667, loss is 0.016956666484475136\n",
      "epoch: 1 step 1668, loss is 0.0710502415895462\n",
      "epoch: 1 step 1669, loss is 0.007008133456110954\n",
      "epoch: 1 step 1670, loss is 0.21395447850227356\n",
      "epoch: 1 step 1671, loss is 0.128061443567276\n",
      "epoch: 1 step 1672, loss is 0.20678196847438812\n",
      "epoch: 1 step 1673, loss is 0.22415968775749207\n",
      "epoch: 1 step 1674, loss is 0.08397642523050308\n",
      "epoch: 1 step 1675, loss is 0.18893855810165405\n",
      "epoch: 1 step 1676, loss is 0.20789159834384918\n",
      "epoch: 1 step 1677, loss is 0.3421628773212433\n",
      "epoch: 1 step 1678, loss is 0.08329568058252335\n",
      "epoch: 1 step 1679, loss is 0.10777005553245544\n",
      "epoch: 1 step 1680, loss is 0.28770652413368225\n",
      "epoch: 1 step 1681, loss is 0.16173502802848816\n",
      "epoch: 1 step 1682, loss is 0.08911692351102829\n",
      "epoch: 1 step 1683, loss is 0.09613072127103806\n",
      "epoch: 1 step 1684, loss is 0.0196407288312912\n",
      "epoch: 1 step 1685, loss is 0.14691004157066345\n",
      "epoch: 1 step 1686, loss is 0.16538022458553314\n",
      "epoch: 1 step 1687, loss is 0.17081548273563385\n",
      "epoch: 1 step 1688, loss is 0.16752029955387115\n",
      "epoch: 1 step 1689, loss is 0.07556203007698059\n",
      "epoch: 1 step 1690, loss is 0.05724847689270973\n",
      "epoch: 1 step 1691, loss is 0.07723591476678848\n",
      "epoch: 1 step 1692, loss is 0.22748827934265137\n",
      "epoch: 1 step 1693, loss is 0.20023450255393982\n",
      "epoch: 1 step 1694, loss is 0.045707911252975464\n",
      "epoch: 1 step 1695, loss is 0.11219199001789093\n",
      "epoch: 1 step 1696, loss is 0.17740048468112946\n",
      "epoch: 1 step 1697, loss is 0.058840714395046234\n",
      "epoch: 1 step 1698, loss is 0.22153080999851227\n",
      "epoch: 1 step 1699, loss is 0.07449723035097122\n",
      "epoch: 1 step 1700, loss is 0.3810114860534668\n",
      "epoch: 1 step 1701, loss is 0.08629638701677322\n",
      "epoch: 1 step 1702, loss is 0.2227892279624939\n",
      "epoch: 1 step 1703, loss is 0.16094565391540527\n",
      "epoch: 1 step 1704, loss is 0.18608491122722626\n",
      "epoch: 1 step 1705, loss is 0.12596172094345093\n",
      "epoch: 1 step 1706, loss is 0.20060348510742188\n",
      "epoch: 1 step 1707, loss is 0.2897909879684448\n",
      "epoch: 1 step 1708, loss is 0.14372855424880981\n",
      "epoch: 1 step 1709, loss is 0.09452032297849655\n",
      "epoch: 1 step 1710, loss is 0.1649545133113861\n",
      "epoch: 1 step 1711, loss is 0.13143958151340485\n",
      "epoch: 1 step 1712, loss is 0.08895035833120346\n",
      "epoch: 1 step 1713, loss is 0.28394749760627747\n",
      "epoch: 1 step 1714, loss is 0.1974935084581375\n",
      "epoch: 1 step 1715, loss is 0.10568737238645554\n",
      "epoch: 1 step 1716, loss is 0.01058405451476574\n",
      "epoch: 1 step 1717, loss is 0.1257704347372055\n",
      "epoch: 1 step 1718, loss is 0.0896354541182518\n",
      "epoch: 1 step 1719, loss is 0.3377484083175659\n",
      "epoch: 1 step 1720, loss is 0.17294782400131226\n",
      "epoch: 1 step 1721, loss is 0.11671129614114761\n",
      "epoch: 1 step 1722, loss is 0.06993158161640167\n",
      "epoch: 1 step 1723, loss is 0.08449213206768036\n",
      "epoch: 1 step 1724, loss is 0.0490744486451149\n",
      "epoch: 1 step 1725, loss is 0.1778782606124878\n",
      "epoch: 1 step 1726, loss is 0.016006093472242355\n",
      "epoch: 1 step 1727, loss is 0.07804140448570251\n",
      "epoch: 1 step 1728, loss is 0.09830362349748611\n",
      "epoch: 1 step 1729, loss is 0.4913692772388458\n",
      "epoch: 1 step 1730, loss is 0.11207643896341324\n",
      "epoch: 1 step 1731, loss is 0.044747576117515564\n",
      "epoch: 1 step 1732, loss is 0.0635237842798233\n",
      "epoch: 1 step 1733, loss is 0.036319926381111145\n",
      "epoch: 1 step 1734, loss is 0.22375133633613586\n",
      "epoch: 1 step 1735, loss is 0.12693189084529877\n",
      "epoch: 1 step 1736, loss is 0.1794988363981247\n",
      "epoch: 1 step 1737, loss is 0.0602247416973114\n",
      "epoch: 1 step 1738, loss is 0.37853333353996277\n",
      "epoch: 1 step 1739, loss is 0.2785823345184326\n",
      "epoch: 1 step 1740, loss is 0.11330924183130264\n",
      "epoch: 1 step 1741, loss is 0.24572473764419556\n",
      "epoch: 1 step 1742, loss is 0.13654503226280212\n",
      "epoch: 1 step 1743, loss is 0.08993854373693466\n",
      "epoch: 1 step 1744, loss is 0.14939749240875244\n",
      "epoch: 1 step 1745, loss is 0.25143638253211975\n",
      "epoch: 1 step 1746, loss is 0.19276076555252075\n",
      "epoch: 1 step 1747, loss is 0.1520737111568451\n",
      "epoch: 1 step 1748, loss is 0.21680326759815216\n",
      "epoch: 1 step 1749, loss is 0.2511528730392456\n",
      "epoch: 1 step 1750, loss is 0.11513651907444\n",
      "epoch: 1 step 1751, loss is 0.10224784165620804\n",
      "epoch: 1 step 1752, loss is 0.20663639903068542\n",
      "epoch: 1 step 1753, loss is 0.061586134135723114\n",
      "epoch: 1 step 1754, loss is 0.039487749338150024\n",
      "epoch: 1 step 1755, loss is 0.2036251574754715\n",
      "epoch: 1 step 1756, loss is 0.03966877609491348\n",
      "epoch: 1 step 1757, loss is 0.027231315150856972\n",
      "epoch: 1 step 1758, loss is 0.11806073784828186\n",
      "epoch: 1 step 1759, loss is 0.043962445110082626\n",
      "epoch: 1 step 1760, loss is 0.20480386912822723\n",
      "epoch: 1 step 1761, loss is 0.1087326630949974\n",
      "epoch: 1 step 1762, loss is 0.0780656635761261\n",
      "epoch: 1 step 1763, loss is 0.19735795259475708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step 1764, loss is 0.18277199566364288\n",
      "epoch: 1 step 1765, loss is 0.1360340714454651\n",
      "epoch: 1 step 1766, loss is 0.017330918461084366\n",
      "epoch: 1 step 1767, loss is 0.13024410605430603\n",
      "epoch: 1 step 1768, loss is 0.29709434509277344\n",
      "epoch: 1 step 1769, loss is 0.10498026013374329\n",
      "epoch: 1 step 1770, loss is 0.11527147144079208\n",
      "epoch: 1 step 1771, loss is 0.345134437084198\n",
      "epoch: 1 step 1772, loss is 0.2717594802379608\n",
      "epoch: 1 step 1773, loss is 0.2283378392457962\n",
      "epoch: 1 step 1774, loss is 0.0384673997759819\n",
      "epoch: 1 step 1775, loss is 0.176451176404953\n",
      "epoch: 1 step 1776, loss is 0.09406087547540665\n",
      "epoch: 1 step 1777, loss is 0.10655457526445389\n",
      "epoch: 1 step 1778, loss is 0.11743699014186859\n",
      "epoch: 1 step 1779, loss is 0.20475371181964874\n",
      "epoch: 1 step 1780, loss is 0.11362048238515854\n",
      "epoch: 1 step 1781, loss is 0.16925252974033356\n",
      "epoch: 1 step 1782, loss is 0.1613941192626953\n",
      "epoch: 1 step 1783, loss is 0.16446731984615326\n",
      "epoch: 1 step 1784, loss is 0.2628989517688751\n",
      "epoch: 1 step 1785, loss is 0.2599729597568512\n",
      "epoch: 1 step 1786, loss is 0.07843288779258728\n",
      "epoch: 1 step 1787, loss is 0.00616246834397316\n",
      "epoch: 1 step 1788, loss is 0.14303813874721527\n",
      "epoch: 1 step 1789, loss is 0.09004691243171692\n",
      "epoch: 1 step 1790, loss is 0.0073612225241959095\n",
      "epoch: 1 step 1791, loss is 0.11986434459686279\n",
      "epoch: 1 step 1792, loss is 0.37537509202957153\n",
      "epoch: 1 step 1793, loss is 0.03435497358441353\n",
      "epoch: 1 step 1794, loss is 0.17364943027496338\n",
      "epoch: 1 step 1795, loss is 0.09953322261571884\n",
      "epoch: 1 step 1796, loss is 0.06589128077030182\n",
      "epoch: 1 step 1797, loss is 0.06567772477865219\n",
      "epoch: 1 step 1798, loss is 0.030495651066303253\n",
      "epoch: 1 step 1799, loss is 0.13174638152122498\n",
      "epoch: 1 step 1800, loss is 0.12769488990306854\n",
      "epoch: 1 step 1801, loss is 0.1406596601009369\n",
      "epoch: 1 step 1802, loss is 0.01889662630856037\n",
      "epoch: 1 step 1803, loss is 0.1025170162320137\n",
      "epoch: 1 step 1804, loss is 0.1047017052769661\n",
      "epoch: 1 step 1805, loss is 0.10653477162122726\n",
      "epoch: 1 step 1806, loss is 0.2483469694852829\n",
      "epoch: 1 step 1807, loss is 0.4505705237388611\n",
      "epoch: 1 step 1808, loss is 0.08267026394605637\n",
      "epoch: 1 step 1809, loss is 0.04931456968188286\n",
      "epoch: 1 step 1810, loss is 0.18475544452667236\n",
      "epoch: 1 step 1811, loss is 0.0898744985461235\n",
      "epoch: 1 step 1812, loss is 0.06011299043893814\n",
      "epoch: 1 step 1813, loss is 0.0558500699698925\n",
      "epoch: 1 step 1814, loss is 0.2750040590763092\n",
      "epoch: 1 step 1815, loss is 0.08818687498569489\n",
      "epoch: 1 step 1816, loss is 0.1620287448167801\n",
      "epoch: 1 step 1817, loss is 0.006809838116168976\n",
      "epoch: 1 step 1818, loss is 0.04070911556482315\n",
      "epoch: 1 step 1819, loss is 0.029029523953795433\n",
      "epoch: 1 step 1820, loss is 0.1900891661643982\n",
      "epoch: 1 step 1821, loss is 0.3131425380706787\n",
      "epoch: 1 step 1822, loss is 0.12208942323923111\n",
      "epoch: 1 step 1823, loss is 0.008195384405553341\n",
      "epoch: 1 step 1824, loss is 0.20186489820480347\n",
      "epoch: 1 step 1825, loss is 0.10134484618902206\n",
      "epoch: 1 step 1826, loss is 0.15988561511039734\n",
      "epoch: 1 step 1827, loss is 0.055812690407037735\n",
      "epoch: 1 step 1828, loss is 0.14566737413406372\n",
      "epoch: 1 step 1829, loss is 0.11692202836275101\n",
      "epoch: 1 step 1830, loss is 0.057336632162332535\n",
      "epoch: 1 step 1831, loss is 0.13866601884365082\n",
      "epoch: 1 step 1832, loss is 0.3332042098045349\n",
      "epoch: 1 step 1833, loss is 0.26320505142211914\n",
      "epoch: 1 step 1834, loss is 0.06900594383478165\n",
      "epoch: 1 step 1835, loss is 0.02555154450237751\n",
      "epoch: 1 step 1836, loss is 0.03933090716600418\n",
      "epoch: 1 step 1837, loss is 0.021902436390519142\n",
      "epoch: 1 step 1838, loss is 0.1975776106119156\n",
      "epoch: 1 step 1839, loss is 0.2500876486301422\n",
      "epoch: 1 step 1840, loss is 0.21521836519241333\n",
      "epoch: 1 step 1841, loss is 0.10229639708995819\n",
      "epoch: 1 step 1842, loss is 0.04220893234014511\n",
      "epoch: 1 step 1843, loss is 0.055768031626939774\n",
      "epoch: 1 step 1844, loss is 0.2947942316532135\n",
      "epoch: 1 step 1845, loss is 0.12519270181655884\n",
      "epoch: 1 step 1846, loss is 0.03666522726416588\n",
      "epoch: 1 step 1847, loss is 0.06074002757668495\n",
      "epoch: 1 step 1848, loss is 0.0761866495013237\n",
      "epoch: 1 step 1849, loss is 0.23314397037029266\n",
      "epoch: 1 step 1850, loss is 0.029110223054885864\n",
      "epoch: 1 step 1851, loss is 0.31116774678230286\n",
      "epoch: 1 step 1852, loss is 0.055939022451639175\n",
      "epoch: 1 step 1853, loss is 0.2014581859111786\n",
      "epoch: 1 step 1854, loss is 0.019982852041721344\n",
      "epoch: 1 step 1855, loss is 0.052759602665901184\n",
      "epoch: 1 step 1856, loss is 0.21708421409130096\n",
      "epoch: 1 step 1857, loss is 0.03414442390203476\n",
      "epoch: 1 step 1858, loss is 0.037223730236291885\n",
      "epoch: 1 step 1859, loss is 0.01988343521952629\n",
      "epoch: 1 step 1860, loss is 0.03718801960349083\n",
      "epoch: 1 step 1861, loss is 0.47103869915008545\n",
      "epoch: 1 step 1862, loss is 0.0968848392367363\n",
      "epoch: 1 step 1863, loss is 0.06905733793973923\n",
      "epoch: 1 step 1864, loss is 0.13268259167671204\n",
      "epoch: 1 step 1865, loss is 0.3494003713130951\n",
      "epoch: 1 step 1866, loss is 0.0347442626953125\n",
      "epoch: 1 step 1867, loss is 0.08115438371896744\n",
      "epoch: 1 step 1868, loss is 0.12732252478599548\n",
      "epoch: 1 step 1869, loss is 0.08057542145252228\n",
      "epoch: 1 step 1870, loss is 0.05422119051218033\n",
      "epoch: 1 step 1871, loss is 0.09048718959093094\n",
      "epoch: 1 step 1872, loss is 0.13636641204357147\n",
      "epoch: 1 step 1873, loss is 0.2992154359817505\n",
      "epoch: 1 step 1874, loss is 0.30933624505996704\n",
      "epoch: 1 step 1875, loss is 0.06503278017044067\n",
      "Epoch time: 22519.637, per step time: 12.010, avg loss: 1.140\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    # clean up old run files before in Windows\n",
    "    os.system('del/f/s/q *.ckpt *.meta')\n",
    "else:\n",
    "    # clean up old run files before in Linux\n",
    "    os.system('rm -f *.ckpt *.meta *.pb')\n",
    "\n",
    "lr = 0.01\n",
    "momentum = 0.9 \n",
    "\n",
    "# create the network\n",
    "network = LeNet5()\n",
    "\n",
    "# define the optimizer\n",
    "net_opt = nn.Momentum(network.trainable_params(), lr, momentum)\n",
    "\n",
    "# define the loss function\n",
    "net_loss = SoftmaxCrossEntropyWithLogits(is_grad=False, sparse=True, reduction='mean')\n",
    "\n",
    "# define the model\n",
    "model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()} )\n",
    "\n",
    "epoch_size = 1\n",
    "mnist_path = \"./MNIST_Data\"\n",
    "# save the network model and parameters for subsequence fine-tuning\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=125, keep_checkpoint_max=16)\n",
    "# group layers into an object with training and evaluation features\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"checkpoint_lenet\", config=config_ck)\n",
    "# define step_loss dictionary for saving loss value and step number information\n",
    "step_loss = {\"step\": [], \"loss_value\": []}\n",
    "# save the steps and loss informations\n",
    "step_loss_info = StepLossInfo()\n",
    "\n",
    "repeat_size = 1\n",
    "train_net(model, epoch_size, mnist_path, repeat_size, ckpoint_cb, step_loss_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成后，能在Jupyter的工作路径上生成多个模型文件，名称具体含义`checkpoint_{网络名称}-{第几个epoch}_{第几个step}.ckpt`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看损失函数随着训练步数的变化情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd7wU5dn/8c+lKHZRQQVFUdQk4i82oii2RGNBozEao4/dJGiiJtYnlojpxR5jotEIRoOKNWJ7LFGxYAOliA0QEQQRUAQbCuf6/XHPsnN2d7ac3Tm75+z3/Xrta6fcM3Pt7Dlz7X3fU8zdERGR5rZcvQMQEZH6UzIQERElAxERUTIQERGUDEREBCUDERFByUBqwMx+Z2bzzOy9dt7uNWZ2QXtusxQze9vM9mrH7fUxMzezLu21zVqL4t+s3nE0OyWDTqK9D0Kx7fYGzgS2dPf1U9zOcWb2dHyau5/k7r9Na5vSMdXrf6GjUzKQam0MzHf39+sdiDS3jlw7agRKBk3AzH5sZlPM7AMzG2lmvaLpZmaXm9n7ZvaRmU0ws62ieYPM7FUzW2Rm75rZWQXWuxfwCNDLzD42sxvMbA8zm5lTbtkvNTP7lZndZmY3RuueZGb9Y2V7m9ldZjbXzOab2VVm9jXgGmCnaDsLorI3mNnvSn3OaJ6b2UlmNtnMPjSzv5mZFfhMvczsMzNbOzZt26gZbAUz62tmj0WxzTOz4WbWLWG/58bXat9E27oz+qzTzOxnRb7Dlc3sUjObHn1XT5vZyrEiR5rZO1FM58eW28HMnjWzBWY2O9qfK5azX8xs+Wib86L4Tok3SZnZmmZ2fbTedy00Fy6fEP/yZnaemU2NvvexUa0yY6+EGIru7+hv6xdmNgH4xMxuATYC7o3+Vv43aZ9KDnfXqxO8gLeBvQpM/xYwD9gO6Ar8FXgymrcPMBboBhjwNaBnNG82sGs0vBawXcJ29wBmJo3nxgb8CvgcGAQsD/wReC6atzwwHrgcWBVYCdglmncc8HTOem8Aflfqc0bzHbgv+qwbAXOBfRM+02PAj2PjFwPXRMObAd+OttEDeBK4IuGzLosvd98QfoiNBYYAKwKbAm8B+yTE9DfgCWCDaD/tHMXQJ/ps1wErA1sDi4GvRcttDwwAukRlXwNOK2e/ACcBrwIbRn8Dj0blu0Tz/wP8I/qu1gVeAE5MiP9sYCLwFcLf2tbAOmXEUM7+Hgf0BlYu9r+gV4ljSL0D0KtGX2RyMrgeuCg2vhrwZXRg+BbwZnSwWC5nuXeAE4E1Smx32QGu0HhubIRk8Ghs3pbAZ9HwTtGBoEuB7RxH8WSQ+DmjcSdKLNH4bcA5CZ/pR8Bj0bABM4DdEsp+F3g54bMuiy933wA7Au/krOtcYFiBbSwHfAZsXWBen+izbRib9gJweEK8pwF3x8YT9wshKZ4Ym7dXVL4LsB4h6awcm38E8HjCdt8ADkqYV8l3U2h/n1DO/4JexV9qJur8egHTMyPu/jEwH9jA3R8DriL86pxjZtea2RpR0UMIv96nm9koM9uphjHFzzr6FFgpanroDUx39yVtWGfi5yyy3dUS1nUHoUmqF7Ab4WD1FICZrWtmt0bNIguBfwPd2xDvxoTmtQWZF3Ae4SCbqzuhljS1yPoKfjYz28LM7jOz96J4/1Ag3qT90ouQCDPiwxsDKwCzY/H/g1BDKKR3G+MvZ3/PQKqmZND5zSL84wJgZqsC6wDvArj7le6+PdAP2IJQncfdX3T3gwj/3P8h/ForxyfAKrHtLU+o3pdjBrCRFe4ILHV73aKfsxLuvgB4GDgM+B/gFo9+chKatRz4uruvARxFqD0U0mpfAPGzrWYA09y9W+y1ursPKrCeeYSmtb6VfhbgauB1YPMo3vOKxJtrNqGJKCPexj+DUDPoHot/DXfvl7CuGbQt/nL2d+7fhm7F3AZKBp3LCma2UuzVBbgZON7MtjGzroRfhs+7+9tm9g0z29HMViAcuD4HlprZimZ2pJmt6e5fAguBpWXG8Cbhl/7+0Xp/SWjvLccLhAPQn8xs1egzDIzmzQE2jHd+5kj8nGVuu9D6jiHUkG6OTV8d+BhYYGYbECXPBOOAQWa2tpmtT2iiyXgBWBh1fq4cdbBuZWbfyF2Ju7cAQ4HLok7n5c1sp+hzlrI64fv72My+CvykjGUybgN+bmYbRJ22v4jFNJuQMC81szXMbLmos3f3hHX9E/itmW1uwdfNbJ0y4y93f2fMIfTBSAWUDDqXBwhty5nXr9z9v8AFwJ2EA21f4PCo/BqEjscPCU0s84FLonlHA29HVfOTCL/ISnL3j4CfEv753yUkmZlFF8ouuxT4DqHT8J1ouR9Esx8DJgHvmdm8AssW+5xtMRLYHJjj7uNj039N6KT+CLgfuKvIOm4idIi/TThwjojFm/ms2wDTCL/+/wmsmbCuswgdsC8CHwB/prz/37MItZtFhO96RPHirVwXxT0BeJnw97WE7A+DYwid368S/obuAHomrOsyQnJ5mJCcrid0eJdSyf7O+CPwy6j5Ku8sOCnMsrVfEZFkZrYf4ayqjUsWlg5HNQMRKShqvhpkZl2iJpoLgbvrHZekQzUDESnIzFYBRgFfJTQ73g/83N0X1jUwSYWSgYiIqJlIRETClYQdTvfu3b1Pnz71DkNEpEMZO3bsPHcveN1Ph0wGffr0YcyYMfUOQ0SkQzGz6Unz1EwkIiJKBiIiomQgIiIoGYiICEoGIiKCkoGIiKBkICIiKBl0XPPnw6231juK6nz8MbS01DsKEUHJoDYyB7SWFjjjDHj11ey8uXPhzjth1qzk5d94I7x/+ilMnFi4zJIlsHhxdny//eCII2B6dA3Jm2/C558nL/vFF62njR0LffvCqFHwwAMweXJyfABjxsDAgbBgQfFycffcAzMTHmWweDGsvjqcnfOskg8/hGHDsp8ryaxZMGNG2GciUr16P4S5La/tt9/ea2bSJPddd3X/+9/D+JIl7vff737BBe7Dh7uPHu0O7n/6k3tLSygzZUpYBrKvd9/Nlu3e3X369FA2Xubjj90ffth9/Hj3F190X7jQfd11W5fJvE44wX3yZPfFi92PPz47/fzz3U8+OTt+9dXu8+aF4e99z/2++9w//9z9H/9wP+kk96eeypZ97TX3ddYpvL3Ma/fd3V94wf2hh9znzg375eOPs/OPPdb9Zz9znzHDfdYs9yOOcD/sMPeRI92PO879wgvdhw4N+yi+3i5dwvqmTw+feYcdisfRr1/47Gee6X7bbe5nnOF+3XXuRx3lPmRI67I9e7rPmeM+dqz7HXfU7m9DpJMBxnjCcbVD3rW0f//+3qbbUTzyCOy9d+0DksYzfDgMGgTdutU7EpGGYWZj3b1/oXkd8t5Ebfbhh/WOQNrLkUeG95YWsHKf/y7SvJqrz+D734fRo0Mb+R57wMEHw4knwv/8D1xxRWjbz9h2W5gwIQxvsUV4AZx+Ohx3XG3jGjQIjjkGTjqpeLm77oIDD4RLLgnDcbsnPYc8JddfX165w6t5DHENLLdcSAxLl5YuK9LMktqPGvlV0z6DSnz5Zevxt94qXG7u3Gx79qxZrZebP9990SL3U091P/300B6f0dIS2vVbWtzfecf97LPDsn36uA8YUHhb48a5f/FFGH7kEfe7787Ou+SS0D8xYEDrNvYhQ0Ib/+mnh76Pe+5x//TTsMx997n/+c+ttzF7tvu0acn7ZfRo99/9LrTpDx8e+l1mzsz2scT3y8yZ7oMHZ2PZeWf3iRPD9k8/3X3vvd0vu8z9hz90v+aa0K8yfbr7VVeFz3L22aE/pFA/wzbbJPdB3HprcvwiTQL1GQgQznIaOBDGj4eNNqpvLJnmm7Y24RxyCHTtCrfcEsYzf8eZ9Y0eDTvv3HqZGTNgww3btj2RTkB9BhJsuWXj9JssV2ULZaZJ76yz4L33stOnTg3vm24K8+bBt78NL78cpr33npKBSILm6jOQzme77UKfS8amm4YXwDrrwG9/m52X288iIssoGUjntuOO2eE//hGmTKlfLCINTMlAOrfu3cNV4BnxJiURWUbJQDq/7t2zw6ecUr84RBqYkoE0l/Hj6x2BSENSMpDmcOON9Y5ApKEpGUhz2H//ekcg0tCUDKQ5rLZavSMQaWhKBtIcVlyx3hGINDQlAxERUTKQJnLooeGWHCKSR8lAmkeXLuERoCKSR8lAmkeXLvDJJ9k7nIrIMkoG0jxGjYJ334Wrr653JCINR8lAmseMGeH9r3+tbxwiDUjJQJrHsceG988+q28cIg1IyUCax8orh3clA5E8SgbSPFZYIbx/9FF94xBpQKkmAzPrbWaPm9lrZjbJzH5eoIyZ2ZVmNsXMJpjZdmnGJMLixfWOQKThpP0M5CXAme7+kpmtDow1s0fc/dVYmf2AzaPXjsDV0buIiLSTVGsG7j7b3V+KhhcBrwEb5BQ7CLjRg+eAbmbWM824RESktXbrMzCzPsC2wPM5szYAZsTGZ5KfMDCzwWY2xszGzI0/xlCkXCeeWO8IRBpWuyQDM1sNuBM4zd0X5s4usEjeJaLufq2793f3/j169EgjTOns+vWrdwQiDSv1ZGBmKxASwXB3v6tAkZlA79j4hsCstOOSJrXbbvWOQKQhpX02kQHXA6+5+2UJxUYCx0RnFQ0APnL32WnGJU1s993Du+5PJNJK2mcTDQSOBiaa2bho2nnARgDufg3wADAImAJ8ChyfckzSzDIPuVm6NNy4TkSAlJOBuz9N4T6BeBkHTk4zDpFlMsngiy+UDERidAWyNJfMVchfflnfOEQajJKBNJd4zUBEllEykOaSSQaqGYi0omQgzWXevPB+5531jUOkwSgZSHOZNCm8X3FFfeMQaTBKBtJcunYN77pzqUgrSgbSXAYODO+bblrfOEQajJKBNJfjo2saM0lBRAAlA2k2ZqGpqKUlucywYaHcLN0iS5qHkoE0HzO46CJ4+eXC82+4IbxPntxuIYnUm5KBNJ9MrWDAgPrGIdJAlAyk+Vh0uyzduVRkGSUDaT7L6c9eJJf+K6T5WNEb6Yo0JSUDERFRMpAmVG7NQH0K0kSUDKT5ZJKBmotEllEykOalZCCyjJKBNB8lAZE8SgbSfJQMRPIoGYiIiJKBNCF1IIvkUTKQ5qMkIJJHyUCal5KCyDJKBtJ8FiwoPl9JQpqQkoGIiCgZiIiIkoE0s9zmoD32gJtvrksoIvWmZCCSMWoUHHlkvaMQqQslA2len35a7whEGoaSgYiIKBmIiIiSgYiIkHIyMLOhZva+mb2SMH8PM/vIzMZFryFpxiNSET3pTJpIl5TXfwNwFXBjkTJPufsBKcchIiJFpFozcPcngQ/S3IZITagWIE2uEfoMdjKz8Wb2oJn1SypkZoPNbIyZjZk7d257xici0unVOxm8BGzs7lsDfwX+k1TQ3a919/7u3r9Hjx7tFqB0QldckT9NNQNpcnVNBu6+0N0/joYfAFYws+71jEmawBpr5E9buLD94xBpIHVNBma2vlm4QYyZ7RDFM7+eMUkTWK7An/2WW7Z/HCINpOyzicxsPeAPQC9338/MtgR2cvfriyxzC7AH0N3MZgIXAisAuPs1wKHAT8xsCfAZcLi76uuSskLPK5g9u/3jEGkglZxaegMwDDg/Gn8TGAEkJgN3P6LYCt39KsKppyLtRw+vEclTSTNRd3e/DWgBcPclwNJUohJJU6lkoGQhTaiSZPCJma0DOICZDQA+SiUqkTQV6jMQaXKV/FecAYwE+prZM4Srik9NJSqRNMWTwahR8PWv1y8WkQZRdp+Bu79kZrsDXwEMeMPdv0wtMpG0fOMb2eGTT4ZJk+oXi0iDqORsomNyJm1nZrh7sfsOiTSevn2zwy0t9YtDpIFUcjZR7OcUKwF7Eq4gVjKQjktnMosAlTUTteofMLM1gZtqHpFIe3r99XpHINIQqjmt4lNg81oFIiIi9VNJn8G9RKeVEpLIlsBtaQQlIiLtq5I+g0tiw0uA6e4+s8bxiDQO9SdIE6mkz2BUmoGIiEj9lEwGZraIbPNQq1mAu3uB+wGLiEhHUjIZuPvq7RGIiIjUTyV9BgCY2bqE6wwAcPd3ahqRiIi0u7JPLTWzA81sMjANGAW8DTyYUlwiItKOKrnO4LfAAOBNd9+EcAXyM6lEJSIi7aqSZPClu88HljOz5dz9cWCblOISEZF2VEmfwQIzWw14EhhuZu8TrjcQEZEOrpKawUGEW1CcDvwfMBX4ThpBidSVnnQmTaiSmsFg4PboquN/pRSPiIjUQSU1gzWAh8zsKTM72czWSysokdT161fvCEQaStnJwN1/7e79gJOBXsAoM3s0tchE0vS1r1VWfvJkuPbadGIRaQBtuYX1+8B7wHxg3dqGI9JOKn3C2YABcOKJunmddFqVXHT2EzN7Avgv0B34sbvrSeLSMS2p8ES4Dz4I70oG0klV0oG8MXCau48rNNPM1nL3D2sTlkjKli5Nnvf558nzlAykk6rkFtbnlCjyX2C76sIRaSfFagbPPhveCx34lQykk6rmsZe5dHK2dBwPPVS6zJAh+dMq7WsQ6SBqmQz0k0k6l9Gj86epZiCdVC2TgUjHseqqbVtONQPppCp+nkERaiaSjmPx4vLKTZoE06eHW1S4q2YgnVbZycDM+gIz3X2xme0BfB240d0XREX2TCE+kXSUe2rpVluF98z9ipQMpJOqpJnoTmCpmW0GXA9sAtycmenuH9Q4NpH0rLJKZeUzyUDNRNJJVZIMWtx9CXAwcIW7nw70TCcskZSNGdO25VQzkE6qoofbmNkRwLHAfdG0FYotYGZDzex9M3slYb6Z2ZVmNsXMJpiZrlOQ9lHpvYkylAykk6okGRwP7AT83t2nmdkmwL9LLHMDsG+R+fsBm0evwcDVFcQj0n7UTCSdXCVXIL8K/AzCrSeA1d39TyWWedLM+hQpchChE9qB58ysm5n1dPfZ5cYl0q5UM5BOqpIb1T1hZmuY2drAeGCYmV1W5fY3AGbExmdG00QaS+ZeRkoG0klV0ky0prsvBL4HDHP37YG9qtx+oWsTCv63mdlgMxtjZmPmzp1b5WZF2kjNRNJJVZIMuphZT+Awsh3I1ZoJ9I6NbwjMKlTQ3a919/7u3r9Hjx412rw0tbYc2FUzkE6qkmTwG+AhYKq7v2hmmwKTq9z+SOCY6KyiAcBH6i+QdtOWB9+rZiCdVCUdyLcDt8fG3wIOKbaMmd0C7AF0N7OZwIVEp6O6+zXAA8AgYArwKeGMJZHGpZqBdFKV3I5iQ+CvwEBCu/7TwM/dfWbSMu5+RLF1RmcRnVxuDCJ1p2QgnVQlzUTDCM06vQhn/NwbTRPpnL797fxpaiaSTqqSZNDD3Ye5+5LodQOgnlzpvLbdNn+aagbSSVWSDOaZ2VFmtnz0OgqYn1ZgInV3yy350zLJYO5cmDevfeMRSVElyeAEwmml7wGzgUNRh690ZjNm5E/LNBOtuy7oFGfpRMpOBu7+jrsf6O493H1dd/8u4QI0keZxzz2qEUinVO1jL8+oSRQiHcVpp8EBB9Q7CpGaqzYZ6FGX0nymTEme98gj8PHH7ReLSI1Umwx0aoVIxvTpsPfecNxx9Y5EpGIlLzozs0UUPugbsHLNIxLpqDI1gtdeq28cIm1QMhm4++rtEYhIh6FrDaQTqraZSKT5JCUDJQnpwJQMRDJWWgnWWafty2eSQVvuhipSZ0oGIhnbbAPvv1/9eqpJBk88AXfcUX0MIhUq+66lIp3SE0/AzJlw1FFhfLkyfh99+GF68Xzzm+FdTU7SzpQMpLntvjvMmROGjz22vrGI1JGaiUTWWy/8Ej/ppNqv+/nnYYstdCGaNDwlA5FayW3aufjicOuKyZPhxRfzy95wA3zxRbuF18qMGSEukYiaiURqLdOB/L//mz8t44474PjjYepU+O1v2y+2jI02Cu/qm5CIagYitZI5sE6cmH+QzU0GmU7oTH+FSJ0pGYikYdGi8srpl7k0CCUDkWokHcy/+93iy+nCNGkwSgYi1Ui6Q+lTT7UeTzr4d7SagXu4NqOjxS0lKRmIVOPGG7PDlRwgM8mhkmVWWgkOPLD88mm49dZwYdzQofWNo1rHHAN/+Uu9o2goSgYitTBlCtx+e3a8UAfyFVeE988+a9s2Fi+Ge+9te4y18NZbrd87qptuCk+tk2V0aqlILfTrV/yagaVL4fTTw/CCBa3nPfAAdOkSHowjUieqGYjUQm4iyO0juOqqwvNffx323x/22af6GN56C846C1paql+XNB0lA5H2EL8bajxRjB5dfLnXX4chQwr3LTz2GFx3XXb8kEPg0kth0qTqYpWmpGQgkobcg3fu3VBLnVr6wQehc3r77cMVyoXubbTnnjB4cHZ8yZK2xSqC+gxE2kel1xUcfXToS2hUOrW001HNQKSUfv0qXyb34F9OzeBb38oOv/tu63nlHHx1gJYqKBmI5Fplldbjyy9f/TrjycCscDJ4/PHk5RvtQN+WK6iHD4e77659LFITaiYSyfXee+FU0LXWCuOlksE225ReZ27N4JFHKoupLRe0NZrM0+QaLbEJoJqBSL7VV4du3eCgg8L4qqsWLz9+fP603M7c3BvX3Xxz8XXmHjDj42+8ASusUHz5JIsWwYABbVu2Gh39IrUmoGQgkuTvf4ennw7JoVrPPpsdfvnl0uUnTGg9Hk8GX/1q4TOHyvnF/dhj4elr7e2DD9pvWzfeCPfc037b6yRSTwZmtq+ZvWFmU8zsnALzjzOzuWY2Lnr9KO2YRMrSqxcMHJjfxFOt/farfJn2bFpxh112qe0zoWu9D4s59tjSd42VPKl+Q2a2PPA3YD9gS+AIM9uyQNER7r5N9PpnmjGJVKw9D2RJykkG5fQVlLOe2bPhmWda34SvWo2wD0uZMAEWLqx3FHWT9je0AzDF3d9y9y+AW4GDUt6mSG11hANZOUaNgoMPTp7/ySfw+efl9UfMnBlOhc08sa2URt+H7rD11uHWIE0q7W9oA2BGbHxmNC3XIWY2wczuMLPehVZkZoPNbIyZjZk7d24asYoU1ghn59TiOoPbbis+f7XVYIst8j+vezj4x914YzgVtlRHeEYlp+fOnw+fflp++VpYujS8P/NMdev59rfDbUE6oLSTQaH/oty/2HuBPu7+deBR4F+FVuTu17p7f3fv36NHjxqHKVJEI/yqvfPO0mW+/DK8m4Vbapu1vq12OWbMyE8q114LvXvDSy9Vtq64SvZh9+6w7bZt31ZG0hXcn3+ePy1zo8EuVZ5t/+ijcNdd1a0jlztMm1bbdRaQ9l/5TCD+S39DYFa8gLvPd/fF0eh1wPYpxyRSmUZIBj/5SekykydnhzMH7mLPWEiSe9fTJ54I76+/nl9ryIw/9RT85jf565o/H+bMqXwfvvlmZeUL2X//whfynXlm/rRMMmjrKbtpuvJK2HRTGDcu1c2k/Vf+IrC5mW1iZisChwMj4wXMrGds9EDgtZRjEqlMIzQTVWKrreAHPwjDbYm90IN5Ss3bbTe48ML8dXXvDuuvX78LzebNy59W6Fd2rWoGbTF8OHz0UfL8J58M71OnphpGqsnA3ZcApwAPEQ7yt7n7JDP7jZllnt/3MzObZGbjgZ8Bx6UZk0jFGqFm0FbFDuRJcmsGtTiQ12od5XZYZ5SbDOuVDCZODFdmn3BC6bIpJ9TU/8rd/QF338Ld+7r776NpQ9x9ZDR8rrv3c/et3f2b7v562jGJVKTRk0Gx0yHjzTjXXFPe+pIOOkuX5l8MV66kB+5cdRXMmlV4Xq5LL4W114bp09sWQ0ahBFGvZqLMrcmL7YN2qpk2+F+5SANo9GRwxx2ly+y2W+HpL76YPy33wJ05GJ17bukzkpJce23+tGnT4NRTi5/uGjcyamF+++38eQsXhjgvvbT0egolu3rVDDL7utgBv52a2HSjOpFSVlyx3hEUd/nlyc0MpRLZDjvkH2ySfsXn3lYbyv/VeuWV+dMyt9SYP7+8dWS2lRvvCSfAyiuH4XJrPxmXXw79+8M667TeRnvJfJYG+MGhZCBSykUXwbBh9Y4i2SuvZM+Tz1VtB7J7OgfIpUuzNYJyf/kmJYNqvpszzgjvr7zS9nVUo5yagZqJRBpE9+71jqC0pGTQFptskh1+91347LPksmaVP27z/vvDM6ErfVZz5tdzGrfzLuegnGvqVLj66sLzHn649Pa++KKhagb1j0BEqpe54CxXtb8qe/cu/UCaTHt7rv/8p/D0Aw6Ahx6qPJakmkHclCmVrxfalgx22QV++lNYvDh/3j77FP+MRx0FXbtmt1tOMujoZxOJdAq//jWMHVvvKJIVOiBB+k0MZq37GOIHrGIdw/GzZ6ppJirUj1FomVKS+kkAdt8dBg/On17qttzFYrvlltbbVTORSAcxZAhst129o0iWlAzK+cVZzvMViokfSB97DN55p/QySTWZYjIHxfj2Ntyw+DLxq7KLKXZQfvJJuO66MDx2bPEHDxVaZ8att+ZfWZ1ZtpwD/mGHlS5TBSUDkc6gmppBtUkufjDca6/w8J1S4smg3JpBJrH98pflL3NO3iNUCi9bzi/0++4LZx4NHZq/vvvvz79GITcZHHEEfOUrhWOJJ+1hw8q/9qKGlAxEOoNCN1/LSLOtObeZCIp3OGdUkgyuvjp0NmcO1C++2Pa+gSTFmoky3ngjvL/6av6yF16Y35Fezjpzk9C8eeFU2fgDkNRMJNKA7r233hEUlnRWy3LLlXdQqkahg3mpZqCJE8tb97x5oZN2q61aHxQz1xXUSiaBFTvwJnX2trQUvkV3Ofs9XjMYPBguvjiMZ24ZfsklMGZMtvzf/pZcC6ySrjMQqcQBB6R37n01ku7yOXRoOJCm5Ve/KtyROnt28eUefDA7HE8mn3zSutz552eH42ct1bq2c/LJ4X3atHALandYa63wAJ+MzOfMTQbuhftm4skg6cK6eILJ9EtASKavvgpnn926/CmnhKukTzyx9GeqkGoGIp1BsXvqZC6sSsOsWeW3yxczdGh45vRqq2WnnXtu6wQwZ052uNa1nXjTzyGHwKGHwp57tm76yXB15GUAAA6wSURBVJwqOmJE62U33BCeey5/nfFrP5LOrErqq1i0CPr1K7xMSj9ElAxEOoNGa74qdC+iJDNmwA9/mF+b+NOfWjcnxS9SqyQZXHdd6zb4ShLV3/+ev83cG+UtWlR42XiMSbefzpRJehBPISldoKZmIpG2mD49XDS0cGF4VKS09oc/lF+22ME56dqOSpJBoWsEyhW/I2yltZH454ovG69ZtKWGk1LNQMlApC022ii8d+1a3ziaVTXNRG25+rnQNksdlM88M5Q5/fTWTUaHH54dbsttRNRMJNKAGq0juVm0tFR+IF28OHvlb7kuuKD1NuPKaW7K9NckxapkINJJKBnUR0sL3HBDZcuceiocfXTbtxlv9/+//0u+J1MhSgYinVxnSQYd7XO0tMCPflTZMqNHV9e8FD/4xzukSylWi6n0jq+gZCDSkGp1Zsejj9ZmPc0ifpZPuZYubbenhrWy3nrZx1vmaqAOZCUDkWrE/zELnW9frm99K/UbkXUqbUkGbfkVXgvz5iXPa0szUUqnlioZiFQjngx22y08tCVXsfsGFVqPpKPW9zOqhXolqAKUDESqkXsQ79ED1l679bRGf4ay1M8TT1S+TEpNXUoGItUo9Is+d1q5v/pPOaX87Z51VvllpXFVeqorpHbjQSUDkWoUar/deefs8Pe+V/66dt21/F998fPfpbkoGYg0oEK/+m+5Bc47L93tdqny5gHxu4ZKx6JkINKACiWDVVfNPj0s80v/uuvg+edrt91qk8E229QmDml/SgYiDSjpNL/cJPGjH8EOO1S27uOOaz0ev6tnqWRwySXF59fr7KURI+Coo+qz7c5CyUCkAZmF+96n4fjjW4+vv352OJ6EevTIX/bMM/On/fvf4X311aFbt+rja4vDDgs1p1J69kw/lo5KyUCkQRV6sEwtfnnHf/2vs05yuT/+sfS67r0XjjwSRo6EV14Jd1u9/vriy9x+e3lxVmqVVUqXeffddLbdGSgZiHQg++8PP/4xXHVV6+l/+Uv569h88+zwzTcnlyvnKtbMtQ/f+U729ttf+UrxZXr3Lr3etij1/OJDDulYF+HddVfh6fHHWMZttll121MyEOlAVlwxPO2rV6/W0089Nf+JXv/4R+F19OgR/vFfegn23jt//gEHhISz6aZhPLfpp2/f7HChA8jAgTBuXPJnSOmgU7Jm8POfp7PdWnjkkfxp3/1u4bJHHll4ejk1o2KUDEQa1De+Ed5zD/yFmLVu+3cv/CSuddfNlt922+z0556Dyy4Lw/feGxLOXnvBs8/mP5j+6adbb6eQrbdOfiRjoWV+8pPCZePinw9Ckjr00Ox4qT6DXXctvY00lPPZcmPfeefkWkzSc6mrvSI9nuRrSMlApFoXXhh+YW+9dW3WN3MmvPFG4Xk77hienJVrwID8g9L664eHykO4c2aSTM0C4OKLsw9k2Xjj/LL77JO8nqOPDldRT5kSmqX+3//Lzrv99mxyiTcTFdpGKTfdVPkyxTz1FLz3Xnk3v8s9wCc9e3qHHZLP+KqmCey550KNMA3unuoL2Bd4A5gCnFNgfldgRDT/eaBPqXVuv/32LtKhzZ7tPm1a7de77rrum22WHV+yxH3SpNLLhUO1e0tLeH36aZj+8MNh+oUXhvfXX8+WPekk9/POy44//HDrdc6fH6Z369Z6+ttvh+nPPNN625lXbkxnnZUd3nzzwssUe910U/H58e+h0PzLL88Ov/xyNo7XXktebtiwwtN79nTfc8/K4i+0b9oIGONJx+qkGbV4AcsDU4FNgRWB8cCWOWV+ClwTDR8OjCi1XiUDkQRLl4aDeaUefND9ySeT57e0uC9YEIZzD/DPPef+yiv5y3zwQeFkkCtzoBs92v2uu7LTf/979112CcObbOJ+wgnuixaF8enTyzt4du/eehuZV7du7r/4hfuYMa1jmTPHfe21Q5k113R/6KHWy0+eHN732afwZwD3Cy7IfgfvvOO+1VatD+b77JMfz5prtk544H7zza3LzJ5dfD+WoZ7JYCfgodj4ucC5OWUeAnaKhrsA8wArtl4lA5E6GjfO/b33Spf78kv3Ll3c//nP4uW6dQsH+0plaiV77x3e//lP94sucv/ii5AUe/UKtQL3/IPvAw8kr3f69PxaTvxgPnx4qPXkzl9xRfeBAwvvm3//2/3WW8PwwQdn1zdihPvEie59+7bexgsvhIQyZ477H/7gPmpU5fungGLJwML8dJjZocC+7v6jaPxoYEd3PyVW5pWozMxofGpUZl7OugYDgwE22mij7adPn55a3CLSjjJnx1Tz0JZ33smeMlvI8OGhD6NPH5gwAXbZpbL1T54cHpt57LGF58+cGS7mW3PN0uuaOzd0+g8blr1tyVtvhWc6DxgAgwZVFlsFzGysu/cvOC/lZPB9YJ+cZLCDu58aKzMpKhNPBju4+/yk9fbv39/HjBmTWtwiIp1RsWSQ9tlEM4H4lSsbArOSyphZF2BNIOccORERSVPayeBFYHMz28TMViR0EI/MKTMSyNS9DgUe8zSrKyIikqfK++AW5+5LzOwUQifx8sBQd59kZr8hdGSMBK4HbjKzKYQaweFpxiQiIvlSTQYA7v4A8EDOtCGx4c+B76cdh4iIJNMVyCIiomQgIiJKBiIigpKBiIiQ8kVnaTGzuUBbL0HuTrjlRSNr9BgbPT5QjLXQ6PFB48fYaPFt7O4FnpPaQZNBNcxsTNIVeI2i0WNs9PhAMdZCo8cHjR9jo8cXp2YiERFRMhARkeZMBtfWO4AyNHqMjR4fKMZaaPT4oPFjbPT4lmm6PgMREcnXjDUDERHJoWQgIiLNlQzMbF8ze8PMppjZOXWKobeZPW5mr5nZJDP7eTT9V2b2rpmNi16DYsucG8X8hpnt005xvm1mE6NYxkTT1jazR8xscvS+VjTdzOzKKMYJZrZdyrF9JbafxpnZQjM7rd770MyGmtn70dP7MtMq3mdmdmxUfrKZJTxaq6YxXmxmr0dx3G1m3aLpfczss9j+vCa2zPbR38eU6HNYivFV/L2m+b+eEOOIWHxvm9m4aHq778M2S3oeZmd7EW6hPRXYFFgRGA9sWYc4egLbRcOrA28CWwK/As4qUH7LKNauwCbRZ1i+HeJ8G+ieM+0i4Jxo+Bzgz9HwIOBBwIABwPPt/L2+B2xc730I7AZsB7zS1n0GrA28Fb2vFQ2vlXKMewNdouE/x2LsEy+Xs54XCM84t+hz7JdifBV9r2n/rxeKMWf+pcCQeu3Dtr6aqWawAzDF3d9y9y+AW4GD2jsId5/t7i9Fw4uA14ANiixyEHCruy9292nAFMJnqYeDgH9Fw/8CvhubfqMHzwHdzKxnO8W0JzDV3Ytdkd4u+9DdnyT/KX2V7rN9gEfc/QN3/xB4BNg3zRjd/WF3XxKNPkd4ImGiKM413P1ZD0e1G2Ofq+bxFZH0vab6v14sxujX/WHALcXWkeY+bKtmSgYbADNi4zMpfhBOnZn1AbYFno8mnRJV1YdmmhOoX9wOPGxmY81scDRtPXefDSGpAevWOUYID0OK/+M10j6EyvdZvf9OTyD8Ss3YxMxeNrNRZrZrNG2DKK6M9oixku+1nvtwV2COu0+OTWuUfVhUMyWDQu1xdTuv1sxWA+4ETnP3hcDVQF9gG2A2oaoJ9Yt7oLtvB+wHnGxmuxUpW5cYLTxK9UDg9mhSo+3DYpJiqlusZnY+sAQYHk2aDWzk7tsCZwA3m9kadYix0u+1nt/3EbT+cdIo+7CkZkoGM4HesfENgVn1CMTMViAkguHufheAu89x96Xu3gJcR7YZoy5xu/us6P194O4onjmZ5p/o/f16xkhIVC+5+5wo1obah5FK91ldYo06qg8AjoyaLYiaX+ZHw2MJ7fBbRDHGm5JSjbEN32u99mEX4HvAiMy0RtmH5WimZPAisLmZbRL9ojwcGNneQURtitcDr7n7ZbHp8Tb2g4HMmQojgcPNrKuZbQJsTuh4SjPGVc1s9cwwoYPxlSiWzNktxwL3xGI8JjpDZgDwUaZpJGWtfoU10j6MqXSfPQTsbWZrRc0he0fTUmNm+wK/AA50909j03uY2fLR8KaE/fZWFOciMxsQ/T0fE/tcacRX6fdar//1vYDX3X1Z80+j7MOy1LP3ur1fhDM43iRk5/PrFMMuhOrgBGBc9BoE3ARMjKaPBHrGljk/ivkN2uGMA8JZGOOj16TMvgLWAf4LTI7e146mG/C3KMaJQP92iHEVYD6wZmxaXfchITHNBr4k/PL7YVv2GaHdfkr0Or4dYpxCaGPP/D1eE5U9JPr+xwMvAd+Jrac/4aA8FbiK6G4GKcVX8fea5v96oRij6TcAJ+WUbfd92NaXbkchIiJN1UwkIiIJlAxERETJQERElAxERAQlAxERQclApCgzO9/C3WUnRHed3NHCHVJXqXdsIrWkU0tFEpjZTsBlwB7uvtjMuhPugjmacF3AvLoGKFJDqhmIJOsJzHP3xQDRwf9QoBfwuJk9DmBme5vZs2b2kpndHt13KvNMiD+b2QvRa7No+vfN7BUzG29mT9bno4m0ppqBSILooP404WrnR4ER7j7KzN4mqhlEtYW7CFe/fmJmvwC6uvtvonLXufvvzewY4DB3P8DMJgL7uvu7ZtbN3RfU5QOKxKhmIJLA3T8GtgcGA3OBEWZ2XE6xAYSHrDxj4elWxxIetJNxS+x9p2j4GeAGM/sx4UEsInXXpd4BiDQyd18KPAE8Ef2iz30MpREeRnNE0ipyh939JDPbEdgfGGdm23h0Z0uRelHNQCSBhWctbx6btA0wHVhEeGQphCeDDYz1B6xiZlvElvlB7P3ZqExfd3/e3YcA82h9u2WRulDNQCTZasBfLTwgfgnh7p6DCbfOftDMZrv7N6Omo1vMrGu03C8Jd8wE6GpmzxN+eGVqDxdHScYIdzId3y6fRqQIdSCLpCTe0VzvWERKUTORiIioZiAiIqoZiIgISgYiIoKSgYiIoGQgIiIoGYiICPD/Ad0SONj7cQZoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = step_loss[\"step\"]\n",
    "loss_value = step_loss[\"loss_value\"]\n",
    "steps = list(map(int, steps))\n",
    "loss_value = list(map(float, loss_value))\n",
    "plt.plot(steps, loss_value, color=\"red\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss_value\")\n",
    "plt.title(\"Loss function value change chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面可以看出来大致分为三个阶段：\n",
    "\n",
    "阶段一：开始训练loss值在2.2上下浮动，训练收益感觉并不明显。\n",
    "\n",
    "阶段二：训练到某一时刻，loss值减少迅速，训练收益大幅增加。\n",
    "\n",
    "阶段三：loss值收敛到一定小的值后，loss值开始振荡在一个小的区间上无法趋0，再继续增加训练并无明显收益，至此训练结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  数据测试验证模型精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建测试网络的过程主要为：\n",
    "\n",
    "1. 载入模型`.cptk`文件中的参数`param`；\n",
    "2. 将参数`param`载入到神经网络LeNet5中；\n",
    "3. 载入测试数据集；\n",
    "4. 调用函数`model.eval`传入参数测试数据集`ds_eval`，就生成模型`checkpoint_lenet-1_1875.ckpt`的精度值。\n",
    "\n",
    "> `dataset_sink_mode`表示数据集下沉模式，不支持CPU，所以这里设置成`False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n",
      "============== Accuracy:{'Accuracy': 0.9613381410256411} ==============\n"
     ]
    }
   ],
   "source": [
    "# testing relate modules \n",
    "def test_net(network, model, mnist_path):\n",
    "    \"\"\"Define the evaluation method.\"\"\"\n",
    "    print(\"============== Starting Testing ==============\")\n",
    "    # load the saved model for evaluation\n",
    "    param_dict = load_checkpoint(\"checkpoint_lenet-1_1875.ckpt\")\n",
    "    # load parameter to the network\n",
    "    load_param_into_net(network, param_dict)\n",
    "    # load testing dataset\n",
    "    ds_eval = create_dataset(os.path.join(mnist_path, \"test\"))\n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    print(\"============== Accuracy:{} ==============\".format(acc))\n",
    "\n",
    "test_net(network, model, mnist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过1875步训练后生成的模型精度超过95%，模型优良。\n",
    "我们可以看一下模型随着训练步数变化，精度随之变化的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`acc_model_info`函数是将每125步的保存的模型，调用`model.eval`函数将测试出的精度返回到步数列表和精度列表，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def acc_model_info(network, model, mnist_path, model_numbers):\n",
    "    \"\"\"Define the plot info method\"\"\"\n",
    "    step_list = []\n",
    "    acc_list = []\n",
    "    for i in range(1, model_numbers+1):\n",
    "        # load the saved model for evaluation\n",
    "        param_dict = load_checkpoint(\"checkpoint_lenet-1_{}.ckpt\".format(str(i*125)))\n",
    "        # load parameter to the network\n",
    "        load_param_into_net(network, param_dict)\n",
    "        # load testing dataset\n",
    "        ds_eval = create_dataset(os.path.join(mnist_path, \"test\"))\n",
    "        acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "        acc_list.append(acc['Accuracy'])\n",
    "        step_list.append(i*125)\n",
    "    return step_list,acc_list\n",
    "\n",
    "# draw line chart according to training steps and model accuracy\n",
    "l1,l2 = acc_model_info(network, model, mnist_path, 15)\n",
    "plt.xlabel(\"Model of Steps\")\n",
    "plt.ylabel(\"Model accuracy\")\n",
    "plt.title(\"Model accuracy variation chart\")\n",
    "plt.plot(l1, l2, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中可以看出训练得到的模型精度变化分为三个阶段：1、缓慢上升，2、迅速上升，3、缓慢上升趋近于不到1的某个值时附近振荡，说明随着训练数据的增加，会对模型精度有着正相关的影响，但是随着精度到达一定程度，训练收益会降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们尝试使用生成的模型应用到分类预测单个或者单组图片数据上，具体步骤如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 需要将要测试的数据转换成适应LeNet5的数据类型。\n",
    "2. 提取出`image`的数据。\n",
    "3. 使用函数`model.predict`预测`image`对应的数字。需要说明的是`predict`返回的是`image`对应0-9的概率值。\n",
    "4. 调用`plot_pie`将预测的各数字的概率显示出来。负概率的数字会被去掉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入要测试的数据集并调用`create_dataset`转换成符合格式要求的数据集，并选取其中一组32张图片进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2, column 5 is incorrectly identified as 8, the correct value should be 3 \n",
      "\n",
      "Row 3, column 3 is incorrectly identified as 5, the correct value should be 8 \n",
      "\n",
      "Row 4, column 6 is incorrectly identified as 6, the correct value should be 0 \n",
      "\n",
      "[8 0 5 4 9 1 8 7 0 5 2 4 8 2 4 1 2 1 5 3 9 8 5 7 1 9 3 8 2 6 0 1] <--Predicted figures\n",
      "[8 0 5 4 9 1 8 7 0 5 2 4 3 2 4 1 2 1 8 3 9 8 5 7 1 9 3 8 2 0 0 1] <--The right number\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_test = create_dataset(test_data_path).create_dict_iterator()\n",
    "data = ds_test.get_next()\n",
    "images = data[\"image\"]\n",
    "labels = data[\"label\"]\n",
    "\n",
    "output =model.predict(Tensor(data['image']))\n",
    "prb = output.asnumpy()\n",
    "pred = np.argmax(output.asnumpy(), axis=1)\n",
    "err_num = []\n",
    "index = 1\n",
    "for i in range(len(labels)):\n",
    "    plt.subplot(4, 8, i+1)\n",
    "    color = 'blue' if pred[i] == labels[i] else 'red'\n",
    "    plt.title(\"pre:{}\".format(pred[i]), color=color)\n",
    "    plt.imshow(np.squeeze(images[i]))\n",
    "    plt.axis(\"off\")\n",
    "    if color == 'red':\n",
    "        index = 0\n",
    "        print(\"Row {}, column {} is incorrectly identified as {}, the correct value should be {}\".format(int(i/8)+1, i%8+1, pred[i], labels[i]), '\\n')\n",
    "if index:\n",
    "    print(\"All the figures in this group are predicted correctly！\")\n",
    "print(pred, \"<--Predicted figures\") \n",
    "print(labels, \"<--The right number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建一个概率分析的饼图函数。\n",
    "\n",
    "备注：`prb`为上一段代码中，存储这组数对应的数字概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1 probability of corresponding numbers [0-9]:\n",
      " [-3.4469228   2.0546532  -3.5465317  -1.3858355  -0.28758872  1.1322775\n",
      " -0.8353202  -3.6402948   8.3553      1.3656969 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 2 probability of corresponding numbers [0-9]:\n",
      " [10.008167   -5.861808    1.4555234  -1.482836   -2.721113   -0.8507886\n",
      "  3.199972   -2.2156045   0.32849124 -1.4580953 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD3CAYAAAC+eIeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5iU1dnH8e+9LF16R6T3Lrs2LGshiqLRoIICryWWJBqNUdM0BDXWJAaNLTFqEo0hGmI0amJJlImCbVBQAZVelrZLWWDr7M79/nEGXXFhd3bKmXJ/rmuuhZmn3Duwvz1znvOcI6qKMcaY5MjxXYAxxmQTC11jjEkiC11jjEkiC11jjEkiC11jjEkiC11jjEkiC12TUkRknohcmqBj9xaRPSLSJPL3biLyPxHZLSJ3i8gNIvJIAs47XUReifdxTXrK9V2AiS8RWQNcqqr/8V1LqlHVdcBBtZ66HCgG2mqcBqyLSF9gNdBUVasj530SeDIexzfpz1q6Jpv1AZbGK3CNaQgL3QwmIheJyHwRmS0iO0VklYiMjzy/XkS2isiFtbafJCIfiMiuyOs37XO8C0RkrYhsE5GZIrJGRCZEXssRkR+LyMrI60+LSMcD1HamiCyKnGuliEysY5sBIvJa5HjFIvKkiLSv9fqPRKQw0j3wqYicFHn+cBEJRo69RUR+HXm+r4ioiOSKyB+BC4EfRrocJojITSLy51rHP0ZEFkTeu/UiclED3qf/Rb7ujBz3qMj7/Wat444XkfdEpCTydXyt1+aJyM8j/267ReQVEem8/39lk24sdDPfEcCHQCfgL8BfgcOAgcAM4H4R2fuRuxS4AGgPTAK+IyJnAYjIcOBBYDrQA2gHHFzrPFcDZwEFQE9gB/BAXQWJyOHA48APIuc6DlhT16bAHZHjDQMOAW6KHGMI8F3gMFVtA5xS6xj3AveqaltgAPD0vgdW1YtwH/l/oaoH7dsdIyK9gX8D9wFdgLHAovrep8j3AtA+cty39jluR+BF4De4f5NfAy+KSKdam00DLga6As2A6+t4b0yastDNfKtV9Q+qWgM8hQuuW1S1UlVfAapwAYyqzlPVj1Q1rKofAnNwIQpwDvC8qr6pqlXAz4DaH8u/BdyoqhtUtRIXjueISF3XDS4BHlPVVyPnKlTVT/bdSFVXRLapVNUiXEDtracGaA4MF5GmqrpGVVdGXgsBA0Wks6ruUdW3G/G+TQf+o6pzVDWkqttUdVED3qf6TAKWq+oTqlqtqnOAT4Azam3zB1X9TFXLcb8wxjaifpOiLHQz35Zafy4HUNV9nzsIQESOEJHXRaRIREqAbwN7P9r2BNbv3UlVy4BttY7TB/hH5KP4TmAZLhi71VHTIcDKOp7/EhHpKiJ/jXQh7AL+vLceVV0BXIML962R7XpGdr0EGAx8Evn4fnp954qmxnrep/r0BNbu89xavvypYXOtP5fx5Yt/Js1Z6Jra/gL8EzhEVdsBv8V9xAfYBPTau6GItMR9PN5rPXCqqrav9WihqoV1nGc97mN/fe7AtaZHR7oKZtSqB1X9i6oegwt8Be6KPL9cVc/HfTy/C5grIq0bcL6G1nig96m+i3IbI/XW1huo630yGchC19TWBtiuqhWRftdptV6bC5wRuQjUDLiZWgGIC57bRKQPgIh0EZEz93OeR4GLReSkyAW4g0Vk6H7q2YO7KHUwrg+YyPGHiMiJItIcqMC12Gsir80QkS6qGgZ2RnapieqdcP29E0RkSuTCWycR2fsx/0DvUxEQBvrv57j/AgaLyLTIcacCw4EXoqzPpCkLXVPbFcAtIrIb12f7+QUoVV0CXIW7ELcJ2A1sBSojm9yLa/29Etn/bdxFvK9Q1XdxF4pmAyVAgK+2/sAF+7jINi8Cz9R6rTlwJ26c7WZcq/aGyGsTgSUisidS13mqWtHQNyFS4zrgNOA6YDvuItqYyMsHep/KgNuA+ZGuliP3Oe424PTIcbcBPwROV9XiaOoz6UtsiKJpjMiIh53AIFVd7bseY9KFtXRNg4nIGSLSKtI/+ivgI+oe6pUSROT7IrJERD4WkTki0sJ3TcZY6JponIm7ELQRGIT72J6SH5UifcBXA/mqOhJoApzntypjbO4FEwVVvRRIyGQ0CZILtBSRENAK98vCGK+spWsyUmSo2q+AdbgLfyWRm0GM8cpC12QkEemA6w7ph7shobWIzPBblTEWuiZzTcDdAl2kqiHccLPx9exjTMJZ6JpMtQ44MjLaQoCTcLcmG+OVha7JSKr6Du4uuvdxQ9tygIe9FmUMdnOEMcYklQ0ZM8akpIULF3bNzc19BBhJan4qDwMfV1dXX5qXl7e1oTtZ6BpjUlJubu4j3bt3H9alS5cdOTk5KfeRPBwOS1FR0fDNmzc/Any9oful4m8PY4wBGNmlS5ddqRi4ADk5OdqlS5cSXEu84fslqB5jjIlVTqoG7l6R+qLKUQtdY4xJIuvTNalBpCnQN/Loglv0scM+j9a4iWuaHM2baxZwdF/c5OTVuMUid+Hm3t2Bm2e3CDfn71pgvSrVSft+TPyJ5MX1eKoL69tk7ty5ba+//vre4XCYGTNmFN9+++2b69unPha6JrncOmZ5wGjccjj9cbfq9iKKT14ltJsPHB3FmWtaNg8vLH/l/V3Ap7UeiynI33LgXU02qq6u5vvf/37vl19++bP+/fuHxowZM+zss8/emZeXF9WE+Puy0DWJI9IFOAoXsnsf3T1V06Rtq5pc3O3BE770SiC4ClgAvBX5+hEF+dEu72MyzLx581r36dOncvjw4VUAkydP3j537tz2eXl5MbV2LXRN/LjFKo/DhdrXcK1ZOeA+SdS3e2Xpfl7qH3nsnRBnN4Hgu7gA/i/wpoVw9lm/fn2zgw8+uGrv33v16lX1zjvvxLwys4WuiY1IX+Ac4FTcx/3mPss5kFH9yxsanG1wczWcBMwEigkEnweeBV6hID+mj5cmPdR1t66IxDyawkLXRE+kF3AuMJX9LD6ZivKGlDV2uZ7OuIU0LwZKCQRfAv4BvEhB/s4D7mnSVu/evasKCwub7f37hg0bmvXs2TMU63EtdE3DiLQFpuOWGz+aFOo2aKhDB5V1jMNhWgNnRx4hAsEXgIeA/1CQn9JjSk10CgoKStesWdPik08+ada3b9/QM8880/HJJ59cFetxLXTNgYmMwi05PgOIuT/LpxF9y3vG+ZBNgW9EHisIBH8L/IGC/O1xPo+BBg3xiqemTZty9913r5s4ceLgmpoapk2bVpyfH3vXkoWu+SqRZriW3BXAMZ6riYsc0aI2rcJdEniKgbjlgW4lEHwaeIiC/LcTeD6TBFOnTi2ZOnVqSTyPaXekmS+ItETke8Bq4C9kSOACtG1dsylJp2oBXAC8RSC4kEDwrCSd16QJC10DIq0QuRZYBdyDW1MsoxzStWq3h9OOA/5BIBgkEDzNw/lNCrLQzWYirRH5Ia5lezf+blxIuBF9y2O+6hyDPOBFAsG3CAQn1Lu1yWgWutlIJAeRS4DlwF1AV88VJdy4wWXN6t8q4Y4EXiUQDBAIHue7GOOHhW62ESkAFgKPAD08V5M0+UPK2vmuoZbjgACB4N8JBA/2XYxJLgvdbCFyMCJzgHnAWM/VJN3IfnEfLhYPk4FlBILfIxBs4rsYkxw2ZCzTueXHrwTuIM3H2TaWoCVd2ld38F3HfrTBXbz8PwLBb1GQn9SxqOlEbo7v1I4668DjflesWNF0+vTp/YqKiprm5ORw4YUXFs2cObPBa6Htj7V0M5lIP+A14D6yNHABWrcMb/RdQwPkAe8QCN5LINjGdzHm85sjNqxatWrJe++9t+zRRx/tunDhwsbeSv45C91MJCKIfAf4EDjeczXe9ewc2uG7hgZqAlwNfEIgeLLvYrJdnz59Qsccc0wZQIcOHcIDBgwoX7duXcwXZC10M41Ib+BV4EGyuHVb29DeFT6HizVGT+AlAsHbrK83NXz66afNli5d2qqgoGBPrMey0M0kIqcBH+CmJDQR4waVpmNwCXADMI9AsJfvYrJZSUlJzuTJkwfceeed6zt27BiO9XgWupnAjbu9FXgBiMdMWhklb3BZOveRHgMsSsQdbSLSXkTmisgnIrJMRI6K9znSXWVlpUyaNGnAueeeu/3CCy+MyzSeFrrpzi2J8zJwI2k43WIyjB5Q3s13DTHqBLxAIPhLAsF4jji6F3hJVYcCY4BlcTx22guHw5x33nl9Bg8eXHHTTTfFbR09GzKWzkSOBP6GW9TR1EnLe3WtSvfQBfcL9XpgPIHgmRTkF8d0MDc/8nHARQCqWgVUHWgf3+ob4hVvr7766kHPPvtsp0GDBpUPHTp0OMDNN99cGOusYxa66UrkbODPuFmtzH60aKaFOcJA33XE0XhgAYHgRAryY5lQuz9uifo/iMgY3F2K31PV/a0jl3VOOeWUPZqAOXyteyEdiVwDPI0Fbr26dQht811DAgzCTR15WAzHyMXNgvaQqh4KlAI/jkdx5sAsdNOJG387G5iN/ds1yKBelZm6iGRX3MiG0xu5/wZgg6q+E/n7XFwImwSzH9x0IdIC17q9xncp6WTswLJMvrjYCniWQPDyaHdU1c3AehEZEnnqJGBpPIszdbPQTQciLYHncUudmyjkDSnN9BtEmgC/IxC8tRH7XgU8KSIf4iZBuj2ulZk62YW0VOcC95+ATX7dCIcOKuvsu4YkuZFAsAUF+dc3dAdVXQTkJ7AmUwdr6aYyC9wYaWhAz8psmq/2OgLBO30XYQ7MWrqpygXuc1jgNlrTXN2Y24Q+vutIsh8RCIYoyJ/pu5C4CwTjOrVjQ6bRLC4ubjJjxow+n376aUsR4eGHH14zYcKEmIbVWUs3Fbkl0J8Dvua7lHTWuV11TDcQpLGfEgj+wHcRmeDyyy8/5OSTT961evXqJUuXLl06duzYmEfDWOimGjfp+B+wwI1Z/x6V2TzQ/xcEgpf6LiKdbd++Peedd95pc8011xQDtGjRQjt37lwT63EtdFPPbcA030VkgtEDytV3DZ79jkDQRrw00ieffNK8Y8eO1eeee27fYcOGDZ86dWqfXbt2xZyZFrqpRORy4Ce+y8gU+UNKW/quwbMc4Im494Vmierqalm2bFmrK6+8smjZsmVLW7VqFZ45c2b3WI9roZsqRE7FTTxu4uTQQWWdfNeQAloA/yAQ7Oq7kHTTt2/fqm7dulWdeOKJpQBTp07dsXjx4laxHtdCNxWIjMLdbZaOk20nzHrgBGAYMAI3D+FXPQmMjjzGA4sjz2/VK2ZP6zfyoqk8+8a8z7c+88br2FhclLiiU9MhwFwCwaa+C0knvXv3ru7evXvV4sWLmwO88sorbYcMGRLzhTQbMuabm2Lv79jSOl+RC9yNmxBgN27lxq8Bw7+0VT8gAHQA/g1cDryDyJ92f/O009ued+LJTPzh1Zx17PE8v+B/jBs0lJ6duyTz20gVx+JWHb7SdyGN5mGl5Pvuu2/d9OnT+1dVVUnv3r0r58yZsybWY1ro+vcobtYos48ekQe4dcqHAYXsG7rja/35SNw8LtCyWc2u8srKtpVVIXIkh+rqau6ZO4fnb5+d8LpT2BUEgu9TkP+o70LSxfjx48s//vjjuE7ubt0LPrkpGu3qcgOswS3+dsQBt3oUOBWAgb2mrXv5vbeZ+MOruemiy3jwublccPIkWrXI+tkwHyAQPNJ3EdnMQtcXtx7VL3yXkQ72AGfjPhu33e9Wr+NC9y4Axg5sFXrxznsIPvw44wYP5YW33uTs407ksl/eyjk/+xFvLfkwCZWnpObA3wkEbS09Tyx0fRDpiLtwZhc26hHCBe50YPJ+t/oQuBR3E58bsJA3uKzZ3ldv+dMj3DjjYua89jJ5g4fx2I9mcsPvs3qgSE/gft9FZCsLXT9+g61rVi8FLsH15V67363W4eL4CWDw58+OG1zWAWD5hnVs3FZEwdg8yioqyMkRRISKqpReDiwZzicQPNt3EdnIQjfZRM7ENdxMPebjovQ13GSvY4F/Ab8FingkMkj9FmAbcEVkCzdT4ah+5T0BbnzkIW695DsAnH/SKfzxpRc48oqLuX7qjCR+JynrIQLBrBzK4ZOoZvudkknkuhWWADHf1ZLtRvLR/CWMPLqu10R0W/j1hXZjRMM8Q0F+SrZ4Fy9evGbMmDEpP2nR4sWLO48ZM6ZvQ7e3IWPJ9RsscBOubauaTezt3DX1mUwgOI2C/L/4LqQ+IsT1dmZV6h33e/PNN3d94oknuogIQ4cOLXvqqafWtGrVKqaWqnUvJIvI17FuhaQ4uEtol+8a0sz9BII96t8su6xevbrpww8/3G3RokVLly9fvqSmpkYeeeSRmEd9WOgmg0hr4AHfZWSL4X3Ks/4qWZQ6sL+7rLNcTU2NlJaW5oRCIcrLy3N69eoVivWYFrrJcSM2WiFpxg0us6F40TuXQLDOPvJs1a9fv9CVV165uV+/fqO7du06pk2bNjWTJ0+O+VOUhW6iiQzkQCOeTNzlDynb/z0U5kDuJhDM5CXro1JUVNTkxRdfbL9ixYqPNm/e/GFZWVnOgw8+aN0LaeCXuLuATJKM6l9m/ZONcwRwnu8iUsXzzz/ftnfv3pU9e/asbt68uZ511lk7FyxYEPPEVBa6iSRyHHCW7zKyi+7u3rE6W5ZdT4Q7CASzfoIKcPPpvv/++wft3r07JxwO89prr7UZNmyYTe2Y4u72XUC2adUivBEY4ruONNYHuAZIuaXcGzLEK55OPPHE0jPOOGPH6NGjh+Xm5jJixIiya6+9NubJmC10E0XkDPbeHmWSpkfH0A7fNWSAnxAIPkpBftbN9r6v2bNnb5w9e/bGeB7TuhcSZ6bvArLRkEMqYv74V5f1WzdzwjXfZtgF5zLioincO3cOAH+b9x9GXDSFnBMOJ/jJ0jr3rais5PBvX8iYS6Yx4qIpzPrD7z5/bfqtP2X0N8/nht9/MaLw548/wnNvBhLxbTRUW+CnPgvIZNbSTQS33tlhvsvIRmMHlSVkyaPcJrncfcU1jBs8lN1lpeRdfgFfyz+Ckf0G8Mwtv+Bbd9+x332bN2vGa79+iINatSJUXc0xV13KqYeP/3xu3w8fm8OxV11GyZ49lFVW8O6yJcy8wPvq6ZcSCN5MQf5234VkGmvpJoa1cj3JH1KWkGWPenTqzLjBQwFo06o1w/r0pbC4iGF9+jGkd98D7isiHNTKrWcYqq4mVF2NiNA0N5fyykrC4TBV1SGa5OTws8d+yy3f/HYivoVotcLNIuRTOBwOp/QQtkh94Wj2sdCNN5EJwFG+y8hWYwaUdUv0OdZs2sgHyz/liGEjGrxPTU0NYy+ZRtezTuZr+UdwxPCRDOvTj95duzPushlMOX4CKwrXowqHDkqZ64BXeR7J8HFRUVG7VA3ecDgsRUVF7YCPo9nPuhfi7wbfBWQvrezTvSqhEwrtKSvj7Fk/4p7vXkvb1g1vVDdp0oRFj/6Fnbt3842ZP+DjVSsY2X8g91x13efbnPGT7/O7627gticeY/HK5Xwt/3AuO/0bifg2GqorcAHwsI+TV1dXX7p58+ZHNm/ePJLUbCCGgY+rq6uj6guy0I0nkeG4VcONB82bamGTHPon6vih6mrOnvUjpk+YyOTjTmzUMdq3acPxY/N46d23GNl/4OfPP/dmgPwhwymtKOfj1St5+qY7OO7qy5k+4VTf67pdSyD4ewrykz4HbF5e3lbg68k+b6Kl4m+PdPYd3wVksy7tqxM296qqcskvfs6w3n25dkp0k8UV7dzBzt27ASivrOA/C99laK1+4FB1Nff+/a/84Lz/o6yiAhH3aTocDlMVinl+lVgNIQODzydr6caLm0nsAt9lZLOBBydmuBjA/I8W88Qr/2JU/4GMvWQaALdfdiWVoSquuvdXFJXsYNJPvs/YgYN5+Zf3sbG4iEt/eSv/uuteNm0r5sI7bqImHCYcDjPlhAmcPv7Yz4/9wD+e5sJT3ErFowcMQlUZdfF5nHbk0bRv0yZR31I0rsctQGfiwFaOiBeRy4Hf1budiYu6Vo645pwtgdnfXV/gq6YMN5yC/GW+i8gE1r0QP76H12S9vCGlrX3XkMFsAv44sdCNB5HDgDG+y8h2hw4qs4luEmeaTfsYHxa68XG+7wKM1gzqVXmw7yoyWD/AJjmPAwvdWLlLzef6LiPb5TbRjc1y1VaMSCzrYogDC93YjceW4vGuY9uarJ8RKwmmEAjaL7YYWejGborvAgz0615Z6ruGLNARONV3EenOQjcWIjnAOb7LMDBqQHlUk46YRpvmu4B0Z6Ebm6OAnr6LMJA/uNSWmEmOUwgELTdiYG9ebCb6LsA44waXxbxKq2mQ9tiKKDGx0I3NBN8FGGd43wobLpY89v8+Bha6jSXSFlsdIiXk5OiW1i3CrXzXkUUsdGNgodt4JwAJWRrGRKdd65otvmvIMuMJBO2XXCNZ6Dae/bZPEb27Vu3yXUOWaQ4cW+9Wpk4Wuo13ku8CjDOiX3mN7xqykDU6GslCtzFE2gFDfZdhnLzBZXaXVPI1bukMY6HbSOMAm3EpRYwbXNredw1ZaJTdEtw4FrqNM853AeYLo/qX2w0qydcU+7TXKBa6jZPnuwDjiOjOTm1rrKXrx2jfBaQjC93GsZZuijioZXij7xqymIVuI1joRkukDTDYdxnG6dmpaqfvGrLYKN8FpCML3egNwy6ipYyhfSq8r1Gexayl2wgWutHr57sA84Vxg8rsrkB/DiYQ7OC7iHRjoRs9C90UkjekrK3vGrKctXajZKEbvf6+CzBfGDOgrJvvGrKcNUKiZKEbPftPljK0rFeXkIWuXzalZpQsdKNnoZsiWjbXQt81GAvdaFnoRsMtt97bdxnG6dYhtN13DdlOVe1uwCjl+i4gzbTB3f5oUsDgQyoqfNeQiVQ1HEa3VYQrd+yqLt1dFNpRXlhZVLO2YhOrKgqbrizf0HJ1xcY2Gyq3diwO7ewePt7WBI2GhW50bHhMChk7sMw+qTWQqqqiOyrDoR27a0p3FYdKyjZWFVWvrdjEqvLCJqsqCluuLt940PrKzR23VG3vWEO4C9ClAYfumujaM42FbnTsHv8Ukj+krLXvGnwLq+4KaWjbnpqyXdtCJWUbq4qr1lVsZnXFxpxV5YUtVlUUtllbsand5qptnUNa3RGI9wKeneN8vIxnoRsdC90UMmZgWUa2slS1NKTVxaU15bu2V+8q3Vy1rWp9xRZdVVGYs7J8Q/PVFRtbr63Y1G5jVVHninBVW8DnWOU2crM001la5bGGtGKhGx3rXkgRTaUm3L9HqIfvOhpKVSuqtWZbWbhi587q3aVbqrZXrq/cEl5dXigrKwqbrS4vbL2mYlO7DZVbO5WGy1sD6dSKbwlY6DaQhW50rKWbIvp3KinLbdLK6y3AqhqqIbytvKZyR0nNnj1bXZBWr63YlLOyvLDp6orCVqsrNrZdX7GlY0nNnna44VWZOMTKciQK9mZFp6XvAowzuveuEMR/Qdp9rtzvKgrtqCys3BpaU7FZVlVsaLqyfEPLNRWb2q6v3NJhW2hnB4XuuEc2sxyJgr1Z0bHJVVJE3pCKBo9cqHXlfvuumtJd20I7Kwori0JrKzfpqvKNTVeVb2ixpmJjm7WVmzturdreMYw29Mq9cSxHomBvVnRsiFKKyBtV3SKsWlKloe17aspKtodKyjdWFYfWVmwOr64ozF1ZvqHF6vKNrddVbu6wqaq4c7XWJOLKvXEsR6Jgb5ZJS7t+Pa3/kTP003XtOdx3LcY+AUbDWm7RqfFdgHGGFGvftfdw+N//ygctQ3zmu54sZ423KFjoRsdCN8VM/oRDd9/OwJ+8wRs5YYp815Ol1HcB6cRCNzq2NEwKaqLk3P5fjt1+F80nLieA2pjRJCvxXUA6sdCNjv3nSmHtKmn77ycpWHY/m/rt4B3f9WQR+7mIgqjaJ4MGEzkR+K/vMkzDPDeERdPOpmVZM4b4riWDVegstfHrUbCWbnR2+C7ANNyZnzJ21x0MmjmPN62/N2GslRslC93o2KTZaaaJknPLPI7ZcSctJn1KAKXSd00ZZqfvAtKNdS9EQ6Qt9ps9rX3WkfWTplO4ohNHeivibWBh5M/jgKP2eX0+8GHkz2GgGPgBbozAX4EK4ERgWGSbOcAkfM019q7O0iO8nDlN2fi6aKjuQqQae9/S1uDtHLL8Pg55cRCLp55Ls9Jmn0dXcmzBBe5luFsK/gwMBjrV2uboyAPgU+At3DQTbwNjgZGR/YZFXu+Bz8kdraUbJeteiN4m3wWY2E1azpiSOxhy0+u8mRNmS9JOXAz0AprhQrcvsOwA238EjIr8uQlu0GI1ILhR428D4xNUa8Os83r2NGShG71Vvgsw8dFEyZkV4Jidd9L6zGUEUBK/5lpXYC1QhpuBdjmwaz/bVgEr+KIbYRSwEtfKPR54DxiDC3B/Vno9exqy0I2e/SfLMG2qOOjZpyhY8RuKBxfzVkJP1gU4BngcF57d2P9P4We4taf3zmDZApgOfAvXpfAZLpD/CTwFrE9Y1QdiPw9RstCNnrV0M9SAHfT69H6O+vcTfNimkqUJO9E44NvAN3EzNO9v7rOPcf23dQkAx0W26QGcia8R5Ba6UbLQjZ79J8twE1cyeucdDLvtv8xvEk5AH/6eyNeduP7cUXVsUwGsAYbW8do2YDeuPziE698VXF9v8q3wctY0ZkPGoiVyONgtptliT1NKL/oG7/19GEcgcVo55DFcn24T4BSgP65/FuCwyNcPcHF2bh37Pw2chBvxsAc3jKwSOAEYHpcKG6pYZ6lN9h4lC91oibTH7kzLOqvbs3HSdNYs68xRCOK7nhTxjs5Sf+Od05R1L0RLdSew2ncZJrn67aTn0gcY/+rjLGlbwRLf9aSIT3wXkI4sdBtnYf2bmEw0YTUjd9zJ8LteZUFC+nvTi/0cNIKFbuMEfRdg/MkB+eF8xpfcQbspHxNAKfNdkycN+jkQkUNE5HURWSYiS0Tke4kuLJVZn25jiEwAXvVdhkkN69qy6bQZrFrShfFZ1N9bDbTVWVpe34Yi0gPooarvi0gbXAv5LFVN3KwgRVUAAAtMSURBVLC8FGah2xgiHbAZx8w+Xu/Lkm+cR7ikRZ2DwDLNQp2l+Y3ZUUSeA+5X1axsuFj3QmOo7sDG65p9nLCGETvvZNTdL/FWbg2FvutJsAWN2UlE+gKHksXDLi10G+913wWY1HTt2xxVcgcdp31IAKXUdz0JMj/aHUTkIODvwDWqur8ZJzKehW7jZeVHI9Mwrapp+eQzFKz/NXtGb2Y+mnEr5r4ZzcYi0hQXuE+q6jOJKSk9WJ9uY4l0ArZiv7hMA7zRm2Vnnk9oR0tG+64lDj7SWdrg70NEBPgTsF1Vr0lcWenBAqOxVLcB7/s49U7gHNxt+cPg82mx7gOGACOAH+5n39mR10cC58PncxlOB0YDN9Ta9ufAc/EsPIsdu45h2+9i9D3/5q3cGjb4ridGL0S5/dHA/wEnisiiyOO0BNSVFmwFhNi8CjTqCm4svgdMBObiplwtw3UwP4db5aU5rgm+r0LgN8BS3ORWU3C37Y+LvP4hcCxuPaIy4F1gZqK+iSz1vXc46vKFVHz7dOY9PoZ8hIN819QIUYWuqr4JWTOUrl7W0o3NK8k+4S7gf8Alkb83A9oDDwE/xgUuuLmy61INlEe+lgE9gaaR58K4EG8C/Ay4Jf7lG6BlNS3+9CzHb/g1ZYdu5E2UsO+aolCMW6/CNJKFbmzm4ybaS5pVuHmwL8aNu7kUKMXNZ/0GcARQwBeTVtV2MHA9bl7sHkA74GRcF0VvXIt3Cm5yK40c3yTOwbvp+v7DHDP/MT7rVMYi3/U00L90lqbTL4mUY6EbC9UQkNQrsdW4juTv4Gb/aw3cGXl+B64J8ktceO57iXQHrgtiNbARF9Z/jrx2D7AIuA7XpXALcFvkOL9P2HdjAMavZ2jxLxj7wIu83bQm5dcci7Y/1+zDQjd2TyXzZL0ij71rXp+DC+FewGRcx9nhuH/Y4n32/Q/QD9dSbhrZft8R7s/hOqlLcYsSPA08AVk7uUAyXfEeR+66nW4Xf0AAZbfveuoQAl72XUS6s9CN3TxI3mqy3YFDcCtvg1uhZThwFvBa5LnPcH2znffZtzeuJVyGawX/F760/ngIuBf4QWSbvVc+9vb1msRrUUPzx56jYNOvqDiskDdSrL/3BZ2VvTc1xIuFbqxUa3ADCZLmPr4Y4rUIN8zrm7j+3pHAebhBkYLrRtg7NucIXMt4HG6FmDBwea3jPgBciFsHcTQumEfhxvu0T+Q3ZL6ieyld3v09x771CMs7l/KB73oiHvNdQCawmyPiQeQY3HUsYxLi4XG8+91JdAs1oY+nEjYBh+gsrfF0/oxhLd34mA8s912EyVyXv8/hu2+nx2ULCaCUeCjhcQvc+LDQjQf3ceEh32WYzNa8hmYPP0/B5l8ROmIDb6AkMwStayFOrHshXtyClYW4LlFjEi7Yg+WTprN760Gf31SYKPN1lh6T4HNkDWvpxotbsHKO7zJM9sjfxKAtv2Lco8/yXrPqhC6Waq3cOLKWbjyJHIqnSXBMdqvKIXTNRBb89jDGqtAujofeAvTVWVpR75amQSx0401kAXCU7zJMdipqxfazzuPjBYdwNEKTOBzyJzpL74zDcUyEhW68iUzGTdZsjDfv92DFpGmUbG5DXgyHKQF62w0R8WWhG29uwubFkBWLE5oU9/ho3rv863SqzKV/I3a/XWfpjXEvKstZ6CaCyDnA33yXYQxAKIfq605mwf1HMEqFDg3crRzoo7O0KJG1ZSML3URwrd0PcXflGpMSiluy4+ypfPS/PoxH6l3A4H6dpVclpbAsY6GbKCJTSPIMZMY0xOJurDptOts3tt3vqichYJDO0rXJrCtbWOgmikgOrrU7wncpxtTlyVEEL/06HSqaMmCfl+7VWbaAZKJY6CaSyOnA877LMGZ/QjlU/3gCC2YfxUgVOuLWPR2oszSpK6JkEwvdRBN5FZjguwxjDmRHC0rOnsKiN/vwz6pb9Ne+68lkFrqJJjIKt7JOPAaqG5NIK4CRqFb6LiST2dwLURKRiSLyqYisEJEf17uD6kfYDGQmPVxrgZt41tKNgog0wa2G8zVgA27R3fNVdWk9O7aP7Ncl0TUa00gvoXqq7yKygbV0o3M4sEJVV6lqFfBX4Mx693IzkP0gwbUZ01h7cAtMmySw0I3OwcD6Wn/fEHmufqp/Av6VgJqMidWPUV3ju4hsYaEbHanjuWj6Zy7DDckxJlUEgAd9F5FNLHSjswG3AvpevXAL7jaM6kbg6jjXZExjlQGXYBd2kspCNzrvAYNEpJ+INMOtdv7PqI6g+gTwXAJqMyZaN6K60ncR2cZGL0RJRE4D7sGNu31MVW9rxEG6AUuATvGtzpgG+y9wMqph34VkGwtdX0ROBV6k7n5iYxJpEzAW1a2+C8lG1r3gi+q/gVt9l2GyTg1wngWuPxa6ft0EvOq7CJNVforq/3wXkc2se8E3kc64FYQPqW9TY2L0InCGjVbwy0I3FYgcDrwBNPNdislYK4AjUN3uu5BsZ90LqUD1XeAS32WYjFUMnGqBmxosdFOF6p8BW3nVxFsFcCaqK3wXYhwL3VSiejvwO99lmIyhwAWoLvBdiPmChW7quRJ4wXcRJiP8GNW/+S7CfJldSEtFIq2A13FTSRrTGLNRvdZ3EearrKWbilTLgInAQt+lmLT0Gwvc1GWhm6pUd+AWtAz6LsWklftR/Z7vIsz+WeimMrfixATc7GbG1OdBVK/yXYQ5MAvdVKdagluT7V3fpZiU9lvgu76LMPWz0E0HXwSv3TNv6nIrqt+x23vTg4VuulDdhQvev/guxaSMGuBbqM70XYhpOAvddOJWIJ4B3O67FONdGXAWqg/7LsREx8bppiuRy3ALCub6LsUkXRFwemTODpNmLHTTmcgpwF+B9r5LMUnzAXA2qqt9F2Iax7oX0pnqy0Aebj5ek/keA8Zb4KY3C910p7oKGI9NlJPJKoBLUb0E1QrfxZjYWPdCJhGZgRuv2dp3KSZuVgPnoGqfZjKEtXQziZuT93DgQ9+lmLh4HBhngZtZLHQzjepSIB+4BQh5rsY0zhbcxOMXRm4FNxnEuhcymchY4I/AGM+VmIZ7CrgS1W2+CzGJYS3dTKa6CDgMt9S7tXpT21ZgCqrnWeBmNmvpZguREcB9wAm+SzFfUoO7yeVn1pWQHSx0s43IOcCvgD6+SzHMA65BdbHvQkzyWPdCtlGdCwwFfgLs8lxNtloJTEb1BAvc7GMt3Wwm0gW4AfgW0NJzNdlgLW6yoj+gan3sWcpC14BIV+A64ArgIM/VZKI1uLD9o4WtsdA1XxDpCFwDXA2081xNJliDha3Zh4Wu+SqRdsA3gW8Dgz1Xk24U+A/wAPACqjWe6zEpxkLX7J+IACcC3wHOxObuPZAS4E/AA6h+5rsYk7osdE3DiPQALgUuAAZ6riZVhIEAbgmlOaiWeq7HpAELXRM9kUOBKcC5wADP1fjwNjAH+Buqm3wXY9KLha6Jjcg4XAB/HRjmuZpEqQTmAy/hgnaN33JMOrPQNfEj0hM4qdajl9+CYrIUeCXyCKBa5rkekyEsdE3iiAwBCnBLCo0DRgHNvdZUt53AQuA9IAi8jWqh35JMprLQNckjkguMwAXwobgLcn0jj2TcEbcddwvuqsjXj4AgqiuScG5jAAtdkwrc0LRuuPDtB/TArXC899Eu8rUtbthaTuQRBqojj1JcqNZ+7MAtV74aWGmzeJlUYKFrjDFJZLOMGWNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMElnoGmNMEv0/mmN78qpP9KYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the pie drawing function of probability analysis\n",
    "def plot_pie(prbs):\n",
    "    dict1 = {}\n",
    "    # remove the negative number and build the dictionary dict1. The key is the number and the value is the probability value\n",
    "    for i in range(10):\n",
    "        if prbs[i] > 0:\n",
    "            dict1[str(i)] = prbs[i]\n",
    "\n",
    "    label_list = dict1.keys()\n",
    "    size = dict1.values()\n",
    "    colors = [\"red\", \"green\", \"pink\", \"blue\", \"purple\", \"orange\", \"gray\"] \n",
    "    color = colors[: len(size)]\n",
    "    plt.pie(size, colors=color, labels=label_list, labeldistance=1.1, autopct=\"%1.1f%%\", shadow=False, startangle=90, pctdistance=0.6)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Image classification\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "for i in range(2):\n",
    "    print(\"Figure {} probability of corresponding numbers [0-9]:\\n\".format(i+1), prb[i])\n",
    "    plot_pie(prb[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上过程就是这次手写数字分类训练的全部体验过程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
